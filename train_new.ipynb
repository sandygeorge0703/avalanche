{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import libraries",
   "id": "43fe3676e3ae94e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:14:48.409826Z",
     "start_time": "2025-02-04T10:14:48.236287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import labels\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Sampler, SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm  # Import tqdm for progress visualization\n",
    "from models.cnn_models import SimpleCNN\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torchmetrics.functional import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Allow loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)  # If using a GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ],
   "id": "f56882980c54c0c5",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define filepaths as constant",
   "id": "673451622178f9a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:14:49.457424Z",
     "start_time": "2025-02-04T10:14:49.448918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define file paths as constants\n",
    "CSV_FILE_PATH = r'C:\\Users\\Sandhra George\\avalanche\\data\\dataset.csv'\n",
    "ROOT_DIR_PATH = r'C:\\Users\\Sandhra George\\avalanche\\caxton_dataset\\print24'\n",
    "\n",
    "csv_file = r'C:\\Users\\Sandhra George\\avalanche\\data\\dataset.csv'  # Path to the CSV file\n",
    "root_dir = r'C:\\Users\\Sandhra George\\avalanche\\caxton_dataset\\print24'  # Path to the image directory"
   ],
   "id": "332560819217a150",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data into DataFrame and filter print24",
   "id": "fd3e431089468016"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:06.915885Z",
     "start_time": "2025-02-04T10:14:50.488049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data into a DataFrame for easier processing\n",
    "data = pd.read_csv(CSV_FILE_PATH)\n",
    "\n",
    "# Limit dataset to the images between row indices 454 and 7058 (inclusive)\n",
    "#data_limited = data.iloc[454:7059].reset_index(drop=True)\n",
    "\n",
    "# Filter the dataset to only include images containing \"print24\"\n",
    "data_filtered = data[data.iloc[:, 0].str.contains('print24', na=False)]\n",
    "\n",
    "# Update the first column to contain only the image filenames\n",
    "data_filtered.iloc[:, 0] = data_filtered.iloc[:, 0].str.replace(r'.*?/(image-\\d+\\.jpg)', r'\\1', regex=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"First rows of filtered DataFrame:\")\n",
    "print(data_filtered.head())\n",
    "\n",
    "# Display the last few rows of the updated DataFrame\n",
    "print(\"\\nLast rows of filtered DataFrame:\")\n",
    "print(data_filtered.tail())"
   ],
   "id": "112cc9f08043995a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First rows of filtered DataFrame:\n",
      "          img_path               timestamp  flow_rate  feed_rate  z_offset  \\\n",
      "99496  image-4.jpg  2020-10-07T11:45:35-86        100        100       0.0   \n",
      "99497  image-5.jpg  2020-10-07T11:45:36-32        100        100       0.0   \n",
      "99498  image-6.jpg  2020-10-07T11:45:36-79        100        100       0.0   \n",
      "99499  image-7.jpg  2020-10-07T11:45:37-26        100        100       0.0   \n",
      "99500  image-8.jpg  2020-10-07T11:45:37-72        100        100       0.0   \n",
      "\n",
      "       target_hotend  hotend    bed  nozzle_tip_x  nozzle_tip_y  img_num  \\\n",
      "99496          205.0  204.86  64.83           654           560        3   \n",
      "99497          205.0  204.62  65.08           654           560        4   \n",
      "99498          205.0  204.62  65.08           654           560        5   \n",
      "99499          205.0  204.62  65.08           654           560        6   \n",
      "99500          205.0  204.62  65.08           654           560        7   \n",
      "\n",
      "       print_id  flow_rate_class  feed_rate_class  z_offset_class  \\\n",
      "99496        24                1                1               1   \n",
      "99497        24                1                1               1   \n",
      "99498        24                1                1               1   \n",
      "99499        24                1                1               1   \n",
      "99500        24                1                1               1   \n",
      "\n",
      "       hotend_class   img_mean    img_std  \n",
      "99496             1  21.047311  31.160557  \n",
      "99497             1  23.239277  32.133393  \n",
      "99498             1  23.686270  31.702140  \n",
      "99499             1  21.645111  31.329910  \n",
      "99500             1  20.883776  32.322521  \n",
      "\n",
      "Last rows of filtered DataFrame:\n",
      "               img_path               timestamp  flow_rate  feed_rate  \\\n",
      "120639  image-26633.jpg  2020-10-07T15:11:15-03        167         39   \n",
      "120640  image-26634.jpg  2020-10-07T15:11:15-48        167         39   \n",
      "120641  image-26635.jpg  2020-10-07T15:11:15-94        167         39   \n",
      "120642  image-26636.jpg  2020-10-07T15:11:16-40        167         39   \n",
      "120643  image-26637.jpg  2020-10-07T15:11:16-85        167         39   \n",
      "\n",
      "        z_offset  target_hotend  hotend    bed  nozzle_tip_x  nozzle_tip_y  \\\n",
      "120639     -0.02          226.0  226.00  65.05           654           560   \n",
      "120640     -0.02          226.0  226.00  65.05           654           560   \n",
      "120641     -0.02          226.0  226.00  65.05           654           560   \n",
      "120642     -0.02          226.0  226.00  65.05           654           560   \n",
      "120643     -0.02          226.0  226.25  64.94           654           560   \n",
      "\n",
      "        img_num  print_id  flow_rate_class  feed_rate_class  z_offset_class  \\\n",
      "120639    26632        24                2                0               1   \n",
      "120640    26633        24                2                0               1   \n",
      "120641    26634        24                2                0               1   \n",
      "120642    26635        24                2                0               1   \n",
      "120643    26636        24                2                0               1   \n",
      "\n",
      "        hotend_class    img_mean    img_std  \n",
      "120639             2   99.738226  71.471386  \n",
      "120640             2  102.395052  72.259859  \n",
      "120641             2  105.231595  74.336885  \n",
      "120642             2   97.592887  67.624012  \n",
      "120643             2   97.459404  67.672459  \n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analysing the target hotend temperature column",
   "id": "135a34632d895db4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:14.122670Z",
     "start_time": "2025-02-04T10:15:14.050131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract unique temperatures in the 'target_hotend' column and sort them\n",
    "unique_temperatures = sorted(data_filtered['target_hotend'].unique())  # Sort temperatures in ascending order\n",
    "\n",
    "# Calculate the full range of temperatures (min and max)\n",
    "temperature_min = data_filtered['target_hotend'].min()\n",
    "temperature_max = data_filtered['target_hotend'].max()\n",
    "\n",
    "# Print the unique temperatures (sorted), count, and full range\n",
    "print(\"\\nUnique target hotend temperatures in the dataset (sorted):\")\n",
    "print(unique_temperatures)\n",
    "print(f\"\\nNumber of unique target hotend temperatures: {len(unique_temperatures)}\")\n",
    "print(f\"Temperature range: {temperature_min} to {temperature_max}\")"
   ],
   "id": "fa4af2335a1e6815",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique target hotend temperatures in the dataset (sorted):\n",
      "[180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0]\n",
      "\n",
      "Number of unique target hotend temperatures: 51\n",
      "Temperature range: 180.0 to 230.0\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a random temperature sub list",
   "id": "f92f82696d7a3423"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:15.165603Z",
     "start_time": "2025-02-04T10:15:15.139597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if we have enough unique temperatures to select from\n",
    "if len(unique_temperatures) >= 50:\n",
    "    # Select the lowest and highest temperatures\n",
    "    temperature_sublist = [temperature_min, temperature_max]\n",
    "\n",
    "    # Remove the lowest and highest temperatures from the unique temperatures list\n",
    "    remaining_temperatures = [temp for temp in unique_temperatures if temp != temperature_min and temp != temperature_max]\n",
    "\n",
    "    # Randomly select 40 other temperatures from the remaining ones\n",
    "    random_temperatures = random.sample(remaining_temperatures, 40)\n",
    "\n",
    "    # Add the random temperatures to the temperature_sublist\n",
    "    temperature_sublist.extend(random_temperatures)\n",
    "    \n",
    "    # Sort from lowest to highest hotend temperature\n",
    "    temperature_sublist = sorted(temperature_sublist)\n",
    "\n",
    "    # Print the temperature sublist\n",
    "    print(\"\\nTemperature sublist:\")\n",
    "    print(temperature_sublist)\n",
    "else:\n",
    "    print(\"Not enough unique temperatures to select from. At least 40 unique temperatures are required.\")"
   ],
   "id": "3590e22617724f85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperature sublist:\n",
      "[180.0, 181.0, 182.0, 183.0, 184.0, 186.0, 187.0, 188.0, 189.0, 191.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 201.0, 202.0, 203.0, 205.0, 208.0, 209.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 226.0, 227.0, 228.0, 229.0, 230.0]\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a new dataframe with equal class distribution",
   "id": "2e2c53293f3db5da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:16.435339Z",
     "start_time": "2025-02-04T10:15:16.024025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialise a dictionary to store DataFrames for each class\n",
    "class_datasets = {}\n",
    "\n",
    "# Iterate through the filtered dataset to gather class-wise data\n",
    "for class_id in [0, 1, 2]:  # Ensure we process all classes: 0, 1, 2\n",
    "    # Filter the data for the current class\n",
    "    class_data = data_filtered[data_filtered['hotend_class'] == class_id]\n",
    "    \n",
    "    if class_data.empty:\n",
    "        print(f\"Class {class_id} dataset size: 0\")\n",
    "    else:\n",
    "        # Store the data for each class in the dictionary\n",
    "        class_datasets[class_id] = class_data\n",
    "        print(f\"Class {class_id} dataset size: {len(class_data)}\")\n",
    "\n",
    "# Find the class with the fewest images\n",
    "min_class_size = min(len(class_datasets[class_id]) for class_id in class_datasets)\n",
    "\n",
    "# Print the class with the fewest images\n",
    "print(f\"\\nSmallest class size: {min_class_size}\")\n",
    "\n",
    "# Now, we will sample the same number of images from each class\n",
    "balanced_data = []\n",
    "\n",
    "# Iterate over each class and sample min_class_size images\n",
    "for class_id in class_datasets:\n",
    "    class_data = class_datasets[class_id]\n",
    "    \n",
    "    # Randomly sample 'min_class_size' images from the class data\n",
    "    sampled_class_data = class_data.sample(n=min_class_size, random_state=42)\n",
    "    balanced_data.append(sampled_class_data)\n",
    "\n",
    "# Combine all the sampled class data into one DataFrame\n",
    "balanced_dataset = pd.concat(balanced_data).reset_index(drop=True)\n",
    "\n",
    "# Display the balanced dataset summary\n",
    "print(f\"\\nBalanced dataset size: {len(balanced_dataset)}\")\n",
    "\n",
    "# OPTIONAL: Shuffle the final balanced dataset\n",
    "balanced_dataset = balanced_dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display the first and last five rows of the shuffled dataset\n",
    "print(\"\\nFirst five rows of the shuffled balanced dataset:\")\n",
    "print(balanced_dataset.head())\n",
    "\n",
    "print(\"\\nLast five rows of the shuffled balanced dataset:\")\n",
    "print(balanced_dataset.tail())\n",
    "\n",
    "# Print the count of images in each class after balancing\n",
    "print(\"\\nNumber of images in each hotend class in the balanced dataset:\")\n",
    "for class_id in [0, 1, 2]:\n",
    "    class_count = len(balanced_dataset[balanced_dataset['hotend_class'] == class_id])\n",
    "    print(f\"Class {class_id}: {class_count} images\")"
   ],
   "id": "d5d322be88b66b67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 dataset size: 7424\n",
      "Class 1 dataset size: 11232\n",
      "Class 2 dataset size: 2492\n",
      "\n",
      "Smallest class size: 2492\n",
      "\n",
      "Balanced dataset size: 7476\n",
      "\n",
      "First five rows of the shuffled balanced dataset:\n",
      "          img_path               timestamp  flow_rate  feed_rate  z_offset  \\\n",
      "0  image-19089.jpg  2020-10-07T14:13:14-93        148         90      0.03   \n",
      "1  image-10323.jpg  2020-10-07T13:05:32-49         92        197      0.04   \n",
      "2   image-3170.jpg  2020-10-07T12:10:07-87         84        151      0.26   \n",
      "3   image-2130.jpg  2020-10-07T12:02:04-56         75         55      0.00   \n",
      "4   image-6277.jpg  2020-10-07T12:34:12-00        134         63      0.20   \n",
      "\n",
      "   target_hotend  hotend    bed  nozzle_tip_x  nozzle_tip_y  img_num  \\\n",
      "0          185.0  185.44  65.28           654           560    19088   \n",
      "1          206.0  206.25  65.06           654           560    10322   \n",
      "2          182.0  188.05  65.05           654           560     3169   \n",
      "3          187.0  187.08  64.92           654           560     2129   \n",
      "4          186.0  184.88  65.31           654           560     6276   \n",
      "\n",
      "   print_id  flow_rate_class  feed_rate_class  z_offset_class  hotend_class  \\\n",
      "0        24                2                1               1             0   \n",
      "1        24                1                2               1             1   \n",
      "2        24                0                2               2             0   \n",
      "3        24                0                0               1             0   \n",
      "4        24                2                0               2             0   \n",
      "\n",
      "     img_mean    img_std  \n",
      "0  100.609424  74.317582  \n",
      "1   65.275384  50.444529  \n",
      "2   77.343324  41.969148  \n",
      "3   60.708646  42.258669  \n",
      "4   72.956410  53.380455  \n",
      "\n",
      "Last five rows of the shuffled balanced dataset:\n",
      "             img_path               timestamp  flow_rate  feed_rate  z_offset  \\\n",
      "7471   image-8380.jpg  2020-10-07T12:50:29-28        138         94     -0.06   \n",
      "7472   image-1401.jpg  2020-10-07T11:56:25-24         46        145      0.22   \n",
      "7473  image-12102.jpg  2020-10-07T13:19:19-56         68         84      0.23   \n",
      "7474   image-3722.jpg  2020-10-07T12:14:24-35         88         43      0.30   \n",
      "7475  image-20837.jpg  2020-10-07T14:26:41-02         64         34     -0.06   \n",
      "\n",
      "      target_hotend  hotend    bed  nozzle_tip_x  nozzle_tip_y  img_num  \\\n",
      "7471          224.0  224.02  64.77           654           560     8379   \n",
      "7472          228.0  226.25  65.48           654           560     1400   \n",
      "7473          227.0  227.13  65.03           654           560    12101   \n",
      "7474          193.0  193.30  65.19           654           560     3721   \n",
      "7475          223.0  223.17  65.09           654           560    20836   \n",
      "\n",
      "      print_id  flow_rate_class  feed_rate_class  z_offset_class  \\\n",
      "7471        24                2                1               0   \n",
      "7472        24                0                2               2   \n",
      "7473        24                0                0               2   \n",
      "7474        24                1                0               2   \n",
      "7475        24                0                0               0   \n",
      "\n",
      "      hotend_class    img_mean    img_std  \n",
      "7471             2   64.386279  47.943702  \n",
      "7472             2   50.991715  38.630041  \n",
      "7473             2   82.043490  63.561291  \n",
      "7474             0   68.027031  47.107019  \n",
      "7475             2  111.988581  83.494139  \n",
      "\n",
      "Number of images in each hotend class in the balanced dataset:\n",
      "Class 0: 2492 images\n",
      "Class 1: 2492 images\n",
      "Class 2: 2492 images\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Convert balanced_dataset into a dataframe that contains only the img_path and hotend_class",
   "id": "eb3276748ad77f61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:17.334636Z",
     "start_time": "2025-02-04T10:15:17.259632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming the previous steps for balancing the dataset are already done...\n",
    "\n",
    "# Select only the 'img_path' and 'hotend_class' columns\n",
    "balanced_dataset_filtered = balanced_dataset[['img_path', 'hotend_class']]\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame\n",
    "print(\"\\nFirst five rows of the filtered balanced dataset:\")\n",
    "print(balanced_dataset_filtered.head())\n",
    "\n",
    "# Display the last few rows of the filtered DataFrame\n",
    "print(\"\\nLast five rows of the filtered balanced dataset:\")\n",
    "print(balanced_dataset_filtered.tail())\n",
    "\n",
    "# Optionally, if you want to save this filtered DataFrame to a CSV\n",
    "#balanced_dataset_filtered.to_csv('balanced_dataset_filtered.csv', index=False)"
   ],
   "id": "294eaba27468643b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First five rows of the filtered balanced dataset:\n",
      "          img_path  hotend_class\n",
      "0  image-19089.jpg             0\n",
      "1  image-10323.jpg             1\n",
      "2   image-3170.jpg             0\n",
      "3   image-2130.jpg             0\n",
      "4   image-6277.jpg             0\n",
      "\n",
      "Last five rows of the filtered balanced dataset:\n",
      "             img_path  hotend_class\n",
      "7471   image-8380.jpg             2\n",
      "7472   image-1401.jpg             2\n",
      "7473  image-12102.jpg             2\n",
      "7474   image-3722.jpg             0\n",
      "7475  image-20837.jpg             2\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:17.848471Z",
     "start_time": "2025-02-04T10:15:17.749395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check class distribution in balanced_dataset\n",
    "class_distribution = balanced_dataset_filtered['hotend_class'].value_counts()\n",
    "print(class_distribution)"
   ],
   "id": "5c02025443c790f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotend_class\n",
      "0    2492\n",
      "1    2492\n",
      "2    2492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:18.294019Z",
     "start_time": "2025-02-04T10:15:18.251169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the indices, the classes, and the number of images in each class\n",
    "for class_label in class_distribution.index:\n",
    "    # Get all indices for the current class\n",
    "    class_indices = balanced_dataset_filtered[balanced_dataset_filtered['hotend_class'] == class_label].index.tolist()\n",
    "    \n",
    "    # Count the number of images for the current class\n",
    "    num_images_in_class = len(class_indices)\n",
    "    \n",
    "    # Print the details for this class\n",
    "    print(f\"\\nClass: {class_label} (Total images: {num_images_in_class})\")\n",
    "    print(\"Indices: \", class_indices)\n",
    "    print(f\"Number of images in class {class_label}: {num_images_in_class}\")\n",
    "\n",
    "# Step 1: Get the number of unique classes\n",
    "num_classes = len(class_distribution)\n",
    "\n",
    "# Step 2: Set a small batch size\n",
    "small_batch_size = 15  # You can change this to a value like 32, 64, etc.\n",
    "\n",
    "# Step 3: Calculate the number of samples per class per batch\n",
    "samples_per_class = small_batch_size // num_classes  # Ensure it's divisible\n",
    "\n",
    "# Make sure we don't ask for more samples than available in the smallest class\n",
    "samples_per_class = min(samples_per_class, class_distribution.min())\n",
    "\n",
    "# Step 4: Calculate the total batch size\n",
    "batch_size = samples_per_class * num_classes\n",
    "\n",
    "print(f\"\\nRecommended Small Batch Size: {batch_size}\")\n",
    "print(f\"Samples per class: {samples_per_class}\")"
   ],
   "id": "e776d405945438cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: 0 (Total images: 2492)\n",
      "Indices:  [0, 2, 3, 4, 5, 6, 9, 10, 14, 16, 18, 20, 25, 27, 30, 32, 35, 38, 44, 45, 53, 54, 56, 61, 63, 64, 66, 67, 70, 71, 72, 74, 77, 78, 83, 85, 90, 93, 94, 100, 101, 110, 111, 113, 116, 117, 118, 120, 123, 124, 127, 128, 129, 130, 134, 139, 140, 146, 149, 151, 152, 157, 159, 161, 166, 167, 172, 174, 175, 176, 179, 186, 191, 196, 200, 204, 211, 218, 219, 225, 226, 227, 230, 234, 238, 239, 242, 243, 247, 249, 252, 254, 255, 261, 262, 266, 268, 270, 271, 272, 273, 276, 278, 279, 283, 286, 288, 290, 293, 298, 303, 305, 310, 316, 317, 318, 319, 320, 324, 327, 329, 331, 333, 334, 335, 340, 343, 344, 345, 347, 350, 352, 354, 356, 357, 361, 366, 371, 375, 377, 378, 380, 387, 391, 392, 393, 394, 396, 399, 403, 408, 409, 416, 425, 430, 434, 439, 440, 443, 446, 453, 456, 462, 465, 467, 471, 475, 477, 478, 479, 481, 482, 483, 485, 489, 490, 491, 493, 495, 496, 497, 501, 503, 504, 506, 508, 511, 513, 514, 515, 519, 523, 524, 526, 530, 533, 538, 539, 540, 545, 547, 548, 551, 553, 557, 562, 566, 567, 569, 570, 572, 576, 577, 580, 583, 584, 585, 588, 600, 602, 604, 608, 611, 618, 619, 620, 621, 623, 624, 627, 629, 631, 635, 637, 638, 639, 640, 643, 650, 656, 657, 666, 671, 675, 676, 677, 680, 681, 683, 684, 690, 692, 695, 696, 700, 702, 705, 706, 709, 710, 712, 715, 716, 722, 732, 734, 741, 746, 751, 752, 756, 757, 759, 764, 768, 769, 774, 775, 781, 784, 786, 787, 792, 793, 796, 798, 801, 809, 814, 818, 821, 822, 823, 824, 828, 830, 831, 832, 836, 837, 839, 840, 841, 842, 843, 844, 846, 849, 853, 857, 858, 859, 860, 863, 866, 868, 871, 874, 876, 887, 889, 902, 904, 907, 908, 909, 912, 917, 918, 920, 923, 926, 931, 932, 937, 941, 943, 945, 951, 962, 963, 970, 973, 978, 979, 982, 987, 988, 989, 990, 996, 997, 1001, 1003, 1004, 1007, 1012, 1015, 1020, 1021, 1028, 1030, 1035, 1043, 1044, 1045, 1047, 1048, 1050, 1052, 1053, 1059, 1062, 1063, 1065, 1066, 1067, 1071, 1072, 1075, 1087, 1090, 1091, 1094, 1095, 1098, 1102, 1103, 1106, 1109, 1111, 1112, 1113, 1118, 1120, 1122, 1123, 1127, 1128, 1129, 1130, 1134, 1140, 1142, 1143, 1144, 1145, 1147, 1152, 1159, 1162, 1163, 1166, 1167, 1169, 1171, 1172, 1179, 1184, 1190, 1196, 1203, 1205, 1210, 1211, 1218, 1221, 1222, 1227, 1230, 1231, 1232, 1237, 1239, 1240, 1241, 1242, 1247, 1249, 1250, 1251, 1254, 1255, 1256, 1257, 1260, 1261, 1262, 1264, 1268, 1270, 1271, 1272, 1275, 1276, 1279, 1280, 1282, 1288, 1289, 1292, 1294, 1295, 1302, 1303, 1307, 1313, 1314, 1316, 1317, 1318, 1321, 1324, 1326, 1328, 1329, 1337, 1342, 1349, 1351, 1356, 1359, 1362, 1364, 1367, 1370, 1371, 1372, 1374, 1375, 1379, 1381, 1383, 1387, 1389, 1391, 1392, 1395, 1397, 1398, 1402, 1410, 1412, 1418, 1421, 1424, 1425, 1429, 1430, 1431, 1433, 1437, 1443, 1444, 1446, 1454, 1455, 1465, 1466, 1468, 1472, 1473, 1481, 1491, 1492, 1493, 1495, 1496, 1499, 1500, 1502, 1503, 1504, 1505, 1507, 1508, 1511, 1512, 1514, 1515, 1518, 1519, 1520, 1521, 1523, 1530, 1534, 1535, 1545, 1549, 1552, 1553, 1555, 1558, 1559, 1560, 1561, 1566, 1567, 1568, 1570, 1580, 1587, 1596, 1601, 1602, 1605, 1611, 1612, 1613, 1615, 1616, 1617, 1618, 1620, 1623, 1624, 1625, 1629, 1630, 1631, 1632, 1640, 1650, 1652, 1653, 1657, 1658, 1660, 1668, 1671, 1677, 1679, 1682, 1683, 1685, 1686, 1688, 1689, 1692, 1694, 1696, 1698, 1700, 1702, 1704, 1705, 1707, 1715, 1719, 1722, 1725, 1728, 1730, 1734, 1739, 1742, 1743, 1745, 1748, 1752, 1753, 1754, 1755, 1756, 1762, 1765, 1769, 1775, 1778, 1780, 1788, 1791, 1793, 1794, 1797, 1798, 1799, 1800, 1801, 1804, 1806, 1813, 1817, 1819, 1820, 1825, 1826, 1832, 1834, 1835, 1839, 1841, 1843, 1852, 1855, 1856, 1867, 1869, 1875, 1876, 1883, 1890, 1891, 1892, 1893, 1895, 1896, 1899, 1900, 1901, 1902, 1903, 1909, 1910, 1913, 1918, 1922, 1925, 1926, 1931, 1933, 1936, 1939, 1941, 1943, 1948, 1951, 1954, 1955, 1956, 1957, 1960, 1965, 1967, 1969, 1970, 1972, 1975, 1978, 1980, 1982, 1984, 1985, 1991, 1992, 2004, 2005, 2007, 2008, 2011, 2012, 2013, 2014, 2015, 2019, 2022, 2023, 2025, 2028, 2033, 2040, 2047, 2050, 2056, 2059, 2060, 2061, 2063, 2064, 2066, 2068, 2069, 2070, 2078, 2081, 2083, 2085, 2086, 2088, 2090, 2095, 2097, 2099, 2101, 2102, 2107, 2110, 2119, 2131, 2135, 2136, 2138, 2141, 2148, 2150, 2155, 2168, 2170, 2176, 2181, 2186, 2209, 2214, 2215, 2216, 2217, 2221, 2222, 2226, 2227, 2228, 2229, 2230, 2232, 2234, 2236, 2242, 2246, 2251, 2252, 2257, 2262, 2270, 2276, 2278, 2281, 2282, 2286, 2288, 2292, 2298, 2300, 2301, 2302, 2303, 2306, 2307, 2310, 2311, 2315, 2318, 2320, 2326, 2327, 2329, 2333, 2334, 2339, 2340, 2344, 2345, 2351, 2355, 2358, 2362, 2363, 2368, 2370, 2371, 2375, 2377, 2380, 2381, 2385, 2387, 2389, 2390, 2391, 2393, 2395, 2396, 2397, 2398, 2401, 2404, 2411, 2412, 2415, 2416, 2420, 2422, 2423, 2428, 2429, 2433, 2434, 2442, 2445, 2446, 2448, 2450, 2458, 2460, 2464, 2466, 2468, 2475, 2478, 2479, 2487, 2491, 2492, 2498, 2499, 2502, 2503, 2506, 2507, 2508, 2512, 2515, 2516, 2521, 2522, 2528, 2529, 2542, 2543, 2548, 2551, 2552, 2560, 2562, 2567, 2573, 2577, 2579, 2581, 2582, 2583, 2585, 2591, 2600, 2606, 2608, 2616, 2617, 2622, 2627, 2628, 2630, 2636, 2637, 2640, 2643, 2645, 2657, 2658, 2664, 2666, 2679, 2681, 2682, 2687, 2688, 2689, 2691, 2692, 2696, 2701, 2702, 2703, 2704, 2705, 2710, 2714, 2723, 2724, 2725, 2728, 2729, 2735, 2736, 2737, 2739, 2747, 2748, 2751, 2752, 2757, 2763, 2767, 2769, 2775, 2778, 2780, 2782, 2786, 2788, 2789, 2794, 2796, 2799, 2800, 2808, 2811, 2815, 2816, 2818, 2830, 2831, 2832, 2834, 2835, 2836, 2837, 2844, 2846, 2847, 2848, 2852, 2858, 2860, 2861, 2867, 2870, 2873, 2874, 2875, 2877, 2879, 2880, 2883, 2887, 2888, 2891, 2892, 2893, 2896, 2898, 2902, 2905, 2910, 2911, 2914, 2917, 2923, 2928, 2929, 2931, 2932, 2933, 2938, 2939, 2942, 2945, 2950, 2951, 2952, 2954, 2955, 2963, 2964, 2965, 2968, 2970, 2977, 2978, 2980, 2984, 2985, 2989, 2993, 2995, 2998, 3000, 3005, 3011, 3012, 3014, 3017, 3019, 3021, 3022, 3025, 3026, 3028, 3029, 3030, 3032, 3034, 3035, 3036, 3041, 3042, 3048, 3049, 3050, 3055, 3058, 3060, 3062, 3066, 3069, 3070, 3072, 3073, 3074, 3076, 3079, 3080, 3081, 3084, 3086, 3090, 3091, 3092, 3097, 3103, 3110, 3111, 3112, 3119, 3124, 3131, 3132, 3133, 3135, 3139, 3145, 3148, 3153, 3155, 3156, 3158, 3162, 3167, 3171, 3173, 3174, 3177, 3178, 3179, 3180, 3181, 3189, 3190, 3191, 3193, 3198, 3201, 3202, 3203, 3210, 3213, 3214, 3215, 3218, 3223, 3229, 3230, 3231, 3238, 3242, 3244, 3251, 3252, 3254, 3255, 3264, 3268, 3273, 3274, 3279, 3281, 3282, 3283, 3285, 3287, 3288, 3290, 3294, 3296, 3297, 3301, 3302, 3303, 3305, 3307, 3311, 3315, 3316, 3321, 3326, 3327, 3331, 3333, 3335, 3340, 3347, 3349, 3351, 3356, 3357, 3360, 3362, 3364, 3366, 3369, 3370, 3372, 3376, 3378, 3386, 3387, 3389, 3390, 3391, 3392, 3393, 3394, 3402, 3408, 3414, 3416, 3419, 3429, 3430, 3435, 3439, 3441, 3443, 3447, 3451, 3453, 3460, 3461, 3468, 3474, 3482, 3483, 3484, 3486, 3487, 3488, 3492, 3493, 3502, 3503, 3504, 3506, 3507, 3510, 3511, 3518, 3519, 3547, 3548, 3555, 3556, 3562, 3566, 3571, 3575, 3577, 3579, 3582, 3584, 3590, 3591, 3593, 3596, 3602, 3609, 3610, 3611, 3621, 3622, 3627, 3628, 3629, 3631, 3633, 3637, 3638, 3643, 3648, 3656, 3657, 3660, 3661, 3662, 3663, 3664, 3666, 3672, 3674, 3677, 3682, 3686, 3690, 3695, 3697, 3703, 3704, 3706, 3710, 3712, 3713, 3714, 3717, 3718, 3720, 3722, 3723, 3727, 3728, 3735, 3739, 3741, 3743, 3749, 3752, 3753, 3755, 3756, 3757, 3759, 3761, 3767, 3769, 3775, 3782, 3786, 3787, 3789, 3794, 3796, 3798, 3803, 3805, 3807, 3808, 3811, 3812, 3815, 3822, 3823, 3824, 3827, 3831, 3838, 3842, 3845, 3849, 3854, 3856, 3857, 3858, 3862, 3867, 3876, 3882, 3887, 3889, 3890, 3893, 3898, 3900, 3901, 3902, 3909, 3913, 3915, 3918, 3919, 3920, 3922, 3928, 3930, 3933, 3934, 3942, 3946, 3947, 3948, 3953, 3954, 3956, 3962, 3964, 3970, 3971, 3972, 3977, 3978, 3979, 3982, 3986, 3991, 3996, 3997, 4000, 4007, 4008, 4011, 4022, 4025, 4028, 4029, 4036, 4042, 4044, 4046, 4054, 4055, 4060, 4061, 4064, 4068, 4077, 4079, 4081, 4084, 4087, 4092, 4097, 4101, 4102, 4103, 4104, 4106, 4107, 4108, 4109, 4110, 4111, 4121, 4129, 4130, 4131, 4133, 4134, 4137, 4138, 4141, 4142, 4144, 4146, 4147, 4149, 4154, 4156, 4161, 4169, 4172, 4181, 4182, 4184, 4188, 4194, 4200, 4203, 4208, 4209, 4216, 4218, 4219, 4227, 4230, 4231, 4243, 4252, 4258, 4259, 4262, 4265, 4267, 4268, 4273, 4274, 4275, 4277, 4280, 4281, 4283, 4284, 4289, 4292, 4293, 4294, 4295, 4297, 4298, 4299, 4301, 4307, 4308, 4311, 4312, 4313, 4316, 4317, 4323, 4325, 4326, 4329, 4332, 4337, 4339, 4344, 4351, 4356, 4357, 4362, 4365, 4367, 4371, 4373, 4375, 4380, 4381, 4382, 4385, 4387, 4389, 4391, 4392, 4393, 4399, 4400, 4401, 4403, 4407, 4417, 4424, 4425, 4426, 4434, 4435, 4442, 4445, 4446, 4449, 4452, 4454, 4459, 4461, 4464, 4465, 4467, 4470, 4472, 4477, 4478, 4479, 4482, 4486, 4487, 4488, 4489, 4491, 4492, 4498, 4500, 4502, 4508, 4509, 4510, 4511, 4515, 4517, 4522, 4526, 4527, 4536, 4537, 4542, 4550, 4552, 4556, 4557, 4560, 4561, 4562, 4563, 4564, 4567, 4568, 4571, 4572, 4576, 4577, 4582, 4591, 4592, 4593, 4594, 4597, 4600, 4602, 4605, 4608, 4611, 4612, 4614, 4618, 4619, 4620, 4622, 4625, 4629, 4633, 4635, 4636, 4658, 4660, 4661, 4662, 4664, 4665, 4666, 4668, 4669, 4670, 4671, 4673, 4677, 4678, 4681, 4683, 4686, 4690, 4695, 4697, 4699, 4702, 4703, 4704, 4705, 4706, 4709, 4711, 4713, 4714, 4717, 4719, 4725, 4728, 4744, 4753, 4755, 4756, 4757, 4762, 4765, 4767, 4768, 4771, 4773, 4775, 4778, 4782, 4785, 4791, 4792, 4799, 4800, 4804, 4808, 4814, 4816, 4818, 4819, 4824, 4825, 4832, 4833, 4841, 4851, 4853, 4857, 4858, 4863, 4865, 4868, 4873, 4874, 4877, 4878, 4879, 4886, 4887, 4888, 4889, 4890, 4892, 4893, 4896, 4899, 4900, 4901, 4902, 4905, 4910, 4916, 4917, 4926, 4927, 4930, 4932, 4948, 4949, 4952, 4955, 4958, 4959, 4960, 4963, 4964, 4968, 4970, 4975, 4980, 4986, 4999, 5000, 5007, 5013, 5014, 5016, 5026, 5030, 5034, 5038, 5042, 5044, 5045, 5051, 5055, 5058, 5059, 5062, 5063, 5069, 5071, 5073, 5074, 5076, 5086, 5089, 5090, 5100, 5101, 5102, 5104, 5105, 5107, 5108, 5111, 5115, 5119, 5121, 5125, 5129, 5134, 5139, 5140, 5141, 5143, 5145, 5147, 5153, 5155, 5156, 5160, 5163, 5168, 5170, 5173, 5180, 5182, 5183, 5186, 5187, 5190, 5191, 5195, 5203, 5208, 5210, 5216, 5223, 5225, 5227, 5229, 5230, 5231, 5232, 5235, 5242, 5247, 5248, 5250, 5252, 5253, 5254, 5259, 5261, 5262, 5263, 5264, 5265, 5267, 5269, 5270, 5272, 5273, 5275, 5276, 5278, 5279, 5283, 5284, 5285, 5286, 5290, 5292, 5293, 5301, 5304, 5305, 5306, 5312, 5316, 5319, 5320, 5324, 5325, 5328, 5331, 5337, 5340, 5342, 5346, 5348, 5352, 5354, 5355, 5360, 5361, 5363, 5364, 5366, 5367, 5371, 5375, 5377, 5378, 5380, 5381, 5383, 5386, 5389, 5392, 5396, 5401, 5403, 5408, 5410, 5411, 5412, 5413, 5415, 5417, 5420, 5421, 5422, 5423, 5426, 5427, 5428, 5431, 5433, 5436, 5437, 5438, 5439, 5442, 5445, 5447, 5452, 5455, 5456, 5459, 5460, 5463, 5466, 5467, 5473, 5474, 5480, 5481, 5487, 5488, 5489, 5493, 5495, 5499, 5503, 5504, 5505, 5510, 5514, 5515, 5516, 5518, 5519, 5522, 5531, 5542, 5545, 5548, 5551, 5559, 5560, 5563, 5566, 5569, 5570, 5572, 5575, 5577, 5578, 5579, 5581, 5585, 5587, 5588, 5589, 5590, 5591, 5594, 5600, 5605, 5608, 5611, 5612, 5613, 5614, 5615, 5617, 5618, 5628, 5630, 5635, 5638, 5639, 5641, 5643, 5648, 5651, 5652, 5653, 5660, 5662, 5664, 5666, 5671, 5672, 5674, 5675, 5680, 5683, 5686, 5687, 5689, 5690, 5694, 5695, 5699, 5700, 5701, 5703, 5704, 5705, 5706, 5711, 5712, 5713, 5717, 5719, 5722, 5724, 5729, 5731, 5734, 5735, 5739, 5742, 5743, 5746, 5747, 5749, 5750, 5752, 5754, 5762, 5763, 5764, 5766, 5769, 5772, 5775, 5780, 5783, 5784, 5786, 5787, 5789, 5794, 5798, 5807, 5809, 5811, 5814, 5815, 5820, 5821, 5824, 5827, 5831, 5836, 5846, 5848, 5852, 5853, 5855, 5860, 5866, 5869, 5870, 5878, 5879, 5880, 5884, 5885, 5886, 5887, 5890, 5891, 5892, 5899, 5902, 5903, 5904, 5907, 5915, 5925, 5927, 5929, 5933, 5936, 5941, 5943, 5945, 5946, 5951, 5952, 5953, 5955, 5958, 5959, 5970, 5975, 5982, 5985, 5993, 5994, 5996, 5998, 6003, 6004, 6006, 6007, 6010, 6016, 6024, 6026, 6030, 6035, 6038, 6039, 6046, 6049, 6055, 6058, 6062, 6064, 6066, 6067, 6069, 6070, 6072, 6076, 6078, 6081, 6085, 6088, 6099, 6112, 6115, 6120, 6121, 6128, 6132, 6133, 6138, 6148, 6151, 6159, 6160, 6161, 6164, 6166, 6167, 6168, 6169, 6170, 6180, 6181, 6182, 6185, 6189, 6200, 6203, 6205, 6207, 6208, 6210, 6212, 6213, 6214, 6215, 6216, 6217, 6222, 6226, 6229, 6232, 6236, 6237, 6239, 6240, 6247, 6248, 6249, 6250, 6251, 6252, 6257, 6261, 6264, 6277, 6278, 6283, 6284, 6290, 6293, 6295, 6296, 6297, 6300, 6301, 6302, 6304, 6306, 6308, 6310, 6312, 6313, 6314, 6323, 6324, 6326, 6333, 6341, 6342, 6344, 6347, 6348, 6350, 6353, 6355, 6357, 6361, 6366, 6368, 6371, 6376, 6377, 6379, 6384, 6388, 6391, 6392, 6394, 6395, 6396, 6402, 6405, 6406, 6409, 6419, 6420, 6426, 6428, 6431, 6433, 6434, 6435, 6438, 6441, 6450, 6451, 6454, 6456, 6458, 6461, 6462, 6472, 6473, 6475, 6477, 6479, 6480, 6483, 6488, 6490, 6508, 6510, 6511, 6519, 6520, 6522, 6523, 6525, 6527, 6529, 6532, 6537, 6540, 6541, 6542, 6543, 6546, 6547, 6549, 6550, 6552, 6555, 6556, 6561, 6564, 6571, 6573, 6575, 6578, 6579, 6581, 6582, 6593, 6594, 6597, 6601, 6603, 6605, 6606, 6608, 6612, 6614, 6626, 6631, 6634, 6636, 6640, 6642, 6646, 6652, 6657, 6667, 6671, 6672, 6675, 6676, 6678, 6679, 6680, 6683, 6686, 6687, 6688, 6690, 6703, 6705, 6709, 6712, 6713, 6714, 6716, 6717, 6718, 6720, 6721, 6724, 6728, 6729, 6734, 6737, 6741, 6745, 6747, 6754, 6755, 6757, 6765, 6770, 6771, 6776, 6781, 6784, 6792, 6799, 6802, 6804, 6811, 6814, 6815, 6817, 6819, 6822, 6823, 6824, 6826, 6832, 6833, 6839, 6841, 6851, 6852, 6856, 6857, 6860, 6864, 6868, 6869, 6871, 6872, 6879, 6883, 6886, 6888, 6895, 6905, 6908, 6909, 6910, 6918, 6922, 6924, 6925, 6926, 6927, 6928, 6931, 6932, 6938, 6939, 6944, 6949, 6950, 6954, 6960, 6965, 6970, 6972, 6976, 6977, 6982, 6985, 6990, 6997, 6998, 7000, 7002, 7008, 7010, 7012, 7014, 7020, 7022, 7025, 7026, 7027, 7033, 7034, 7035, 7036, 7038, 7040, 7042, 7046, 7051, 7053, 7054, 7055, 7060, 7064, 7068, 7072, 7073, 7077, 7079, 7082, 7088, 7092, 7095, 7099, 7102, 7112, 7113, 7117, 7120, 7122, 7126, 7131, 7132, 7134, 7136, 7145, 7149, 7153, 7161, 7164, 7167, 7169, 7170, 7171, 7174, 7176, 7177, 7182, 7183, 7187, 7189, 7193, 7195, 7197, 7199, 7203, 7208, 7211, 7218, 7223, 7224, 7228, 7231, 7235, 7243, 7244, 7252, 7253, 7259, 7262, 7265, 7266, 7267, 7277, 7284, 7287, 7290, 7294, 7298, 7300, 7301, 7305, 7308, 7311, 7312, 7318, 7323, 7326, 7333, 7338, 7345, 7350, 7352, 7356, 7358, 7361, 7362, 7368, 7369, 7370, 7373, 7374, 7380, 7381, 7383, 7388, 7393, 7396, 7397, 7400, 7402, 7404, 7408, 7412, 7413, 7414, 7415, 7416, 7417, 7422, 7426, 7428, 7429, 7434, 7435, 7436, 7438, 7440, 7441, 7448, 7452, 7455, 7456, 7457, 7458, 7466, 7474]\n",
      "Number of images in class 0: 2492\n",
      "\n",
      "Class: 1 (Total images: 2492)\n",
      "Indices:  [1, 8, 11, 12, 17, 19, 21, 22, 26, 28, 29, 31, 33, 34, 36, 37, 43, 46, 49, 55, 59, 68, 75, 79, 80, 86, 87, 89, 95, 96, 97, 98, 103, 109, 114, 115, 125, 131, 135, 138, 141, 143, 144, 148, 153, 156, 158, 160, 164, 168, 171, 177, 178, 180, 183, 184, 185, 190, 193, 198, 202, 206, 207, 210, 214, 216, 221, 222, 223, 229, 231, 232, 233, 235, 236, 237, 241, 244, 245, 246, 248, 250, 251, 256, 257, 259, 275, 277, 280, 282, 284, 289, 297, 300, 304, 306, 308, 309, 311, 312, 313, 315, 321, 322, 330, 336, 341, 342, 346, 348, 351, 353, 355, 358, 359, 360, 363, 367, 368, 369, 370, 374, 376, 379, 381, 386, 388, 389, 390, 401, 402, 406, 412, 413, 415, 417, 419, 420, 422, 423, 424, 426, 428, 431, 435, 436, 438, 445, 448, 451, 455, 458, 461, 464, 468, 469, 474, 476, 484, 486, 492, 494, 499, 512, 516, 521, 525, 529, 531, 532, 534, 541, 542, 543, 544, 550, 555, 556, 561, 563, 565, 568, 571, 573, 574, 575, 579, 581, 589, 590, 591, 592, 594, 598, 609, 610, 612, 613, 614, 615, 616, 617, 625, 626, 632, 634, 641, 648, 649, 651, 659, 660, 662, 663, 665, 669, 670, 674, 678, 682, 686, 688, 701, 703, 704, 707, 708, 711, 714, 718, 719, 720, 721, 723, 724, 726, 727, 728, 729, 730, 731, 733, 738, 740, 742, 747, 748, 749, 753, 758, 760, 761, 766, 770, 773, 779, 783, 785, 788, 790, 795, 802, 804, 806, 807, 808, 810, 816, 817, 819, 825, 829, 833, 835, 845, 847, 848, 850, 855, 856, 861, 862, 864, 869, 870, 873, 875, 877, 878, 879, 880, 882, 883, 888, 890, 892, 893, 894, 896, 897, 900, 905, 906, 911, 921, 924, 927, 928, 929, 933, 936, 938, 942, 946, 948, 950, 952, 955, 956, 957, 958, 959, 965, 969, 972, 974, 977, 992, 993, 998, 1005, 1006, 1008, 1009, 1010, 1013, 1014, 1016, 1018, 1022, 1023, 1024, 1026, 1027, 1029, 1031, 1032, 1036, 1038, 1040, 1046, 1064, 1069, 1073, 1074, 1076, 1077, 1078, 1079, 1080, 1085, 1089, 1096, 1097, 1104, 1108, 1114, 1115, 1117, 1119, 1133, 1135, 1136, 1137, 1141, 1146, 1148, 1151, 1153, 1154, 1156, 1157, 1158, 1160, 1164, 1168, 1170, 1175, 1176, 1178, 1180, 1187, 1189, 1193, 1195, 1200, 1204, 1209, 1216, 1217, 1223, 1224, 1228, 1234, 1236, 1238, 1248, 1252, 1258, 1263, 1269, 1273, 1274, 1278, 1281, 1283, 1287, 1290, 1291, 1293, 1297, 1298, 1300, 1301, 1305, 1306, 1308, 1309, 1310, 1320, 1323, 1330, 1333, 1335, 1338, 1339, 1341, 1343, 1353, 1354, 1357, 1360, 1365, 1368, 1373, 1376, 1378, 1382, 1384, 1385, 1388, 1390, 1393, 1396, 1399, 1400, 1403, 1405, 1406, 1407, 1408, 1416, 1419, 1420, 1426, 1432, 1434, 1436, 1439, 1440, 1442, 1447, 1449, 1453, 1457, 1461, 1462, 1464, 1469, 1470, 1475, 1478, 1479, 1482, 1484, 1487, 1489, 1494, 1498, 1501, 1506, 1510, 1516, 1522, 1525, 1532, 1533, 1536, 1537, 1539, 1540, 1542, 1543, 1544, 1546, 1548, 1551, 1557, 1562, 1563, 1564, 1565, 1573, 1581, 1583, 1584, 1585, 1586, 1588, 1589, 1606, 1607, 1608, 1633, 1641, 1643, 1644, 1645, 1647, 1656, 1661, 1662, 1666, 1669, 1674, 1676, 1680, 1693, 1697, 1706, 1709, 1710, 1713, 1720, 1721, 1733, 1736, 1737, 1738, 1740, 1746, 1749, 1750, 1757, 1758, 1761, 1764, 1767, 1773, 1774, 1777, 1787, 1790, 1792, 1795, 1796, 1803, 1805, 1809, 1810, 1811, 1815, 1816, 1818, 1821, 1822, 1824, 1827, 1828, 1829, 1830, 1831, 1833, 1837, 1838, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1853, 1857, 1859, 1862, 1864, 1866, 1868, 1870, 1871, 1872, 1873, 1874, 1879, 1880, 1882, 1894, 1897, 1908, 1911, 1916, 1917, 1919, 1921, 1923, 1924, 1928, 1932, 1934, 1935, 1940, 1944, 1946, 1947, 1949, 1953, 1958, 1959, 1962, 1963, 1964, 1971, 1973, 1974, 1976, 1977, 1981, 1983, 1986, 1995, 2000, 2002, 2006, 2010, 2017, 2020, 2024, 2026, 2029, 2032, 2034, 2037, 2039, 2042, 2045, 2048, 2054, 2055, 2057, 2062, 2065, 2067, 2071, 2072, 2073, 2075, 2076, 2077, 2080, 2091, 2092, 2093, 2103, 2104, 2108, 2109, 2111, 2112, 2113, 2114, 2115, 2117, 2118, 2120, 2122, 2123, 2127, 2128, 2129, 2130, 2132, 2133, 2134, 2137, 2140, 2143, 2144, 2145, 2147, 2152, 2154, 2156, 2158, 2159, 2161, 2163, 2165, 2172, 2174, 2177, 2179, 2180, 2184, 2185, 2187, 2189, 2190, 2191, 2192, 2193, 2196, 2198, 2202, 2204, 2205, 2206, 2207, 2208, 2210, 2219, 2220, 2223, 2224, 2225, 2233, 2237, 2239, 2241, 2245, 2247, 2248, 2249, 2250, 2254, 2258, 2259, 2260, 2263, 2269, 2271, 2272, 2273, 2275, 2279, 2280, 2285, 2291, 2297, 2299, 2304, 2308, 2312, 2314, 2317, 2319, 2321, 2323, 2324, 2330, 2331, 2332, 2336, 2337, 2338, 2342, 2343, 2347, 2349, 2352, 2361, 2364, 2365, 2366, 2374, 2378, 2382, 2386, 2388, 2394, 2399, 2400, 2402, 2403, 2406, 2407, 2410, 2414, 2419, 2421, 2424, 2425, 2426, 2427, 2431, 2437, 2438, 2441, 2443, 2444, 2447, 2449, 2453, 2456, 2459, 2462, 2463, 2471, 2472, 2473, 2474, 2482, 2483, 2485, 2486, 2488, 2489, 2496, 2500, 2501, 2505, 2509, 2525, 2527, 2530, 2532, 2533, 2535, 2537, 2540, 2544, 2545, 2547, 2549, 2550, 2553, 2555, 2556, 2558, 2559, 2561, 2563, 2566, 2568, 2569, 2570, 2571, 2576, 2578, 2580, 2587, 2589, 2594, 2596, 2597, 2598, 2601, 2602, 2604, 2609, 2614, 2618, 2620, 2621, 2625, 2629, 2631, 2632, 2638, 2639, 2641, 2648, 2649, 2652, 2653, 2660, 2662, 2663, 2674, 2676, 2677, 2685, 2690, 2694, 2699, 2706, 2707, 2709, 2712, 2715, 2719, 2721, 2733, 2734, 2742, 2746, 2750, 2754, 2758, 2760, 2765, 2768, 2774, 2777, 2779, 2784, 2785, 2787, 2790, 2791, 2792, 2793, 2797, 2798, 2801, 2802, 2803, 2805, 2807, 2809, 2814, 2817, 2819, 2821, 2824, 2825, 2838, 2839, 2842, 2843, 2849, 2851, 2855, 2856, 2859, 2862, 2864, 2865, 2869, 2881, 2884, 2885, 2886, 2894, 2895, 2897, 2899, 2901, 2903, 2912, 2915, 2916, 2919, 2920, 2921, 2922, 2926, 2930, 2936, 2937, 2941, 2944, 2957, 2961, 2967, 2969, 2972, 2974, 2975, 2982, 2988, 2994, 2996, 2997, 3004, 3006, 3007, 3008, 3009, 3010, 3016, 3020, 3031, 3033, 3037, 3038, 3044, 3047, 3051, 3052, 3053, 3056, 3057, 3059, 3063, 3071, 3075, 3082, 3083, 3085, 3087, 3093, 3095, 3098, 3100, 3104, 3105, 3106, 3115, 3117, 3118, 3120, 3123, 3125, 3128, 3129, 3130, 3134, 3138, 3142, 3146, 3147, 3151, 3154, 3161, 3163, 3165, 3168, 3172, 3187, 3188, 3195, 3197, 3205, 3206, 3208, 3211, 3212, 3216, 3221, 3222, 3224, 3225, 3226, 3232, 3237, 3240, 3241, 3243, 3247, 3248, 3249, 3253, 3257, 3258, 3262, 3266, 3267, 3270, 3272, 3275, 3277, 3280, 3284, 3286, 3289, 3291, 3292, 3293, 3295, 3306, 3308, 3309, 3312, 3322, 3323, 3324, 3328, 3332, 3337, 3341, 3342, 3348, 3350, 3354, 3355, 3359, 3373, 3381, 3383, 3385, 3395, 3397, 3398, 3400, 3403, 3405, 3407, 3411, 3412, 3417, 3423, 3424, 3425, 3426, 3432, 3433, 3440, 3442, 3444, 3449, 3454, 3456, 3458, 3459, 3463, 3464, 3469, 3470, 3471, 3476, 3478, 3479, 3480, 3481, 3489, 3490, 3495, 3496, 3497, 3498, 3499, 3500, 3505, 3509, 3514, 3516, 3520, 3524, 3527, 3529, 3530, 3532, 3534, 3538, 3542, 3543, 3550, 3552, 3554, 3557, 3560, 3564, 3565, 3567, 3568, 3569, 3570, 3572, 3573, 3574, 3576, 3580, 3581, 3583, 3587, 3588, 3589, 3592, 3595, 3597, 3599, 3600, 3603, 3606, 3613, 3614, 3615, 3616, 3617, 3623, 3625, 3626, 3630, 3634, 3635, 3640, 3644, 3645, 3649, 3650, 3652, 3653, 3654, 3655, 3658, 3659, 3673, 3675, 3676, 3678, 3681, 3689, 3692, 3693, 3694, 3696, 3699, 3701, 3705, 3707, 3708, 3711, 3715, 3721, 3724, 3725, 3729, 3730, 3736, 3740, 3744, 3745, 3748, 3750, 3754, 3758, 3760, 3763, 3764, 3765, 3766, 3770, 3771, 3780, 3783, 3784, 3790, 3791, 3801, 3804, 3806, 3813, 3814, 3817, 3821, 3825, 3829, 3830, 3832, 3835, 3841, 3843, 3844, 3847, 3850, 3851, 3853, 3859, 3860, 3861, 3863, 3864, 3865, 3869, 3870, 3871, 3874, 3875, 3877, 3879, 3881, 3883, 3884, 3888, 3891, 3894, 3896, 3899, 3904, 3905, 3907, 3908, 3916, 3923, 3924, 3925, 3926, 3929, 3931, 3932, 3935, 3936, 3938, 3939, 3940, 3941, 3943, 3945, 3958, 3959, 3960, 3961, 3963, 3965, 3966, 3969, 3973, 3975, 3987, 3990, 3992, 3994, 3995, 3998, 4001, 4002, 4003, 4004, 4005, 4006, 4010, 4013, 4015, 4017, 4019, 4020, 4021, 4026, 4027, 4030, 4031, 4032, 4034, 4035, 4038, 4041, 4045, 4047, 4048, 4050, 4053, 4062, 4063, 4065, 4066, 4067, 4070, 4071, 4072, 4073, 4074, 4078, 4080, 4085, 4090, 4094, 4095, 4099, 4105, 4116, 4120, 4122, 4126, 4128, 4132, 4140, 4143, 4148, 4150, 4152, 4153, 4160, 4165, 4166, 4168, 4170, 4171, 4173, 4177, 4179, 4180, 4185, 4186, 4187, 4189, 4193, 4195, 4197, 4199, 4205, 4206, 4210, 4211, 4212, 4215, 4220, 4222, 4224, 4225, 4228, 4229, 4233, 4234, 4244, 4245, 4246, 4247, 4248, 4251, 4253, 4255, 4256, 4260, 4261, 4266, 4269, 4276, 4278, 4285, 4291, 4303, 4304, 4306, 4310, 4315, 4319, 4320, 4322, 4334, 4343, 4347, 4348, 4352, 4354, 4355, 4361, 4369, 4370, 4372, 4376, 4379, 4383, 4388, 4395, 4404, 4406, 4408, 4411, 4421, 4433, 4436, 4437, 4440, 4444, 4450, 4453, 4456, 4457, 4458, 4460, 4463, 4466, 4473, 4474, 4475, 4476, 4480, 4481, 4483, 4485, 4493, 4495, 4497, 4501, 4506, 4513, 4514, 4516, 4518, 4519, 4521, 4524, 4525, 4530, 4531, 4533, 4535, 4540, 4541, 4543, 4546, 4547, 4555, 4558, 4565, 4566, 4570, 4575, 4581, 4583, 4584, 4586, 4587, 4596, 4599, 4606, 4617, 4621, 4623, 4628, 4632, 4634, 4639, 4641, 4642, 4643, 4644, 4646, 4647, 4651, 4653, 4655, 4657, 4659, 4672, 4675, 4676, 4682, 4685, 4687, 4689, 4692, 4693, 4696, 4698, 4708, 4712, 4715, 4716, 4718, 4720, 4721, 4722, 4724, 4729, 4733, 4734, 4735, 4736, 4738, 4741, 4742, 4745, 4746, 4748, 4749, 4750, 4752, 4769, 4770, 4777, 4783, 4787, 4789, 4790, 4794, 4797, 4798, 4801, 4802, 4803, 4806, 4810, 4811, 4812, 4813, 4817, 4826, 4827, 4828, 4830, 4836, 4837, 4840, 4844, 4845, 4849, 4864, 4867, 4869, 4870, 4871, 4875, 4881, 4882, 4884, 4885, 4894, 4897, 4906, 4908, 4913, 4914, 4915, 4918, 4919, 4920, 4924, 4925, 4928, 4931, 4934, 4938, 4942, 4943, 4945, 4947, 4950, 4951, 4956, 4965, 4966, 4971, 4972, 4974, 4982, 4989, 4990, 4993, 4997, 5001, 5002, 5004, 5009, 5010, 5012, 5015, 5017, 5018, 5021, 5023, 5027, 5031, 5035, 5039, 5040, 5043, 5049, 5050, 5052, 5053, 5054, 5060, 5066, 5067, 5070, 5075, 5077, 5080, 5081, 5082, 5084, 5085, 5087, 5088, 5094, 5095, 5103, 5109, 5110, 5113, 5114, 5116, 5117, 5124, 5127, 5130, 5131, 5135, 5137, 5144, 5148, 5149, 5150, 5151, 5152, 5154, 5157, 5158, 5159, 5161, 5162, 5164, 5165, 5166, 5169, 5171, 5172, 5176, 5179, 5184, 5189, 5192, 5193, 5197, 5200, 5201, 5206, 5207, 5213, 5214, 5221, 5222, 5224, 5226, 5234, 5236, 5238, 5241, 5243, 5245, 5249, 5251, 5256, 5257, 5258, 5277, 5281, 5282, 5288, 5291, 5295, 5296, 5298, 5299, 5302, 5307, 5309, 5311, 5315, 5318, 5321, 5322, 5323, 5330, 5332, 5336, 5338, 5339, 5341, 5343, 5344, 5345, 5347, 5351, 5353, 5365, 5369, 5370, 5372, 5374, 5376, 5379, 5382, 5384, 5385, 5388, 5390, 5395, 5398, 5399, 5400, 5418, 5424, 5434, 5435, 5440, 5443, 5444, 5446, 5449, 5454, 5461, 5468, 5469, 5475, 5476, 5478, 5491, 5492, 5494, 5496, 5497, 5498, 5501, 5502, 5506, 5507, 5511, 5520, 5521, 5523, 5527, 5528, 5530, 5533, 5535, 5537, 5538, 5540, 5544, 5550, 5552, 5553, 5554, 5555, 5556, 5557, 5562, 5567, 5568, 5576, 5582, 5592, 5596, 5597, 5598, 5601, 5602, 5616, 5619, 5621, 5622, 5623, 5624, 5629, 5631, 5632, 5636, 5640, 5642, 5646, 5655, 5659, 5661, 5663, 5665, 5668, 5670, 5676, 5679, 5684, 5688, 5691, 5693, 5696, 5697, 5698, 5702, 5710, 5714, 5715, 5716, 5720, 5721, 5723, 5728, 5732, 5738, 5744, 5745, 5748, 5753, 5755, 5756, 5757, 5758, 5761, 5765, 5767, 5771, 5776, 5782, 5785, 5788, 5792, 5793, 5796, 5797, 5799, 5800, 5801, 5805, 5806, 5812, 5813, 5819, 5822, 5823, 5825, 5826, 5828, 5830, 5832, 5835, 5840, 5841, 5851, 5854, 5858, 5859, 5862, 5864, 5867, 5868, 5871, 5873, 5874, 5888, 5889, 5894, 5895, 5896, 5898, 5901, 5908, 5909, 5911, 5912, 5913, 5914, 5919, 5921, 5922, 5923, 5926, 5930, 5931, 5934, 5937, 5944, 5949, 5950, 5954, 5957, 5961, 5962, 5963, 5964, 5965, 5966, 5967, 5968, 5969, 5971, 5972, 5973, 5987, 5988, 5989, 5991, 5992, 5995, 5999, 6000, 6001, 6002, 6005, 6009, 6012, 6013, 6014, 6022, 6023, 6029, 6031, 6032, 6036, 6037, 6040, 6041, 6042, 6043, 6045, 6048, 6053, 6057, 6060, 6063, 6065, 6071, 6074, 6079, 6080, 6082, 6084, 6089, 6090, 6096, 6097, 6100, 6101, 6105, 6108, 6118, 6119, 6122, 6123, 6126, 6127, 6130, 6131, 6134, 6135, 6137, 6140, 6141, 6142, 6143, 6147, 6149, 6153, 6154, 6156, 6157, 6158, 6162, 6172, 6173, 6177, 6178, 6184, 6186, 6187, 6188, 6192, 6197, 6199, 6202, 6204, 6209, 6211, 6223, 6227, 6228, 6230, 6231, 6233, 6235, 6238, 6241, 6244, 6245, 6246, 6255, 6256, 6258, 6260, 6265, 6269, 6270, 6272, 6274, 6276, 6279, 6282, 6285, 6286, 6289, 6298, 6307, 6309, 6311, 6315, 6316, 6319, 6321, 6322, 6332, 6334, 6338, 6340, 6345, 6351, 6352, 6354, 6358, 6359, 6362, 6363, 6364, 6369, 6372, 6373, 6378, 6381, 6385, 6386, 6389, 6398, 6399, 6401, 6410, 6413, 6415, 6418, 6423, 6425, 6427, 6429, 6430, 6432, 6436, 6440, 6444, 6445, 6446, 6447, 6448, 6460, 6465, 6467, 6470, 6471, 6474, 6478, 6481, 6482, 6491, 6492, 6493, 6494, 6496, 6499, 6500, 6501, 6503, 6504, 6506, 6509, 6512, 6513, 6514, 6517, 6518, 6521, 6528, 6530, 6531, 6533, 6534, 6535, 6536, 6538, 6539, 6544, 6545, 6548, 6554, 6559, 6567, 6568, 6569, 6574, 6576, 6577, 6585, 6586, 6588, 6589, 6595, 6596, 6600, 6602, 6607, 6610, 6613, 6616, 6621, 6622, 6623, 6624, 6625, 6627, 6633, 6635, 6638, 6639, 6643, 6644, 6645, 6647, 6651, 6654, 6661, 6662, 6663, 6664, 6666, 6681, 6685, 6689, 6694, 6696, 6697, 6698, 6699, 6700, 6701, 6704, 6707, 6710, 6711, 6715, 6723, 6726, 6730, 6731, 6738, 6739, 6740, 6743, 6744, 6749, 6751, 6756, 6758, 6759, 6761, 6762, 6763, 6764, 6767, 6768, 6769, 6772, 6773, 6774, 6780, 6786, 6789, 6790, 6794, 6795, 6796, 6797, 6803, 6805, 6807, 6808, 6810, 6812, 6813, 6816, 6820, 6821, 6825, 6829, 6830, 6834, 6835, 6836, 6838, 6840, 6842, 6847, 6848, 6850, 6853, 6858, 6861, 6865, 6866, 6867, 6870, 6873, 6874, 6880, 6884, 6889, 6892, 6897, 6900, 6901, 6902, 6904, 6906, 6907, 6911, 6912, 6914, 6916, 6917, 6921, 6923, 6929, 6936, 6940, 6945, 6946, 6948, 6951, 6955, 6957, 6959, 6962, 6963, 6964, 6971, 6973, 6974, 6975, 6978, 6980, 6986, 6987, 6989, 6991, 6992, 6993, 6994, 7003, 7006, 7007, 7009, 7011, 7013, 7015, 7017, 7018, 7019, 7028, 7029, 7032, 7041, 7044, 7049, 7052, 7056, 7058, 7059, 7061, 7067, 7070, 7074, 7080, 7081, 7084, 7086, 7093, 7100, 7103, 7104, 7105, 7106, 7107, 7108, 7110, 7115, 7116, 7118, 7119, 7123, 7124, 7125, 7127, 7130, 7135, 7137, 7139, 7140, 7141, 7146, 7147, 7155, 7156, 7162, 7168, 7172, 7173, 7181, 7184, 7185, 7186, 7188, 7192, 7196, 7198, 7200, 7201, 7202, 7204, 7205, 7210, 7215, 7221, 7222, 7226, 7227, 7229, 7230, 7232, 7237, 7238, 7241, 7242, 7245, 7247, 7248, 7249, 7256, 7258, 7263, 7271, 7274, 7275, 7276, 7279, 7280, 7282, 7283, 7288, 7289, 7296, 7299, 7306, 7309, 7313, 7314, 7319, 7321, 7325, 7327, 7329, 7331, 7335, 7339, 7341, 7343, 7351, 7355, 7357, 7364, 7366, 7367, 7375, 7376, 7377, 7378, 7382, 7387, 7389, 7391, 7392, 7394, 7395, 7398, 7401, 7403, 7410, 7411, 7420, 7423, 7424, 7425, 7430, 7431, 7432, 7437, 7439, 7442, 7443, 7445, 7446, 7447, 7459, 7460, 7461, 7464, 7469, 7470]\n",
      "Number of images in class 1: 2492\n",
      "\n",
      "Class: 2 (Total images: 2492)\n",
      "Indices:  [7, 13, 15, 23, 24, 39, 40, 41, 42, 47, 48, 50, 51, 52, 57, 58, 60, 62, 65, 69, 73, 76, 81, 82, 84, 88, 91, 92, 99, 102, 104, 105, 106, 107, 108, 112, 119, 121, 122, 126, 132, 133, 136, 137, 142, 145, 147, 150, 154, 155, 162, 163, 165, 169, 170, 173, 181, 182, 187, 188, 189, 192, 194, 195, 197, 199, 201, 203, 205, 208, 209, 212, 213, 215, 217, 220, 224, 228, 240, 253, 258, 260, 263, 264, 265, 267, 269, 274, 281, 285, 287, 291, 292, 294, 295, 296, 299, 301, 302, 307, 314, 323, 325, 326, 328, 332, 337, 338, 339, 349, 362, 364, 365, 372, 373, 382, 383, 384, 385, 395, 397, 398, 400, 404, 405, 407, 410, 411, 414, 418, 421, 427, 429, 432, 433, 437, 441, 442, 444, 447, 449, 450, 452, 454, 457, 459, 460, 463, 466, 470, 472, 473, 480, 487, 488, 498, 500, 502, 505, 507, 509, 510, 517, 518, 520, 522, 527, 528, 535, 536, 537, 546, 549, 552, 554, 558, 559, 560, 564, 578, 582, 586, 587, 593, 595, 596, 597, 599, 601, 603, 605, 606, 607, 622, 628, 630, 633, 636, 642, 644, 645, 646, 647, 652, 653, 654, 655, 658, 661, 664, 667, 668, 672, 673, 679, 685, 687, 689, 691, 693, 694, 697, 698, 699, 713, 717, 725, 735, 736, 737, 739, 743, 744, 745, 750, 754, 755, 762, 763, 765, 767, 771, 772, 776, 777, 778, 780, 782, 789, 791, 794, 797, 799, 800, 803, 805, 811, 812, 813, 815, 820, 826, 827, 834, 838, 851, 852, 854, 865, 867, 872, 881, 884, 885, 886, 891, 895, 898, 899, 901, 903, 910, 913, 914, 915, 916, 919, 922, 925, 930, 934, 935, 939, 940, 944, 947, 949, 953, 954, 960, 961, 964, 966, 967, 968, 971, 975, 976, 980, 981, 983, 984, 985, 986, 991, 994, 995, 999, 1000, 1002, 1011, 1017, 1019, 1025, 1033, 1034, 1037, 1039, 1041, 1042, 1049, 1051, 1054, 1055, 1056, 1057, 1058, 1060, 1061, 1068, 1070, 1081, 1082, 1083, 1084, 1086, 1088, 1092, 1093, 1099, 1100, 1101, 1105, 1107, 1110, 1116, 1121, 1124, 1125, 1126, 1131, 1132, 1138, 1139, 1149, 1150, 1155, 1161, 1165, 1173, 1174, 1177, 1181, 1182, 1183, 1185, 1186, 1188, 1191, 1192, 1194, 1197, 1198, 1199, 1201, 1202, 1206, 1207, 1208, 1212, 1213, 1214, 1215, 1219, 1220, 1225, 1226, 1229, 1233, 1235, 1243, 1244, 1245, 1246, 1253, 1259, 1265, 1266, 1267, 1277, 1284, 1285, 1286, 1296, 1299, 1304, 1311, 1312, 1315, 1319, 1322, 1325, 1327, 1331, 1332, 1334, 1336, 1340, 1344, 1345, 1346, 1347, 1348, 1350, 1352, 1355, 1358, 1361, 1363, 1366, 1369, 1377, 1380, 1386, 1394, 1401, 1404, 1409, 1411, 1413, 1414, 1415, 1417, 1422, 1423, 1427, 1428, 1435, 1438, 1441, 1445, 1448, 1450, 1451, 1452, 1456, 1458, 1459, 1460, 1463, 1467, 1471, 1474, 1476, 1477, 1480, 1483, 1485, 1486, 1488, 1490, 1497, 1509, 1513, 1517, 1524, 1526, 1527, 1528, 1529, 1531, 1538, 1541, 1547, 1550, 1554, 1556, 1569, 1571, 1572, 1574, 1575, 1576, 1577, 1578, 1579, 1582, 1590, 1591, 1592, 1593, 1594, 1595, 1597, 1598, 1599, 1600, 1603, 1604, 1609, 1610, 1614, 1619, 1621, 1622, 1626, 1627, 1628, 1634, 1635, 1636, 1637, 1638, 1639, 1642, 1646, 1648, 1649, 1651, 1654, 1655, 1659, 1663, 1664, 1665, 1667, 1670, 1672, 1673, 1675, 1678, 1681, 1684, 1687, 1690, 1691, 1695, 1699, 1701, 1703, 1708, 1711, 1712, 1714, 1716, 1717, 1718, 1723, 1724, 1726, 1727, 1729, 1731, 1732, 1735, 1741, 1744, 1747, 1751, 1759, 1760, 1763, 1766, 1768, 1770, 1771, 1772, 1776, 1779, 1781, 1782, 1783, 1784, 1785, 1786, 1789, 1802, 1807, 1808, 1812, 1814, 1823, 1836, 1840, 1842, 1844, 1854, 1858, 1860, 1861, 1863, 1865, 1877, 1878, 1881, 1884, 1885, 1886, 1887, 1888, 1889, 1898, 1904, 1905, 1906, 1907, 1912, 1914, 1915, 1920, 1927, 1929, 1930, 1937, 1938, 1942, 1945, 1950, 1952, 1961, 1966, 1968, 1979, 1987, 1988, 1989, 1990, 1993, 1994, 1996, 1997, 1998, 1999, 2001, 2003, 2009, 2016, 2018, 2021, 2027, 2030, 2031, 2035, 2036, 2038, 2041, 2043, 2044, 2046, 2049, 2051, 2052, 2053, 2058, 2074, 2079, 2082, 2084, 2087, 2089, 2094, 2096, 2098, 2100, 2105, 2106, 2116, 2121, 2124, 2125, 2126, 2139, 2142, 2146, 2149, 2151, 2153, 2157, 2160, 2162, 2164, 2166, 2167, 2169, 2171, 2173, 2175, 2178, 2182, 2183, 2188, 2194, 2195, 2197, 2199, 2200, 2201, 2203, 2211, 2212, 2213, 2218, 2231, 2235, 2238, 2240, 2243, 2244, 2253, 2255, 2256, 2261, 2264, 2265, 2266, 2267, 2268, 2274, 2277, 2283, 2284, 2287, 2289, 2290, 2293, 2294, 2295, 2296, 2305, 2309, 2313, 2316, 2322, 2325, 2328, 2335, 2341, 2346, 2348, 2350, 2353, 2354, 2356, 2357, 2359, 2360, 2367, 2369, 2372, 2373, 2376, 2379, 2383, 2384, 2392, 2405, 2408, 2409, 2413, 2417, 2418, 2430, 2432, 2435, 2436, 2439, 2440, 2451, 2452, 2454, 2455, 2457, 2461, 2465, 2467, 2469, 2470, 2476, 2477, 2480, 2481, 2484, 2490, 2493, 2494, 2495, 2497, 2504, 2510, 2511, 2513, 2514, 2517, 2518, 2519, 2520, 2523, 2524, 2526, 2531, 2534, 2536, 2538, 2539, 2541, 2546, 2554, 2557, 2564, 2565, 2572, 2574, 2575, 2584, 2586, 2588, 2590, 2592, 2593, 2595, 2599, 2603, 2605, 2607, 2610, 2611, 2612, 2613, 2615, 2619, 2623, 2624, 2626, 2633, 2634, 2635, 2642, 2644, 2646, 2647, 2650, 2651, 2654, 2655, 2656, 2659, 2661, 2665, 2667, 2668, 2669, 2670, 2671, 2672, 2673, 2675, 2678, 2680, 2683, 2684, 2686, 2693, 2695, 2697, 2698, 2700, 2708, 2711, 2713, 2716, 2717, 2718, 2720, 2722, 2726, 2727, 2730, 2731, 2732, 2738, 2740, 2741, 2743, 2744, 2745, 2749, 2753, 2755, 2756, 2759, 2761, 2762, 2764, 2766, 2770, 2771, 2772, 2773, 2776, 2781, 2783, 2795, 2804, 2806, 2810, 2812, 2813, 2820, 2822, 2823, 2826, 2827, 2828, 2829, 2833, 2840, 2841, 2845, 2850, 2853, 2854, 2857, 2863, 2866, 2868, 2871, 2872, 2876, 2878, 2882, 2889, 2890, 2900, 2904, 2906, 2907, 2908, 2909, 2913, 2918, 2924, 2925, 2927, 2934, 2935, 2940, 2943, 2946, 2947, 2948, 2949, 2953, 2956, 2958, 2959, 2960, 2962, 2966, 2971, 2973, 2976, 2979, 2981, 2983, 2986, 2987, 2990, 2991, 2992, 2999, 3001, 3002, 3003, 3013, 3015, 3018, 3023, 3024, 3027, 3039, 3040, 3043, 3045, 3046, 3054, 3061, 3064, 3065, 3067, 3068, 3077, 3078, 3088, 3089, 3094, 3096, 3099, 3101, 3102, 3107, 3108, 3109, 3113, 3114, 3116, 3121, 3122, 3126, 3127, 3136, 3137, 3140, 3141, 3143, 3144, 3149, 3150, 3152, 3157, 3159, 3160, 3164, 3166, 3169, 3170, 3175, 3176, 3182, 3183, 3184, 3185, 3186, 3192, 3194, 3196, 3199, 3200, 3204, 3207, 3209, 3217, 3219, 3220, 3227, 3228, 3233, 3234, 3235, 3236, 3239, 3245, 3246, 3250, 3256, 3259, 3260, 3261, 3263, 3265, 3269, 3271, 3276, 3278, 3298, 3299, 3300, 3304, 3310, 3313, 3314, 3317, 3318, 3319, 3320, 3325, 3329, 3330, 3334, 3336, 3338, 3339, 3343, 3344, 3345, 3346, 3352, 3353, 3358, 3361, 3363, 3365, 3367, 3368, 3371, 3374, 3375, 3377, 3379, 3380, 3382, 3384, 3388, 3396, 3399, 3401, 3404, 3406, 3409, 3410, 3413, 3415, 3418, 3420, 3421, 3422, 3427, 3428, 3431, 3434, 3436, 3437, 3438, 3445, 3446, 3448, 3450, 3452, 3455, 3457, 3462, 3465, 3466, 3467, 3472, 3473, 3475, 3477, 3485, 3491, 3494, 3501, 3508, 3512, 3513, 3515, 3517, 3521, 3522, 3523, 3525, 3526, 3528, 3531, 3533, 3535, 3536, 3537, 3539, 3540, 3541, 3544, 3545, 3546, 3549, 3551, 3553, 3558, 3559, 3561, 3563, 3578, 3585, 3586, 3594, 3598, 3601, 3604, 3605, 3607, 3608, 3612, 3618, 3619, 3620, 3624, 3632, 3636, 3639, 3641, 3642, 3646, 3647, 3651, 3665, 3667, 3668, 3669, 3670, 3671, 3679, 3680, 3683, 3684, 3685, 3687, 3688, 3691, 3698, 3700, 3702, 3709, 3716, 3719, 3726, 3731, 3732, 3733, 3734, 3737, 3738, 3742, 3746, 3747, 3751, 3762, 3768, 3772, 3773, 3774, 3776, 3777, 3778, 3779, 3781, 3785, 3788, 3792, 3793, 3795, 3797, 3799, 3800, 3802, 3809, 3810, 3816, 3818, 3819, 3820, 3826, 3828, 3833, 3834, 3836, 3837, 3839, 3840, 3846, 3848, 3852, 3855, 3866, 3868, 3872, 3873, 3878, 3880, 3885, 3886, 3892, 3895, 3897, 3903, 3906, 3910, 3911, 3912, 3914, 3917, 3921, 3927, 3937, 3944, 3949, 3950, 3951, 3952, 3955, 3957, 3967, 3968, 3974, 3976, 3980, 3981, 3983, 3984, 3985, 3988, 3989, 3993, 3999, 4009, 4012, 4014, 4016, 4018, 4023, 4024, 4033, 4037, 4039, 4040, 4043, 4049, 4051, 4052, 4056, 4057, 4058, 4059, 4069, 4075, 4076, 4082, 4083, 4086, 4088, 4089, 4091, 4093, 4096, 4098, 4100, 4112, 4113, 4114, 4115, 4117, 4118, 4119, 4123, 4124, 4125, 4127, 4135, 4136, 4139, 4145, 4151, 4155, 4157, 4158, 4159, 4162, 4163, 4164, 4167, 4174, 4175, 4176, 4178, 4183, 4190, 4191, 4192, 4196, 4198, 4201, 4202, 4204, 4207, 4213, 4214, 4217, 4221, 4223, 4226, 4232, 4235, 4236, 4237, 4238, 4239, 4240, 4241, 4242, 4249, 4250, 4254, 4257, 4263, 4264, 4270, 4271, 4272, 4279, 4282, 4286, 4287, 4288, 4290, 4296, 4300, 4302, 4305, 4309, 4314, 4318, 4321, 4324, 4327, 4328, 4330, 4331, 4333, 4335, 4336, 4338, 4340, 4341, 4342, 4345, 4346, 4349, 4350, 4353, 4358, 4359, 4360, 4363, 4364, 4366, 4368, 4374, 4377, 4378, 4384, 4386, 4390, 4394, 4396, 4397, 4398, 4402, 4405, 4409, 4410, 4412, 4413, 4414, 4415, 4416, 4418, 4419, 4420, 4422, 4423, 4427, 4428, 4429, 4430, 4431, 4432, 4438, 4439, 4441, 4443, 4447, 4448, 4451, 4455, 4462, 4468, 4469, 4471, 4484, 4490, 4494, 4496, 4499, 4503, 4504, 4505, 4507, 4512, 4520, 4523, 4528, 4529, 4532, 4534, 4538, 4539, 4544, 4545, 4548, 4549, 4551, 4553, 4554, 4559, 4569, 4573, 4574, 4578, 4579, 4580, 4585, 4588, 4589, 4590, 4595, 4598, 4601, 4603, 4604, 4607, 4609, 4610, 4613, 4615, 4616, 4624, 4626, 4627, 4630, 4631, 4637, 4638, 4640, 4645, 4648, 4649, 4650, 4652, 4654, 4656, 4663, 4667, 4674, 4679, 4680, 4684, 4688, 4691, 4694, 4700, 4701, 4707, 4710, 4723, 4726, 4727, 4730, 4731, 4732, 4737, 4739, 4740, 4743, 4747, 4751, 4754, 4758, 4759, 4760, 4761, 4763, 4764, 4766, 4772, 4774, 4776, 4779, 4780, 4781, 4784, 4786, 4788, 4793, 4795, 4796, 4805, 4807, 4809, 4815, 4820, 4821, 4822, 4823, 4829, 4831, 4834, 4835, 4838, 4839, 4842, 4843, 4846, 4847, 4848, 4850, 4852, 4854, 4855, 4856, 4859, 4860, 4861, 4862, 4866, 4872, 4876, 4880, 4883, 4891, 4895, 4898, 4903, 4904, 4907, 4909, 4911, 4912, 4921, 4922, 4923, 4929, 4933, 4935, 4936, 4937, 4939, 4940, 4941, 4944, 4946, 4953, 4954, 4957, 4961, 4962, 4967, 4969, 4973, 4976, 4977, 4978, 4979, 4981, 4983, 4984, 4985, 4987, 4988, 4991, 4992, 4994, 4995, 4996, 4998, 5003, 5005, 5006, 5008, 5011, 5019, 5020, 5022, 5024, 5025, 5028, 5029, 5032, 5033, 5036, 5037, 5041, 5046, 5047, 5048, 5056, 5057, 5061, 5064, 5065, 5068, 5072, 5078, 5079, 5083, 5091, 5092, 5093, 5096, 5097, 5098, 5099, 5106, 5112, 5118, 5120, 5122, 5123, 5126, 5128, 5132, 5133, 5136, 5138, 5142, 5146, 5167, 5174, 5175, 5177, 5178, 5181, 5185, 5188, 5194, 5196, 5198, 5199, 5202, 5204, 5205, 5209, 5211, 5212, 5215, 5217, 5218, 5219, 5220, 5228, 5233, 5237, 5239, 5240, 5244, 5246, 5255, 5260, 5266, 5268, 5271, 5274, 5280, 5287, 5289, 5294, 5297, 5300, 5303, 5308, 5310, 5313, 5314, 5317, 5326, 5327, 5329, 5333, 5334, 5335, 5349, 5350, 5356, 5357, 5358, 5359, 5362, 5368, 5373, 5387, 5391, 5393, 5394, 5397, 5402, 5404, 5405, 5406, 5407, 5409, 5414, 5416, 5419, 5425, 5429, 5430, 5432, 5441, 5448, 5450, 5451, 5453, 5457, 5458, 5462, 5464, 5465, 5470, 5471, 5472, 5477, 5479, 5482, 5483, 5484, 5485, 5486, 5490, 5500, 5508, 5509, 5512, 5513, 5517, 5524, 5525, 5526, 5529, 5532, 5534, 5536, 5539, 5541, 5543, 5546, 5547, 5549, 5558, 5561, 5564, 5565, 5571, 5573, 5574, 5580, 5583, 5584, 5586, 5593, 5595, 5599, 5603, 5604, 5606, 5607, 5609, 5610, 5620, 5625, 5626, 5627, 5633, 5634, 5637, 5644, 5645, 5647, 5649, 5650, 5654, 5656, 5657, 5658, 5667, 5669, 5673, 5677, 5678, 5681, 5682, 5685, 5692, 5707, 5708, 5709, 5718, 5725, 5726, 5727, 5730, 5733, 5736, 5737, 5740, 5741, 5751, 5759, 5760, 5768, 5770, 5773, 5774, 5777, 5778, 5779, 5781, 5790, 5791, 5795, 5802, 5803, 5804, 5808, 5810, 5816, 5817, 5818, 5829, 5833, 5834, 5837, 5838, 5839, 5842, 5843, 5844, 5845, 5847, 5849, 5850, 5856, 5857, 5861, 5863, 5865, 5872, 5875, 5876, 5877, 5881, 5882, 5883, 5893, 5897, 5900, 5905, 5906, 5910, 5916, 5917, 5918, 5920, 5924, 5928, 5932, 5935, 5938, 5939, 5940, 5942, 5947, 5948, 5956, 5960, 5974, 5976, 5977, 5978, 5979, 5980, 5981, 5983, 5984, 5986, 5990, 5997, 6008, 6011, 6015, 6017, 6018, 6019, 6020, 6021, 6025, 6027, 6028, 6033, 6034, 6044, 6047, 6050, 6051, 6052, 6054, 6056, 6059, 6061, 6068, 6073, 6075, 6077, 6083, 6086, 6087, 6091, 6092, 6093, 6094, 6095, 6098, 6102, 6103, 6104, 6106, 6107, 6109, 6110, 6111, 6113, 6114, 6116, 6117, 6124, 6125, 6129, 6136, 6139, 6144, 6145, 6146, 6150, 6152, 6155, 6163, 6165, 6171, 6174, 6175, 6176, 6179, 6183, 6190, 6191, 6193, 6194, 6195, 6196, 6198, 6201, 6206, 6218, 6219, 6220, 6221, 6224, 6225, 6234, 6242, 6243, 6253, 6254, 6259, 6262, 6263, 6266, 6267, 6268, 6271, 6273, 6275, 6280, 6281, 6287, 6288, 6291, 6292, 6294, 6299, 6303, 6305, 6317, 6318, 6320, 6325, 6327, 6328, 6329, 6330, 6331, 6335, 6336, 6337, 6339, 6343, 6346, 6349, 6356, 6360, 6365, 6367, 6370, 6374, 6375, 6380, 6382, 6383, 6387, 6390, 6393, 6397, 6400, 6403, 6404, 6407, 6408, 6411, 6412, 6414, 6416, 6417, 6421, 6422, 6424, 6437, 6439, 6442, 6443, 6449, 6452, 6453, 6455, 6457, 6459, 6463, 6464, 6466, 6468, 6469, 6476, 6484, 6485, 6486, 6487, 6489, 6495, 6497, 6498, 6502, 6505, 6507, 6515, 6516, 6524, 6526, 6551, 6553, 6557, 6558, 6560, 6562, 6563, 6565, 6566, 6570, 6572, 6580, 6583, 6584, 6587, 6590, 6591, 6592, 6598, 6599, 6604, 6609, 6611, 6615, 6617, 6618, 6619, 6620, 6628, 6629, 6630, 6632, 6637, 6641, 6648, 6649, 6650, 6653, 6655, 6656, 6658, 6659, 6660, 6665, 6668, 6669, 6670, 6673, 6674, 6677, 6682, 6684, 6691, 6692, 6693, 6695, 6702, 6706, 6708, 6719, 6722, 6725, 6727, 6732, 6733, 6735, 6736, 6742, 6746, 6748, 6750, 6752, 6753, 6760, 6766, 6775, 6777, 6778, 6779, 6782, 6783, 6785, 6787, 6788, 6791, 6793, 6798, 6800, 6801, 6806, 6809, 6818, 6827, 6828, 6831, 6837, 6843, 6844, 6845, 6846, 6849, 6854, 6855, 6859, 6862, 6863, 6875, 6876, 6877, 6878, 6881, 6882, 6885, 6887, 6890, 6891, 6893, 6894, 6896, 6898, 6899, 6903, 6913, 6915, 6919, 6920, 6930, 6933, 6934, 6935, 6937, 6941, 6942, 6943, 6947, 6952, 6953, 6956, 6958, 6961, 6966, 6967, 6968, 6969, 6979, 6981, 6983, 6984, 6988, 6995, 6996, 6999, 7001, 7004, 7005, 7016, 7021, 7023, 7024, 7030, 7031, 7037, 7039, 7043, 7045, 7047, 7048, 7050, 7057, 7062, 7063, 7065, 7066, 7069, 7071, 7075, 7076, 7078, 7083, 7085, 7087, 7089, 7090, 7091, 7094, 7096, 7097, 7098, 7101, 7109, 7111, 7114, 7121, 7128, 7129, 7133, 7138, 7142, 7143, 7144, 7148, 7150, 7151, 7152, 7154, 7157, 7158, 7159, 7160, 7163, 7165, 7166, 7175, 7178, 7179, 7180, 7190, 7191, 7194, 7206, 7207, 7209, 7212, 7213, 7214, 7216, 7217, 7219, 7220, 7225, 7233, 7234, 7236, 7239, 7240, 7246, 7250, 7251, 7254, 7255, 7257, 7260, 7261, 7264, 7268, 7269, 7270, 7272, 7273, 7278, 7281, 7285, 7286, 7291, 7292, 7293, 7295, 7297, 7302, 7303, 7304, 7307, 7310, 7315, 7316, 7317, 7320, 7322, 7324, 7328, 7330, 7332, 7334, 7336, 7337, 7340, 7342, 7344, 7346, 7347, 7348, 7349, 7353, 7354, 7359, 7360, 7363, 7365, 7371, 7372, 7379, 7384, 7385, 7386, 7390, 7399, 7405, 7406, 7407, 7409, 7418, 7419, 7421, 7427, 7433, 7444, 7449, 7450, 7451, 7453, 7454, 7462, 7463, 7465, 7467, 7468, 7471, 7472, 7473, 7475]\n",
      "Number of images in class 2: 2492\n",
      "\n",
      "Recommended Small Batch Size: 15\n",
      "Samples per class: 5\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## At this point the balanced dataset has been created",
   "id": "d166159ead56a161"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create training, validation, and testing datasets",
   "id": "b55e0411a4aef4ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:29.852279Z",
     "start_time": "2025-02-04T10:15:29.676495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of images in each class (this will be the same after balancing)\n",
    "num_images_per_class = len(balanced_dataset_filtered) // 3  # since there are 3 classes\n",
    "\n",
    "# Calculate the number of samples per class\n",
    "train_size = int(0.8 * num_images_per_class)\n",
    "valid_size = int(0.1 * num_images_per_class)\n",
    "test_size = num_images_per_class - train_size - valid_size\n",
    "\n",
    "# Sample indices for each class\n",
    "train_indices = []\n",
    "valid_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for class_label in [0, 1, 2]:\n",
    "    class_data = balanced_dataset_filtered[balanced_dataset_filtered['hotend_class'] == class_label].index.tolist()\n",
    "    \n",
    "    # Shuffle the indices of the current class\n",
    "    random.shuffle(class_data)\n",
    "    \n",
    "    # Split the indices for each class into train, validation, and test\n",
    "    train_indices.extend(class_data[:train_size])\n",
    "    valid_indices.extend(class_data[train_size:train_size + valid_size])\n",
    "    test_indices.extend(class_data[train_size + valid_size:])\n",
    "\n",
    "# Sort the indices of the training, validation, and test datasets to ensure consistent and ordered processing\n",
    "train_indices = sorted(train_indices)\n",
    "valid_indices = sorted(valid_indices)\n",
    "test_indices = sorted(test_indices)\n",
    "\n",
    "# Class distribution in train, validation, and test sets\n",
    "train_class_distribution = [0, 0, 0]\n",
    "valid_class_distribution = [0, 0, 0]\n",
    "test_class_distribution = [0, 0, 0]\n",
    "\n",
    "for index in train_indices:\n",
    "    class_label = balanced_dataset_filtered.loc[index, 'hotend_class']\n",
    "    train_class_distribution[class_label] += 1\n",
    "\n",
    "for index in valid_indices:\n",
    "    class_label = balanced_dataset_filtered.loc[index, 'hotend_class']\n",
    "    valid_class_distribution[class_label] += 1\n",
    "\n",
    "for index in test_indices:\n",
    "    class_label = balanced_dataset_filtered.loc[index, 'hotend_class']\n",
    "    test_class_distribution[class_label] += 1\n",
    "\n",
    "# Print the class distribution\n",
    "print(\"Train set class distribution:\", train_class_distribution)\n",
    "print(\"Validation set class distribution:\", valid_class_distribution)\n",
    "print(\"Test set class distribution:\", test_class_distribution)\n",
    "\n",
    "# Verify lengths\n",
    "print(\"Train set size:\", len(train_indices))\n",
    "print(\"Validation set size:\", len(valid_indices))\n",
    "print(\"Test set size:\", len(test_indices))"
   ],
   "id": "421ff1d56ef10d56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set class distribution: [1993, 1993, 1993]\n",
      "Validation set class distribution: [249, 249, 249]\n",
      "Test set class distribution: [250, 250, 250]\n",
      "Train set size: 5979\n",
      "Validation set size: 747\n",
      "Test set size: 750\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:31.154133Z",
     "start_time": "2025-02-04T10:15:30.609021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create DataFrames for train, validation, and test sets based on the indices\n",
    "train_data = balanced_dataset_filtered.iloc[train_indices].reset_index(drop=True)\n",
    "val_data = balanced_dataset_filtered.iloc[valid_indices].reset_index(drop=True)\n",
    "test_data = balanced_dataset_filtered.iloc[test_indices].reset_index(drop=True)\n",
    "\n",
    "# Optionally print the first few rows to verify\n",
    "print(\"Train DataFrame sample:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"Validation DataFrame sample:\")\n",
    "print(val_data.head())\n",
    "\n",
    "print(\"Test DataFrame sample:\")\n",
    "print(test_data.head())"
   ],
   "id": "98286ae2848d58f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame sample:\n",
      "          img_path  hotend_class\n",
      "0  image-19089.jpg             0\n",
      "1  image-10323.jpg             1\n",
      "2   image-6277.jpg             0\n",
      "3  image-19945.jpg             0\n",
      "4  image-16946.jpg             0\n",
      "Validation DataFrame sample:\n",
      "          img_path  hotend_class\n",
      "0   image-3170.jpg             0\n",
      "1   image-4689.jpg             0\n",
      "2   image-1677.jpg             2\n",
      "3   image-1688.jpg             2\n",
      "4  image-13683.jpg             0\n",
      "Test DataFrame sample:\n",
      "          img_path  hotend_class\n",
      "0   image-2130.jpg             0\n",
      "1  image-19192.jpg             0\n",
      "2  image-20143.jpg             0\n",
      "3  image-22545.jpg             1\n",
      "4  image-23153.jpg             1\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check for Missing or Invalid Labels in Training, Validation, and Test Data",
   "id": "662a17fac6e8a62b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:32.849204Z",
     "start_time": "2025-02-04T10:15:32.817104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for any missing labels or invalid labels\n",
    "print(train_data['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(train_data['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "# Check for any missing labels or invalid labels\n",
    "print(val_data['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(val_data['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "# Check for any missing labels or invalid labels\n",
    "print(test_data['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(test_data['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values"
   ],
   "id": "fe34679176616c37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0 1 2]\n",
      "0\n",
      "[0 2 1]\n",
      "0\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Balanced Dataset class",
   "id": "7e886322ccb7f106"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:33.825170Z",
     "start_time": "2025-02-04T10:15:33.795622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the dataset class\n",
    "class BalancedDataset(Dataset):\n",
    "    def __init__(self, data_frame, root_dir, transform=None):\n",
    "        self.data = data_frame\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Validate that the images exist in the directory\n",
    "        self.valid_indices = self.get_valid_indices()\n",
    "\n",
    "    def get_valid_indices(self):\n",
    "        valid_indices = []\n",
    "        for idx in tqdm(range(len(self.data)), desc=\"Validating images\"):\n",
    "            img_name = self.data.iloc[idx, 0].strip()\n",
    "            img_name = img_name.split('/')[-1]  # Extract file name\n",
    "            \n",
    "            if img_name.startswith(\"image-\"):\n",
    "                try:\n",
    "                    # Ensure we only include images in the valid range\n",
    "                    image_number = int(img_name.split('-')[1].split('.')[0])\n",
    "                    if 4 <= image_number <= 26637:\n",
    "                        full_img_path = os.path.join(self.root_dir, img_name)\n",
    "                        if os.path.exists(full_img_path):\n",
    "                            valid_indices.append(idx)\n",
    "                        else:\n",
    "                            print(f\"Image does not exist: {full_img_path}\")\n",
    "                except ValueError:\n",
    "                    print(f\"Invalid filename format for {img_name}. Skipping...\")\n",
    "        \n",
    "        print(f\"Total valid indices found: {len(valid_indices)}\")  # Debugging output\n",
    "        return valid_indices\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.valid_indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Wrap around the index if it exceeds the length of valid indices\n",
    "        idx = idx % len(self.valid_indices)\n",
    "        \n",
    "        # Get the actual index from valid indices\n",
    "        actual_idx = self.valid_indices[idx]\n",
    "        img_name = self.data.iloc[actual_idx, 0].strip()\n",
    "        full_img_path = os.path.join(self.root_dir, img_name)\n",
    "    \n",
    "        try:\n",
    "            # Attempt to open the image and convert to RGB\n",
    "            image = Image.open(full_img_path).convert('RGB')\n",
    "    \n",
    "            # Fetch the label and convert it to an integer\n",
    "            label_str = self.data.iloc[actual_idx]['hotend_class']  # Use column name 'hotend_class'\n",
    "            label = int(label_str)  # Ensure label is integer\n",
    "    \n",
    "            # Apply transformations if defined\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "    \n",
    "            return image, label, actual_idx\n",
    "        except (OSError, IOError, ValueError) as e:\n",
    "            # Print error message for debugging\n",
    "            print(f\"Error loading image {full_img_path}: {e}\")\n",
    "    \n",
    "            # Handle gracefully by skipping the corrupted/missing file\n",
    "            # Fetch the next valid index (recursively handle until a valid image is found)\n",
    "            return self.__getitem__((idx + 1) % len(self.valid_indices))"
   ],
   "id": "dd3290d191b6defb",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Balanced Batch Sampler class",
   "id": "c6eafdf84257d772"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:34.720369Z",
     "start_time": "2025-02-04T10:15:34.696535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BalancedBatchSampler(Sampler):\n",
    "    def __init__(self, data_frame, batch_size=15, samples_per_class=5):\n",
    "        \"\"\"\n",
    "        data_frame: Pandas DataFrame with image paths and their respective class labels.\n",
    "        batch_size: Total batch size.\n",
    "        samples_per_class: Number of samples to draw from each class per batch.\n",
    "        \"\"\"\n",
    "        self.data_frame = data_frame\n",
    "        self.batch_size = batch_size\n",
    "        self.samples_per_class = samples_per_class\n",
    "        self.num_classes = len(data_frame['hotend_class'].unique())\n",
    "        \n",
    "        if self.batch_size % self.num_classes != 0:\n",
    "            raise ValueError(\"Batch size must be divisible by the number of classes.\")\n",
    "\n",
    "        self.class_indices = {\n",
    "            class_id: self.data_frame[self.data_frame['hotend_class'] == class_id].index.tolist()\n",
    "            for class_id in self.data_frame['hotend_class'].unique()\n",
    "        }\n",
    "        \n",
    "        # Shuffle class indices initially\n",
    "        for class_id in self.class_indices:\n",
    "            random.shuffle(self.class_indices[class_id])\n",
    "\n",
    "        self.num_samples_per_epoch = sum(len(indices) for indices in self.class_indices.values())\n",
    "        self.indices_used = {class_id: [] for class_id in self.class_indices}\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = []\n",
    "\n",
    "        # Replenish indices for each class\n",
    "        for class_id in self.class_indices:\n",
    "            if not self.class_indices[class_id]:\n",
    "                raise ValueError(f\"Class {class_id} has no samples. Cannot form balanced batches.\")\n",
    "\n",
    "            # Shuffle and use all indices from this class\n",
    "            self.indices_used[class_id] = self.class_indices[class_id].copy()\n",
    "            random.shuffle(self.indices_used[class_id])\n",
    "\n",
    "        # Generate balanced batches\n",
    "        while len(batches) * self.batch_size < self.num_samples_per_epoch:\n",
    "            batch = []\n",
    "            for class_id in self.indices_used:\n",
    "                if len(self.indices_used[class_id]) < self.samples_per_class:\n",
    "                    # If a class runs out of samples, reshuffle and replenish\n",
    "                    self.indices_used[class_id] = self.class_indices[class_id].copy()\n",
    "                    random.shuffle(self.indices_used[class_id])\n",
    "\n",
    "                # Take `samples_per_class` indices from the current class\n",
    "                batch.extend(self.indices_used[class_id][:self.samples_per_class])\n",
    "                self.indices_used[class_id] = self.indices_used[class_id][self.samples_per_class:]\n",
    "\n",
    "            # Shuffle the batch and append\n",
    "            random.shuffle(batch)\n",
    "            batches.append(batch)\n",
    "\n",
    "        return iter(batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Total number of batches per epoch\n",
    "        return self.num_samples_per_epoch // self.batch_size"
   ],
   "id": "4227e9802147100b",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:40.319267Z",
     "start_time": "2025-02-04T10:15:35.328718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the dataset instance (make sure to provide the right data_frame and root directory)\n",
    "train_dataset = BalancedDataset(data_frame=train_data, root_dir=root_dir)\n",
    "val_dataset = BalancedDataset(data_frame=val_data, root_dir=root_dir)\n",
    "test_dataset = BalancedDataset(data_frame=test_data, root_dir=root_dir)\n",
    "\n",
    "# Create the sampler (pass the DataFrame instead of the dataset)\n",
    "train_sampler = BalancedBatchSampler(data_frame=train_data, batch_size=15, samples_per_class=5)\n",
    "val_sampler = BalancedBatchSampler(data_frame=val_data, batch_size=15, samples_per_class=5)\n",
    "test_sampler = BalancedBatchSampler(data_frame=test_data, batch_size=15, samples_per_class=5)\n",
    "\n",
    "# Create the DataLoader with the sampler\n",
    "train_loader = DataLoader(train_dataset, batch_sampler=train_sampler, shuffle = False)\n",
    "\n",
    "# For validation and testing, we typically don't need a batch_sampler, so use regular batching\n",
    "val_loader = DataLoader(val_dataset, batch_sampler=val_sampler, shuffle = False)  # or any batch size that makes sense\n",
    "test_loader = DataLoader(test_dataset, batch_sampler=test_sampler)  # same as above\n",
    "\n",
    "print(f\"Train dataset length: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation dataset length: {len(val_loader.dataset)}\")\n",
    "print(f\"Test dataset length: {len(test_loader.dataset)}\")"
   ],
   "id": "e590c590333250c4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating images:   0%|          | 0/5979 [00:00<?, ?it/s]\u001B[A\n",
      "Validating images:   2%|         | 106/5979 [00:00<00:05, 1054.79it/s]\u001B[A\n",
      "Validating images:   4%|         | 212/5979 [00:00<00:06, 850.82it/s] \u001B[A\n",
      "Validating images:   5%|         | 300/5979 [00:00<00:10, 552.28it/s]\u001B[A\n",
      "Validating images:   6%|         | 365/5979 [00:00<00:09, 577.03it/s]\u001B[A\n",
      "Validating images:   8%|         | 466/5979 [00:00<00:07, 695.29it/s]\u001B[A\n",
      "Validating images:   9%|         | 544/5979 [00:00<00:07, 691.05it/s]\u001B[A\n",
      "Validating images:  10%|         | 619/5979 [00:00<00:07, 701.55it/s]\u001B[A\n",
      "Validating images:  12%|        | 712/5979 [00:01<00:06, 764.10it/s]\u001B[A\n",
      "Validating images:  14%|        | 810/5979 [00:01<00:06, 820.53it/s]\u001B[A\n",
      "Validating images:  15%|        | 916/5979 [00:01<00:05, 889.65it/s]\u001B[A\n",
      "Validating images:  17%|        | 1038/5979 [00:01<00:05, 983.56it/s]\u001B[A\n",
      "Validating images:  19%|        | 1143/5979 [00:01<00:04, 1003.07it/s]\u001B[A\n",
      "Validating images:  21%|        | 1250/5979 [00:01<00:04, 1021.21it/s]\u001B[A\n",
      "Validating images:  23%|       | 1366/5979 [00:01<00:04, 1059.88it/s]\u001B[A\n",
      "Validating images:  25%|       | 1486/5979 [00:01<00:04, 1099.65it/s]\u001B[A\n",
      "Validating images:  27%|       | 1609/5979 [00:01<00:03, 1135.82it/s]\u001B[A\n",
      "Validating images:  29%|       | 1757/5979 [00:01<00:03, 1237.92it/s]\u001B[A\n",
      "Validating images:  32%|      | 1903/5979 [00:02<00:03, 1301.84it/s]\u001B[A\n",
      "Validating images:  34%|      | 2039/5979 [00:02<00:02, 1317.29it/s]\u001B[A\n",
      "Validating images:  37%|      | 2222/5979 [00:02<00:02, 1467.35it/s]\u001B[A\n",
      "Validating images:  40%|      | 2389/5979 [00:02<00:02, 1524.30it/s]\u001B[A\n",
      "Validating images:  43%|     | 2542/5979 [00:02<00:02, 1515.61it/s]\u001B[A\n",
      "Validating images:  45%|     | 2718/5979 [00:02<00:02, 1585.47it/s]\u001B[A\n",
      "Validating images:  48%|     | 2877/5979 [00:02<00:01, 1559.07it/s]\u001B[A\n",
      "Validating images:  51%|    | 3077/5979 [00:02<00:01, 1687.70it/s]\u001B[A\n",
      "Validating images:  54%|    | 3247/5979 [00:02<00:01, 1660.19it/s]\u001B[A\n",
      "Validating images:  57%|    | 3433/5979 [00:02<00:01, 1718.50it/s]\u001B[A\n",
      "Validating images:  60%|    | 3606/5979 [00:03<00:01, 1658.86it/s]\u001B[A\n",
      "Validating images:  63%|   | 3778/5979 [00:03<00:01, 1675.07it/s]\u001B[A\n",
      "Validating images:  66%|   | 3976/5979 [00:03<00:01, 1764.09it/s]\u001B[A\n",
      "Validating images:  70%|   | 4169/5979 [00:03<00:01, 1808.99it/s]\u001B[A\n",
      "Validating images:  73%|  | 4361/5979 [00:03<00:00, 1839.86it/s]\u001B[A\n",
      "Validating images:  76%|  | 4573/5979 [00:03<00:00, 1920.07it/s]\u001B[A\n",
      "Validating images:  80%|  | 4766/5979 [00:03<00:00, 1873.74it/s]\u001B[A\n",
      "Validating images:  83%| | 4969/5979 [00:03<00:00, 1918.02it/s]\u001B[A\n",
      "Validating images:  86%| | 5162/5979 [00:03<00:00, 1872.81it/s]\u001B[A\n",
      "Validating images:  90%| | 5362/5979 [00:03<00:00, 1909.22it/s]\u001B[A\n",
      "Validating images:  93%|| 5554/5979 [00:04<00:00, 1857.36it/s]\u001B[A\n",
      "Validating images: 100%|| 5979/5979 [00:04<00:00, 1408.26it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid indices found: 5979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating images:   0%|          | 0/747 [00:00<?, ?it/s]\u001B[A\n",
      "Validating images:  30%|       | 224/747 [00:00<00:00, 2205.28it/s]\u001B[A\n",
      "Validating images:  60%|    | 445/747 [00:00<00:00, 1918.40it/s]\u001B[A\n",
      "Validating images: 100%|| 747/747 [00:00<00:00, 2100.77it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid indices found: 747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating images:   0%|          | 0/750 [00:00<?, ?it/s]\u001B[A\n",
      "Validating images:  38%|      | 287/750 [00:00<00:00, 2852.73it/s]\u001B[A\n",
      "Validating images: 100%|| 750/750 [00:00<00:00, 2784.64it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid indices found: 750\n",
      "Train dataset length: 5979\n",
      "Validation dataset length: 747\n",
      "Test dataset length: 750\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check the class distribution of randomly selected batches in train loader",
   "id": "af4056d2dc855bf7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:47.517237Z",
     "start_time": "2025-02-04T10:15:41.395364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to print random batches and their class distribution\n",
    "def print_random_batches(train_loader, num_batches=5):\n",
    "    for _ in range(num_batches):\n",
    "        # Get the next batch from the loader\n",
    "        batch_images, batch_labels, _ = next(iter(train_loader))  # Get the images, labels, and indices (if needed)\n",
    "        \n",
    "        # Calculate the class distribution in this batch\n",
    "        class_distribution = Counter(batch_labels.tolist())  # Convert tensor to list for counting\n",
    "        \n",
    "        # Print the class distribution for the current batch\n",
    "        print(f\"Class distribution for this batch: {dict(class_distribution)}\")\n",
    "        \n",
    "        # Print the actual labels for the batch (as a list or tensor)\n",
    "        print(\"Actual labels for this batch:\")\n",
    "        print(batch_labels.tolist())  # Converts tensor to list for readability\n",
    "        \n",
    "        # Print the image tensor shape for the batch\n",
    "        print(\"Image tensor shape for the batch:\")\n",
    "        print(batch_images.shape)  # This prints the shape of the image tensor\n",
    "        \n",
    "        # Optionally, print a few details of the image tensors (e.g., min and max values) to understand them\n",
    "        print(\"Min and max values of the image tensors:\")\n",
    "        print(f\"Min: {batch_images.min()}, Max: {batch_images.max()}\")\n",
    "        \n",
    "        # If you want to print the image itself (assuming it's a small size, for visualization)\n",
    "        # You can use something like matplotlib to visualize the images, for example:\n",
    "        # from matplotlib import pyplot as plt\n",
    "        # plt.imshow(batch_images[0].permute(1, 2, 0).numpy())  # assuming 3 channel images\n",
    "        # plt.show()\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Print random batches and their class distribution\n",
    "print_random_batches(train_loader, num_batches=5)"
   ],
   "id": "8a20d253412d479d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution for this batch: {2: 5, 1: 5, 0: 5}\n",
      "Actual labels for this batch:\n",
      "[2, 1, 2, 1, 0, 1, 1, 0, 2, 0, 2, 0, 2, 1, 0]\n",
      "Image tensor shape for the batch:\n",
      "torch.Size([15, 3, 224, 224])\n",
      "Min and max values of the image tensors:\n",
      "Min: -2.1179039478302, Max: 2.640000104904175\n",
      "--------------------------------------------------\n",
      "Class distribution for this batch: {2: 5, 1: 5, 0: 5}\n",
      "Actual labels for this batch:\n",
      "[2, 2, 1, 2, 1, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0]\n",
      "Image tensor shape for the batch:\n",
      "torch.Size([15, 3, 224, 224])\n",
      "Min and max values of the image tensors:\n",
      "Min: -1.9809060096740723, Max: 2.640000104904175\n",
      "--------------------------------------------------\n",
      "Class distribution for this batch: {0: 5, 1: 5, 2: 5}\n",
      "Actual labels for this batch:\n",
      "[0, 1, 2, 2, 0, 0, 1, 0, 0, 2, 2, 1, 1, 2, 1]\n",
      "Image tensor shape for the batch:\n",
      "torch.Size([15, 3, 224, 224])\n",
      "Min and max values of the image tensors:\n",
      "Min: -2.1179039478302, Max: 2.640000104904175\n",
      "--------------------------------------------------\n",
      "Class distribution for this batch: {1: 5, 0: 5, 2: 5}\n",
      "Actual labels for this batch:\n",
      "[1, 0, 1, 2, 1, 0, 0, 2, 1, 0, 2, 2, 0, 2, 1]\n",
      "Image tensor shape for the batch:\n",
      "torch.Size([15, 3, 224, 224])\n",
      "Min and max values of the image tensors:\n",
      "Min: -2.015155553817749, Max: 2.640000104904175\n",
      "--------------------------------------------------\n",
      "Class distribution for this batch: {2: 5, 1: 5, 0: 5}\n",
      "Actual labels for this batch:\n",
      "[2, 1, 1, 1, 0, 2, 2, 0, 2, 0, 2, 1, 0, 0, 1]\n",
      "Image tensor shape for the batch:\n",
      "torch.Size([15, 3, 224, 224])\n",
      "Min and max values of the image tensors:\n",
      "Min: -2.1007792949676514, Max: 2.640000104904175\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check class distribution of random batches from training, validation and testing data",
   "id": "2cc6d0c1a5f2f130"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:53.867731Z",
     "start_time": "2025-02-04T10:15:50.331557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_label_batch_from_loader(loader, dataset_name):\n",
    "    \"\"\"Fetch and print a batch of labels from the data loader.\"\"\"\n",
    "    data_iter = iter(loader)\n",
    "    batch_images, batch_labels, _ = next(data_iter)  # Get one batch (including the index)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} - Sample Label Batch:\")\n",
    "    print(batch_labels)  # Print the labels for the batch\n",
    "    \n",
    "    # Optionally, you can convert the tensor labels to a list for easier reading:\n",
    "    print(f\"Labels as list: {batch_labels.tolist()}\")\n",
    "\n",
    "# Print batches of labels from the train, validation, and test loaders\n",
    "print_label_batch_from_loader(train_loader, 'Training')\n",
    "print_label_batch_from_loader(val_loader, 'Validation')\n",
    "print_label_batch_from_loader(test_loader, 'Test')"
   ],
   "id": "bc6606335e8ab7c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training - Sample Label Batch:\n",
      "tensor([1, 0, 0, 2, 1, 0, 2, 1, 2, 1, 1, 2, 2, 0, 0])\n",
      "Labels as list: [1, 0, 0, 2, 1, 0, 2, 1, 2, 1, 1, 2, 2, 0, 0]\n",
      "\n",
      "Validation - Sample Label Batch:\n",
      "tensor([1, 2, 1, 2, 2, 1, 2, 0, 2, 1, 0, 1, 0, 0, 0])\n",
      "Labels as list: [1, 2, 1, 2, 2, 1, 2, 0, 2, 1, 0, 1, 0, 0, 0]\n",
      "\n",
      "Test - Sample Label Batch:\n",
      "tensor([1, 1, 1, 0, 1, 1, 0, 2, 0, 2, 0, 2, 2, 2, 0])\n",
      "Labels as list: [1, 1, 1, 0, 1, 1, 0, 2, 0, 2, 0, 2, 2, 2, 0]\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setting up a new folder for each experiment",
   "id": "2593fbbffb0507f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:15:53.942763Z",
     "start_time": "2025-02-04T10:15:53.872721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Set base directory\n",
    "base_dir = \"experiments\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Function to get the next experiment folder\n",
    "def get_experiment_folder(exp_num):\n",
    "    return os.path.join(base_dir, f\"Experiment_{exp_num:02d}\")  # Keeps two-digit format (01, 02, ..., 10)\n",
    "\n",
    "# Set initial experiment number\n",
    "experiment_num = 1\n",
    "experiment_folder = get_experiment_folder(experiment_num)\n",
    "\n",
    "# Create the main experiment directory if it doesn't exist\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "# Set model path inside experiment folder\n",
    "model_path = os.path.join(experiment_folder, \"best_model.pth\")\n",
    "\n",
    "# Create subdirectories for training, validation, and test confusion matrices\n",
    "train_folder = os.path.join(experiment_folder, \"training_confusion_matrices\")\n",
    "val_folder = os.path.join(experiment_folder, \"validation_confusion_matrices\")\n",
    "test_folder = os.path.join(experiment_folder, \"test_confusion_matrices\")\n",
    "\n",
    "# Ensure that the subdirectories exist\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(val_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Print the directory where results will be saved\n",
    "print(f\"Saving results to: {experiment_folder}\")"
   ],
   "id": "7024fc4958e617bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to: experiments\\Experiment_01\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Display a Random Image from the Dataset with Its Label",
   "id": "31f09daea1bf55ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:16:00.299311Z",
     "start_time": "2025-02-04T10:15:56.651527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Assume 'train_data' is your DataFrame with image paths and labels\n",
    "random_index = random.choice(train_data.index)  # Choose a random index\n",
    "img_path = os.path.join(root_dir, train_data.iloc[random_index, 0])\n",
    "label = train_data.loc[random_index, 'hotend_class']\n",
    "\n",
    "# Load the image\n",
    "img = plt.imread(img_path)  # Use appropriate image loading method\n",
    "\n",
    "# Plot the image and set the title\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Label: {label}\")\n",
    "\n",
    "# Define the path to save the image inside the current experiment folder\n",
    "output_path = os.path.join(experiment_folder, \"output_image.png\")\n",
    "\n",
    "# Save the figure in the experiment folder\n",
    "plt.savefig(output_path)\n",
    "\n",
    "# Optional: Clear the plot to avoid overlaps in subsequent operations\n",
    "plt.clf()\n",
    "\n",
    "print(f\"Image saved to: {output_path}\")"
   ],
   "id": "c28c6f62f3e4c234",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to: experiments\\Experiment_01\\output_image.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:16:01.007335Z",
     "start_time": "2025-02-04T10:16:00.997001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensure that image paths and labels are correctly aligned\n",
    "\n",
    "# First image\n",
    "first_index = train_data.index[0]\n",
    "first_image = train_data.loc[first_index, 'img_path']\n",
    "first_label = train_data.loc[first_index, 'hotend_class']\n",
    "print(f\"First Image Path: {first_image}, First Label: {first_label}\")\n",
    "\n",
    "# Last image\n",
    "last_index = train_data.index[-1]  # Accessing the last index\n",
    "last_image = train_data.loc[last_index, 'img_path']\n",
    "last_label = train_data.loc[last_index, 'hotend_class']\n",
    "print(f\"Last Image Path: {last_image}, Last Label: {last_label}\")"
   ],
   "id": "eb1033deadf45bc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Image Path: image-19089.jpg, First Label: 0\n",
      "Last Image Path: image-20837.jpg, Last Label: 2\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Printing Class Distribution for Training, Validation, and Test Data",
   "id": "3d491c9c57e1a27c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T10:18:42.138489Z",
     "start_time": "2025-02-04T10:16:04.678853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to print class distribution\n",
    "def print_class_distribution(loader, dataset_name):\n",
    "    \"\"\"Print class distribution in the dataset.\"\"\"\n",
    "    all_labels = []\n",
    "\n",
    "    # Collect all labels from the dataset\n",
    "    for batch in loader:\n",
    "        if len(batch) == 2:  # Normal batch with (image, label)\n",
    "            _, labels = batch\n",
    "        elif len(batch) == 3:  # Batch with (image, label, idx) from BalancedDataset\n",
    "            _, labels, _ = batch\n",
    "        \n",
    "        # Collect labels from the batch\n",
    "        all_labels.extend(labels.cpu().numpy())  # Collect labels and move them to CPU if using GPU\n",
    "\n",
    "    # Calculate and print the class distribution\n",
    "    class_counts = Counter(all_labels)\n",
    "    print(f\"\\n{dataset_name} Class Distribution:\")\n",
    "    for class_id, count in class_counts.items():\n",
    "        print(f\"Class {class_id}: {count} samples\")\n",
    "\n",
    "# Print class distribution for train, validation, and test data\n",
    "print_class_distribution(train_loader, 'Training')\n",
    "print_class_distribution(val_loader, 'Validation')\n",
    "print_class_distribution(test_loader, 'Test')"
   ],
   "id": "92f8659014c6c801",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Class Distribution:\n",
      "Class 0: 1995 samples\n",
      "Class 2: 1995 samples\n",
      "Class 1: 1995 samples\n",
      "\n",
      "Validation Class Distribution:\n",
      "Class 1: 250 samples\n",
      "Class 2: 250 samples\n",
      "Class 0: 250 samples\n",
      "\n",
      "Test Class Distribution:\n",
      "Class 2: 250 samples\n",
      "Class 0: 250 samples\n",
      "Class 1: 250 samples\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CNN Model Training, Validation, and Testing with Class Distribution and Learning Rate Scheduling",
   "id": "82cf7bf9b954071b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "# Training loop across 10 experiments\n",
    "while experiment_num <= 10:\n",
    "    print(f\"\\nStarting {experiment_folder}...\\n\")   \n",
    "   \n",
    "    # Set device to GPU if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Move model to device\n",
    "    model = SimpleCNN(num_classes=3).to(device)\n",
    "    \n",
    "    # Training parameters\n",
    "    class_weights = torch.tensor([1.0, 1.0, 1.0]).to(device)  # Update these based on your class distribution\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)  # Adjust learning rate if needed\n",
    "    # **Add the learning rate scheduler here**\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # Decrease LR every 10 epochs by a factor of 0.1\n",
    "    \n",
    "    # Initialise confusion matrix trackers\n",
    "    num_classes = 3\n",
    "    train_cm = ConfusionMatrix(task='multiclass', num_classes=num_classes).to(device)\n",
    "    val_cm = ConfusionMatrix(task='multiclass',num_classes=num_classes).to(device)\n",
    "    \n",
    "    # Store losses for plotting\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # Set experiment parameters\n",
    "    num_epochs = 2 # Total epochs to train\n",
    "    load_pretrained = False  # Set to True to resume training\n",
    "    model_path = \"best_model.pth\"\n",
    "    \n",
    "    if load_pretrained and os.path.exists(model_path):\n",
    "    \tprint(f\"Loading pretrained model from {model_path}...\")\n",
    "    \tcheckpoint = torch.load(model_path, map_location=device, weights_only=True)\n",
    "    \n",
    "    # Print the checkpoint keys to check its contents\n",
    "    \tprint(f\"Checkpoint keys: {checkpoint.keys()}\")\n",
    "    \n",
    "    \t# If the checkpoint contains 'model_state' (which is the standard key for model weights)\n",
    "    \tif 'model_state' in checkpoint:\n",
    "        \tmodel.load_state_dict(checkpoint['model_state'])  # Load the model weights\n",
    "        \toptimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "        \tscheduler.load_state_dict(checkpoint['scheduler_state'])\n",
    "        \n",
    "        \t# Optionally, load epoch and best validation accuracy values from checkpoint\n",
    "        \tstart_epoch = checkpoint['epoch']\n",
    "        \tbest_val_accuracy = checkpoint['best_val_accuracy']\n",
    "        \n",
    "        \tprint(f\"Loaded model weights from checkpoint, resuming from epoch {start_epoch + 1}...\")\n",
    "    \telse:\n",
    "        \tprint(\"No valid model weights found in checkpoint. Starting fresh.\")\n",
    "        \tstart_epoch = 0\n",
    "        \tbest_val_accuracy = 0.0\n",
    "    else:\n",
    "\t# If no pretrained model is loaded, start fresh\n",
    "    \tstart_epoch = 0\n",
    "    \tbest_val_accuracy = 0.0\n",
    "    \tprint(\"Starting fresh, no pretrained model loaded.\")\n",
    "    \n",
    "    # Ensure the experiment folder exists\n",
    "    os.makedirs(experiment_folder, exist_ok=True)\n",
    "    \n",
    "    # Create the CSV file path (inside the experiment folder)\n",
    "    csv_file_path = os.path.join(experiment_folder, \"training_validation_losses.csv\")\n",
    "    \n",
    "    # Header row with the specified headings (only write header if the file doesn't exist)\n",
    "    header = [\"Epoch\", \"Training Loss\", \"Validation Loss\"]\n",
    "    \n",
    "    # Check if the file already exists\n",
    "    file_exists = os.path.exists(csv_file_path)\n",
    "    \n",
    "    # If the file doesn't exist, write the header\n",
    "    if not file_exists:\n",
    "        with open(csv_file_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(header)\n",
    "            \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        class_counts = [0] * 3  # Assuming 3 classes, update if needed\n",
    "    \n",
    "        # Training phase with tqdm progress bar\n",
    "        for images, labels, _ in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            print(f\"Outputs (Raw): {outputs}\")  # Log raw outputs\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Track training loss and accuracy\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            # Update confusion matrix\n",
    "            train_cm.update(predicted, labels)\n",
    "    \n",
    "            # Update class counts\n",
    "            for label in labels:\n",
    "                class_counts[label.item()] += 1\n",
    "            \n",
    "            # Print predicted vs actual labels for each batch\n",
    "            for i in range(len(labels)):\n",
    "                print(f\"Predicted: {predicted[i].item()}, Actual: {labels[i].item()}\")\n",
    "    \n",
    "        train_epoch_loss = running_loss / total_samples\n",
    "        train_epoch_accuracy = correct_predictions / total_samples\n",
    "        print(f\"Training Loss: {train_epoch_loss:.4f}, Training Accuracy: {train_epoch_accuracy:.4f}\")\n",
    "        \n",
    "        # Print class distribution during training\n",
    "        print(f\"Training Class Distribution: {class_counts}\")\n",
    "        \n",
    "        # **Call the scheduler here at the end of each epoch to update the learning rate**\n",
    "        scheduler.step()\n",
    "    \n",
    "        # Store training loss for plotting\n",
    "        train_losses.append(train_epoch_loss)\n",
    "        \n",
    "        # Compute and plot confusion matrix for training\n",
    "        cm_train = train_cm.compute()\n",
    "        print(f\"Training Confusion Matrix:\\n{cm_train}\")\n",
    "        sns.heatmap(cm_train.cpu().numpy(), annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                    xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title(f'Training Confusion Matrix - Epoch {start_epoch + 1}')\n",
    "        output_path_train = os.path.join(train_folder, f\"training_confusion_matrix_epoch_{start_epoch + 1}.png\")\n",
    "        plt.savefig(output_path_train)  # Save the plot\n",
    "        plt.clf()  # Clear the plot for the next iteration\n",
    "        print(f\"Training Confusion Matrix saved to: {output_path_train}\")\n",
    "    \n",
    "        train_cm.reset()  # Reset confusion matrix tracker for next epoch\n",
    "        print(f\"Training Loss: {train_epoch_loss:.4f}, Training Accuracy: {train_epoch_accuracy:.4f}\")\n",
    "    \n",
    "        # Validation phase with tqdm progress bar\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_samples = 0\n",
    "        val_class_counts = [0] * 3  # Assuming 3 classes, update if needed\n",
    "    \n",
    "        with torch.no_grad():  # Disable gradient computation for validation\n",
    "            for images, labels, _ in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                print(f\"Outputs (Raw): {outputs}\")  # Log raw outputs\n",
    "                loss = criterion(outputs, labels)\n",
    "    \n",
    "                # Track validation loss and accuracy\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct_predictions += (predicted == labels).sum().item()\n",
    "                val_total_samples += labels.size(0)\n",
    "                \n",
    "                # Update confusion matrix\n",
    "                val_cm.update(predicted, labels)\n",
    "    \n",
    "                # Update class counts for validation\n",
    "                for label in labels:\n",
    "                    val_class_counts[label.item()] += 1\n",
    "    \n",
    "                # Print predicted vs actual labels for each batch\n",
    "                for i in range(len(labels)):\n",
    "                    print(f\"Predicted: {predicted[i].item()}, Actual: {labels[i].item()}\")\n",
    "    \n",
    "        val_epoch_loss = val_loss / val_total_samples\n",
    "        val_epoch_accuracy = val_correct_predictions / val_total_samples\n",
    "        print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy:.4f}\")\n",
    "        \n",
    "        # Print class distribution during validation\n",
    "        print(f\"Validation Class Distribution: {val_class_counts}\")\n",
    "    \n",
    "        # Store validation loss for plotting\n",
    "        val_losses.append(val_epoch_loss)\n",
    "        \n",
    "        # Compute and plot confusion matrix for validation\n",
    "        cm_val = val_cm.compute()\n",
    "        print(f\"Validation Confusion Matrix:\\n{cm_val}\")\n",
    "        sns.heatmap(cm_val.cpu().numpy(), annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                    xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title(f'Validation Confusion Matrix - Epoch {start_epoch + 1}')\n",
    "        output_path_val = os.path.join(val_folder, f\"validation_confusion_matrix_epoch_{start_epoch + 1}.png\")\n",
    "        plt.savefig(output_path_val)  # Save the plot\n",
    "        plt.clf()  # Clear the plot for the next iteration\n",
    "        print(f\"Validation Confusion Matrix saved to: {output_path_val}\")\n",
    "    \n",
    "        val_cm.reset()  # Reset confusion matrix tracker for next epoch\n",
    "        print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy:.4f}\")\n",
    "    \n",
    "        # Save the model if it achieves better validation accuracy\n",
    "        if val_epoch_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_epoch_accuracy  # Update the best accuracy\n",
    "            torch.save({\n",
    "                \"epoch\": epoch + 1,  # Save next epoch to start from\n",
    "                \"model_state\": model.state_dict(),  # Save model weights\n",
    "                \"optimizer_state\": optimizer.state_dict(),  # Save optimizer state\n",
    "                \"scheduler_state\": scheduler.state_dict(),  # Save scheduler state\n",
    "                \"best_val_accuracy\": best_val_accuracy  # Save best validation accuracy\n",
    "            }, model_path)\n",
    "\n",
    "            print(f\"Saved model at epoch {epoch + 1} with improved validation accuracy: {best_val_accuracy:.4f}\")\n",
    "            \n",
    "        # Save the training and validation losses to the CSV file after each epoch\n",
    "        with open(csv_file_path, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            # Write the current epoch's training and validation losses\n",
    "            writer.writerow([epoch + 1, train_epoch_loss, val_epoch_loss])\n",
    "\n",
    "    print(f\"Epoch {start_epoch + 1} Training and Validation Losses saved to: {csv_file_path}\")\n",
    "    \n",
    "    # End of training loop\n",
    "    print(\"Training complete.\")\n",
    "        \n",
    "    # Plotting the training and validation losses\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', color='blue')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', color='red')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the plot to the current working directory\n",
    "    output_path = os.path.join(experiment_folder, \"training_validation_loss.png\")\n",
    "    plt.savefig(output_path)  # Save the plot\n",
    "    plt.clf()  # Clear the plot to free memory for future use\n",
    "    print(f\"Training and Validation Loss plot saved to: {output_path}\")\n",
    "    \n",
    "    # Test model function with tqdm progress bar\n",
    "    def test_model(model, test_loader):\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        test_class_counts = [0] * 3  # Assuming 3 classes, update if needed\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        with torch.no_grad():  # Disable gradients for testing\n",
    "            for images, labels, _ in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "                \n",
    "                # Store labels and predictions for confusion matrix\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "                # Update class counts for testing\n",
    "                for label in labels:\n",
    "                    test_class_counts[label.item()] += 1\n",
    "    \n",
    "                # Print predicted vs actual labels for each batch\n",
    "                for i in range(len(labels)):\n",
    "                    print(f\"Predicted: {predicted[i].item()}, Actual: {labels[i].item()}\")\n",
    "    \n",
    "        avg_accuracy = correct_predictions / total_samples\n",
    "        print(f\"Test Accuracy: {avg_accuracy:.4f}\")\n",
    "        \n",
    "        # Print class distribution during testing\n",
    "        print(f\"Test Class Distribution: {test_class_counts}\")\n",
    "        \n",
    "         # Generate confusion matrix\n",
    "        cm_test = confusion_matrix(all_labels, all_predictions, labels=range(3))\n",
    "        print(f\"Test Confusion Matrix:\\n{cm_test}\")\n",
    "    \n",
    "        # Plot confusion matrix\n",
    "        sns.heatmap(cm_test, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                    xticklabels=range(3), yticklabels=range(3))\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Test Confusion Matrix')\n",
    "    \n",
    "        # Save confusion matrix plot\n",
    "        output_path_test = os.path.join(test_folder, \"test_confusion_matrix.png\")\n",
    "        plt.savefig(output_path_test)\n",
    "        plt.clf()  # Clear the plot for the next use\n",
    "        print(f\"Test Confusion Matrix saved to: {output_path_test}\")\n",
    "    \n",
    "    \n",
    "    # Run the test phase after training\n",
    "    test_model(model, test_loader)\n",
    "    \n",
    "    # Move to next experiment\n",
    "    experiment_num += 1\n",
    "    if experiment_num <= 10:  # Ensure it does not go beyond Experiment_10\n",
    "        experiment_folder = get_experiment_folder(experiment_num)\n",
    "        os.makedirs(experiment_folder, exist_ok=True)\n",
    "        model_path = os.path.join(experiment_folder, \"best_model.pth\")  # Update model path\n",
    "\n",
    "print(\"\\nAll 10 Experiments Completed.\")"
   ],
   "id": "bcf6a46e97b2d2df",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
