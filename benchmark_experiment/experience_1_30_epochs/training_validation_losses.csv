Epoch,Training Loss,Validation Loss
1,1.1031359377361478,1.1017800569534302
2,1.100614485286531,1.1015880107879639
3,1.0993755488168626,1.1011160612106323
4,1.0989423309053694,1.1006544828414917
5,1.0981877247492473,1.10014808177948
6,1.0975760505312966,1.0996822118759155
7,1.0969960519245692,1.09920334815979
8,1.0971385637919109,1.098713994026184
9,1.0958761828286308,1.0982173681259155
10,1.0946898119790214,1.0978909730911255
11,1.0938587529318673,1.097875714302063
12,1.0937077431451707,1.097877860069275
13,1.0935910599572318,1.0979132652282715
14,1.0934255917867024,1.0979340076446533
15,1.0933146874109905,1.0979620218276978
16,1.0931711423964727,1.0979259014129639
17,1.0930684748150052,1.0979169607162476
18,1.0929714498065768,1.0978947877883911
19,1.0928495895294916,1.097847819328308
20,1.0927151498340426,1.097757339477539
21,1.0925682385762532,1.0977474451065063
22,1.092552627835955,1.0977425575256348
23,1.092539804322379,1.0977401733398438
24,1.0925290073667253,1.0977412462234497
25,1.0925161441167195,1.0977388620376587
26,1.0925023158391316,1.0977331399917603
27,1.0924911271958124,1.0977319478988647
28,1.09247921194349,1.0977287292480469
29,1.0924646854400635,1.0977270603179932
30,1.0924532924379622,1.097719669342041
