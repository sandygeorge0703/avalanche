{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing libraries",
   "id": "cf83250ee7f63eeb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T18:43:52.338882Z",
     "start_time": "2025-03-02T18:43:38.551082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, Sampler, SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "from tqdm import tqdm  \n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.utils.data import ConcatDataset\n",
    "import random\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "# Allow loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ],
   "id": "b8061d6902ab803b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define filepaths as constant",
   "id": "41b9047ff69b1348"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define file paths as constants\n",
    "CSV_FILE_PATH = r'C:\\Users\\Sandhra George\\avalanche\\data\\dataset.csv'\n",
    "ROOT_DIR_PATH = r'C:\\Users\\Sandhra George\\avalanche\\caxton_dataset\\print24'\n",
    "\n",
    "csv_file = r'C:\\Users\\Sandhra George\\avalanche\\data\\dataset.csv'  # Path to the CSV file\n",
    "root_dir = r'C:\\Users\\Sandhra George\\avalanche\\caxton_dataset\\print24'  # Path to the image directory"
   ],
   "id": "1abad502d1ece263",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data into DataFrame and filter print24",
   "id": "cb52d1ca4b474151"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load data into a DataFrame for easier processing\n",
    "data = pd.read_csv(CSV_FILE_PATH)\n",
    "\n",
    "# Limit dataset to the images between row indices 454 and 7058 (inclusive)\n",
    "#data_limited = data.iloc[454:7059].reset_index(drop=True)\n",
    "\n",
    "# Filter the dataset to only include images containing \"print24\"\n",
    "data_filtered = data[data.iloc[:, 0].str.contains('print24', na=False)]\n",
    "\n",
    "# Update the first column to contain only the image filenames\n",
    "data_filtered.iloc[:, 0] = data_filtered.iloc[:, 0].str.replace(r'.*?/(image-\\d+\\.jpg)', r'\\1', regex=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"First rows of filtered DataFrame:\")\n",
    "print(data_filtered.head())\n",
    "\n",
    "# Display the last few rows of the updated DataFrame\n",
    "print(\"\\nLast rows of filtered DataFrame:\")\n",
    "print(data_filtered.tail())"
   ],
   "id": "a798b6f5b4adbf65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analysing the target hotend temperature column",
   "id": "5d0423ac0a8bc90c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract unique temperatures in the 'target_hotend' column and sort them\n",
    "unique_temperatures = sorted(data_filtered['target_hotend'].unique())  # Sort temperatures in ascending order\n",
    "\n",
    "# Calculate the full range of temperatures (min and max)\n",
    "temperature_min = data_filtered['target_hotend'].min()\n",
    "temperature_max = data_filtered['target_hotend'].max()\n",
    "\n",
    "# Print the unique temperatures (sorted), count, and full range\n",
    "print(\"\\nUnique target hotend temperatures in the dataset (sorted):\")\n",
    "print(unique_temperatures)\n",
    "print(f\"\\nNumber of unique target hotend temperatures: {len(unique_temperatures)}\")\n",
    "print(f\"Temperature range: {temperature_min} to {temperature_max}\")"
   ],
   "id": "f29c405cf341b9ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a random temperature sub list and new dataframes with equal class distribution",
   "id": "a22e7cd8879fcbeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract unique temperatures and sort them\n",
    "unique_temperatures = sorted(data_filtered['target_hotend'].unique())  # Sort temperatures in ascending order\n",
    "\n",
    "# Check if we have enough unique temperatures to select from\n",
    "if len(unique_temperatures) >= 50:\n",
    "    # Select the lowest and highest temperatures\n",
    "    temperature_min = unique_temperatures[0]\n",
    "    temperature_max = unique_temperatures[-1]\n",
    "\n",
    "    # Remove the lowest and highest temperatures from the unique temperatures list\n",
    "    remaining_temperatures = [temp for temp in unique_temperatures if temp != temperature_min and temp != temperature_max]\n",
    "\n",
    "    # Randomly select 40 other temperatures from the remaining ones\n",
    "    random_temperatures = random.sample(remaining_temperatures, 40)\n",
    "\n",
    "    # Add the random temperatures to the temperature_sublist\n",
    "    temperature_sublist = [temperature_min, temperature_max] + random_temperatures\n",
    "    \n",
    "    # Sort from lowest to highest hotend temperature\n",
    "    temperature_sublist = sorted(temperature_sublist)\n",
    "\n",
    "    # Print the temperature sublist\n",
    "    print(\"\\nTemperature sublist:\")\n",
    "    print(temperature_sublist)\n",
    "    \n",
    "    # Split into three experience groups\n",
    "    split_size = len(temperature_sublist) // 3\n",
    "    experience_1 = temperature_sublist[:split_size]  # First third\n",
    "    experience_2 = temperature_sublist[split_size:2*split_size]  # Second third\n",
    "    experience_3 = temperature_sublist[2*split_size:]  # Last third\n",
    "\n",
    "    # Print the results\n",
    "    print(\"\\nExperience Group 1:\", experience_1)\n",
    "    print(\"\\nExperience Group 2:\", experience_2)\n",
    "    print(\"\\nExperience Group 3:\", experience_3)\n",
    "else:\n",
    "    print(\"Not enough unique temperatures to select from. At least 50 unique temperatures are required.\")\n",
    "    experience_1 = experience_2 = experience_3 = []\n",
    "\n",
    "# Initialize a dictionary to store DataFrames for each class per experience\n",
    "experience_datasets = {1: {}, 2: {}, 3: {}}\n",
    "\n",
    "# Iterate through the three experience groups\n",
    "for exp_id, experience_temps in enumerate([experience_1, experience_2, experience_3], start=1):\n",
    "    if not experience_temps:\n",
    "        print(f\"Skipping Experience {exp_id} due to insufficient temperatures.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing Experience {exp_id} with temperatures: {experience_temps}...\")\n",
    "\n",
    "    # Filter the dataset based on the current experience's temperature range\n",
    "    exp_data = data_filtered[data_filtered['target_hotend'].isin(experience_temps)]\n",
    "    \n",
    "    # Check if exp_data is empty after filtering\n",
    "    if exp_data.empty:\n",
    "        print(f\"No data found for Experience {exp_id} with temperatures {experience_temps}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Create a dictionary to store class-wise data for this experience\n",
    "    class_datasets = {}\n",
    "\n",
    "    # Iterate through each class (0, 1, 2) and filter data\n",
    "    for class_id in [0, 1, 2]:\n",
    "        class_data = exp_data[exp_data['hotend_class'] == class_id]\n",
    "        \n",
    "        if class_data.empty:\n",
    "            print(f\"Warning: Class {class_id} in Experience {exp_id} has no data!\")\n",
    "        else:\n",
    "            class_datasets[class_id] = class_data\n",
    "            print(f\"Class {class_id} dataset size in Experience {exp_id}: {len(class_data)}\")\n",
    "\n",
    "    # Ensure that all classes have data before proceeding to balance\n",
    "    if len(class_datasets) != 3:\n",
    "        print(f\"Skipping Experience {exp_id} because one or more classes are missing data!\")\n",
    "        continue  # Skip processing this experience if any class has no data\n",
    "\n",
    "    # Find the smallest class size in this experience\n",
    "    min_class_size = min(len(class_datasets[class_id]) for class_id in class_datasets)\n",
    "    print(f\"Smallest class size in Experience {exp_id}: {min_class_size}\")\n",
    "\n",
    "    # Balance the dataset for this experience\n",
    "    balanced_data = []\n",
    "\n",
    "    for class_id in class_datasets:\n",
    "        class_data = class_datasets[class_id]\n",
    "        # Randomly sample 'min_class_size' images from the class data to balance class distribution\n",
    "        sampled_class_data = class_data.sample(n=min_class_size, random_state=42)  # Sample equally\n",
    "        balanced_data.append(sampled_class_data)\n",
    "\n",
    "    # Combine all class data for this experience into one balanced dataset\n",
    "    balanced_dataset = pd.concat(balanced_data).reset_index(drop=True)\n",
    "\n",
    "    # Shuffle the final balanced dataset\n",
    "    balanced_dataset = balanced_dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Store the balanced dataset in the experience_datasets dictionary\n",
    "    experience_datasets[exp_id] = balanced_dataset\n",
    "\n",
    "    # Print summary for this experience\n",
    "    print(f\"\\nBalanced dataset size for Experience {exp_id}: {len(balanced_dataset)}\")\n",
    "    print(\"Number of images in each class after balancing:\")\n",
    "\n",
    "    for class_id in [0, 1, 2]:\n",
    "        class_count = len(balanced_dataset[balanced_dataset['hotend_class'] == class_id])\n",
    "        print(f\"Class {class_id}: {class_count} images\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Print the first few rows for verification\n",
    "for exp_id in [1, 2, 3]:\n",
    "    if exp_id in experience_datasets:\n",
    "        print(f\"\\nFirst five rows of Experience {exp_id} dataset:\")\n",
    "        print(experience_datasets[exp_id].head())"
   ],
   "id": "47acde363e257d88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Checking the class distribution of all the experience datasets",
   "id": "32f7aecc5666b507"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Iterate over all experience datasets (1, 2, 3)\n",
    "for exp_id in [1, 2, 3]:\n",
    "    # Check if the experience dataset exists (in case an experience was skipped)\n",
    "    if exp_id in experience_datasets:\n",
    "        # Select only the 'img_path' and 'hotend_class' columns\n",
    "        balanced_dataset_filtered = experience_datasets[exp_id][['img_path', 'hotend_class']]\n",
    "\n",
    "        # Check the class distribution in the filtered dataset\n",
    "        class_distribution = balanced_dataset_filtered['hotend_class'].value_counts()\n",
    "        \n",
    "        # Print the class distribution for the current experience\n",
    "        print(f\"\\nClass distribution for Experience {exp_id}:\")\n",
    "        print(class_distribution)"
   ],
   "id": "84535699bd125895",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Printing the indices, the classes, and the number of images in each class",
   "id": "77f6b191f590e6f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Iterate over all experience datasets (1, 2, 3)\n",
    "for exp_id in [1, 2, 3]:\n",
    "    # Check if the experience dataset exists (in case an experience was skipped)\n",
    "    if exp_id in experience_datasets:\n",
    "        # Select only the 'img_path' and 'hotend_class' columns for the current experience dataset\n",
    "        balanced_dataset_filtered = experience_datasets[exp_id][['img_path', 'hotend_class']]\n",
    "\n",
    "        # Get the class distribution for the current experience dataset\n",
    "        class_distribution = balanced_dataset_filtered['hotend_class'].value_counts()\n",
    "        \n",
    "        # Step 1: Print the indices, the classes, and the number of images in each class\n",
    "        print(f\"\\n--- Experience {exp_id} ---\")\n",
    "        for class_label in class_distribution.index:\n",
    "            # Get all indices for the current class\n",
    "            class_indices = balanced_dataset_filtered[balanced_dataset_filtered['hotend_class'] == class_label].index.tolist()\n",
    "\n",
    "            # Count the number of images for the current class\n",
    "            num_images_in_class = len(class_indices)\n",
    "\n",
    "            # Print the details for this class\n",
    "            print(f\"\\nClass: {class_label} (Total images: {num_images_in_class})\")\n",
    "            print(\"Indices: \", class_indices)\n",
    "            print(f\"Number of images in class {class_label}: {num_images_in_class}\")\n",
    "\n",
    "        # Step 2: Get the number of unique classes\n",
    "        num_classes = len(class_distribution)\n",
    "\n",
    "        # Step 3: Set a small batch size\n",
    "        small_batch_size = 15  # You can change this to a value like 32, 64, etc.\n",
    "\n",
    "        # Step 4: Calculate the number of samples per class per batch\n",
    "        samples_per_class = small_batch_size // num_classes  # Ensure it's divisible\n",
    "\n",
    "        # Make sure we don't ask for more samples than available in the smallest class\n",
    "        samples_per_class = min(samples_per_class, class_distribution.min())\n",
    "\n",
    "        # Step 5: Calculate the total batch size\n",
    "        batch_size = samples_per_class * num_classes\n",
    "\n",
    "        print(f\"\\nRecommended Small Batch Size for Experience {exp_id}: {batch_size}\")\n",
    "        print(f\"Samples per class in Experience {exp_id}: {samples_per_class}\")\n",
    "        print(\"-\" * 50)  # To separate each experience's results"
   ],
   "id": "49fc331070b94ce1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create training, validation, and testing datasets",
   "id": "1be9c1eebf9fd709"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Iterate over all experience datasets (1, 2, 3)\n",
    "for exp_id in [1, 2, 3]:\n",
    "    # Check if the experience dataset exists (in case an experience was skipped)\n",
    "    if exp_id in experience_datasets:\n",
    "        # Select only the 'img_path' and 'hotend_class' columns for the current experience dataset\n",
    "        balanced_dataset_filtered = experience_datasets[exp_id][['img_path', 'hotend_class']]\n",
    "\n",
    "        # Number of images per class (this will be the same after balancing)\n",
    "        num_images_per_class = len(balanced_dataset_filtered) // 3  # Assuming there are 3 classes (0, 1, 2)\n",
    "\n",
    "        # Calculate the number of samples per class for train, validation, and test sets\n",
    "        train_size = int(0.7 * num_images_per_class)\n",
    "        valid_size = int(0.15 * num_images_per_class)\n",
    "        test_size = num_images_per_class - train_size - valid_size\n",
    "\n",
    "        # Lists to hold indices for each class's dataset (train, validation, test)\n",
    "        train_indices, valid_indices, test_indices = [], [], []\n",
    "\n",
    "        # Split the data by class (assuming classes are 0, 1, 2)\n",
    "        for class_label in [0, 1, 2]:\n",
    "            class_data = balanced_dataset_filtered[balanced_dataset_filtered['hotend_class'] == class_label].index.tolist()\n",
    "\n",
    "            # Shuffle the indices of the current class\n",
    "            random.shuffle(class_data)\n",
    "\n",
    "            # Split the indices for each class into train, validation, and test\n",
    "            train_indices.extend(class_data[:train_size])\n",
    "            valid_indices.extend(class_data[train_size:train_size + valid_size])\n",
    "            test_indices.extend(class_data[train_size + valid_size:])\n",
    "\n",
    "        # Sort the indices to ensure consistent processing\n",
    "        train_indices, valid_indices, test_indices = sorted(train_indices), sorted(valid_indices), sorted(test_indices)\n",
    "\n",
    "        # Create DataFrames for train, validation, and test sets based on the indices\n",
    "        globals()[f'train_{exp_id}'] = balanced_dataset_filtered.loc[train_indices].reset_index(drop=True)\n",
    "        globals()[f'valid_{exp_id}'] = balanced_dataset_filtered.loc[valid_indices].reset_index(drop=True)\n",
    "        globals()[f'test_{exp_id}'] = balanced_dataset_filtered.loc[test_indices].reset_index(drop=True)\n",
    "\n",
    "        # Count class distribution for each of the datasets\n",
    "        def count_class_distribution(indices):\n",
    "            class_counts = [0, 0, 0]  # Assuming 3 classes (0, 1, 2)\n",
    "            for index in indices:\n",
    "                class_label = balanced_dataset_filtered.loc[index, 'hotend_class']\n",
    "                class_counts[class_label] += 1\n",
    "            return class_counts\n",
    "\n",
    "        # Count class distribution for each of the datasets\n",
    "        train_class_distribution = count_class_distribution(train_indices)\n",
    "        valid_class_distribution = count_class_distribution(valid_indices)\n",
    "        test_class_distribution = count_class_distribution(test_indices)\n",
    "\n",
    "        # Print the class distribution and dataset sizes\n",
    "        print(f\"\\n--- Experience {exp_id} ---\")\n",
    "        print(f\"Train set size: {len(train_indices)} | Class distribution: {train_class_distribution}\")\n",
    "        print(f\"Validation set size: {len(valid_indices)} | Class distribution: {valid_class_distribution}\")\n",
    "        print(f\"Test set size: {len(test_indices)} | Class distribution: {test_class_distribution}\")\n",
    "\n",
    "        print(f\"Experience {exp_id} datasets created successfully!\\n\")\n",
    "\n",
    "# Now, the datasets are directly available as:\n",
    "# train_1, valid_1, test_1, train_2, valid_2, test_2, train_3, valid_3, test_3"
   ],
   "id": "cb6e91a94bc66fc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check for Missing or Invalid Labels in Training, Validation, and Test Data",
   "id": "9c6d9800330d9cf0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for any missing labels or invalid labels\n",
    "print(train_1['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(train_1['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(train_2['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(train_2['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(train_3['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(train_3['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(valid_1['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(valid_1['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(valid_2['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(valid_2['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(valid_3['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(valid_3['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(test_1['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(test_1['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(test_2['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(test_2['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(test_3['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(test_3['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values"
   ],
   "id": "9013740cba3d35b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Balanced Dataset class",
   "id": "8cd987e605164710"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the dataset class\n",
    "class BalancedDataset(Dataset):\n",
    "    def __init__(self, data_frame, root_dir, transform=None):\n",
    "        self.data = data_frame\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Validate that the images exist in the directory\n",
    "        self.valid_indices = self.get_valid_indices()\n",
    "\n",
    "    def get_valid_indices(self):\n",
    "        valid_indices = []\n",
    "        for idx in tqdm(range(len(self.data)), desc=\"Validating images\"):\n",
    "            img_name = self.data.iloc[idx, 0].strip()\n",
    "            img_name = img_name.split('/')[-1]  # Extract file name\n",
    "            \n",
    "            if img_name.startswith(\"image-\"):\n",
    "                try:\n",
    "                    # Ensure we only include images in the valid range\n",
    "                    image_number = int(img_name.split('-')[1].split('.')[0])\n",
    "                    if 4 <= image_number <= 26637:\n",
    "                        full_img_path = os.path.join(self.root_dir, img_name)\n",
    "                        if os.path.exists(full_img_path):\n",
    "                            valid_indices.append(idx)\n",
    "                        else:\n",
    "                            print(f\"Image does not exist: {full_img_path}\")\n",
    "                except ValueError:\n",
    "                    print(f\"Invalid filename format for {img_name}. Skipping...\")\n",
    "        \n",
    "        print(f\"Total valid indices found: {len(valid_indices)}\")  # Debugging output\n",
    "        return valid_indices\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.valid_indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Wrap around the index if it exceeds the length of valid indices.\n",
    "        idx = idx % len(self.valid_indices)\n",
    "        \n",
    "        # Get the actual index from valid indices.\n",
    "        actual_idx = self.valid_indices[idx]\n",
    "        img_name = self.data.iloc[actual_idx, 0].strip()\n",
    "        full_img_path = os.path.join(self.root_dir, img_name)\n",
    "        \n",
    "        # Extract the label from the DataFrame (assumed to be in column index 1).\n",
    "        label = self.data.iloc[actual_idx, 1]\n",
    "        \n",
    "        try:\n",
    "            # Attempt to open the image and convert it to RGB.\n",
    "            image = Image.open(full_img_path).convert('RGB')\n",
    "            \n",
    "            # Apply transformations if defined.\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            # Return image, label, and a dummy task_label (set as None).\n",
    "            return image, label\n",
    "        except (OSError, IOError, ValueError) as e:\n",
    "            print(f\"Error loading image {full_img_path}: {e}\")\n",
    "            # If error occurs, try the next valid index.\n",
    "            return self.__getitem__((idx + 1) % len(self.valid_indices))"
   ],
   "id": "f9b871fcd654111f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Balanced Batch Sampler class",
   "id": "f288ab510f111651"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class BalancedBatchSampler(Sampler):\n",
    "    def __init__(self, data_frame, batch_size=15, samples_per_class=5):\n",
    "        \"\"\"\n",
    "        data_frame: Pandas DataFrame with image paths and their respective class labels.\n",
    "        batch_size: Total batch size.\n",
    "        samples_per_class: Number of samples to draw from each class per batch.\n",
    "        \"\"\"\n",
    "        self.data_frame = data_frame\n",
    "        self.batch_size = batch_size\n",
    "        self.samples_per_class = samples_per_class\n",
    "        self.num_classes = len(data_frame['hotend_class'].unique())\n",
    "        \n",
    "        if self.batch_size % self.num_classes != 0:\n",
    "            raise ValueError(\"Batch size must be divisible by the number of classes.\")\n",
    "\n",
    "        self.class_indices = {\n",
    "            class_id: self.data_frame[self.data_frame['hotend_class'] == class_id].index.tolist()\n",
    "            for class_id in self.data_frame['hotend_class'].unique()\n",
    "        }\n",
    "        \n",
    "        # Shuffle class indices initially\n",
    "        for class_id in self.class_indices:\n",
    "            random.shuffle(self.class_indices[class_id])\n",
    "\n",
    "        self.num_samples_per_epoch = sum(len(indices) for indices in self.class_indices.values())\n",
    "        self.indices_used = {class_id: [] for class_id in self.class_indices}\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = []\n",
    "\n",
    "        # Replenish indices for each class\n",
    "        for class_id in self.class_indices:\n",
    "            if not self.class_indices[class_id]:\n",
    "                raise ValueError(f\"Class {class_id} has no samples. Cannot form balanced batches.\")\n",
    "\n",
    "            # Shuffle and use all indices from this class\n",
    "            self.indices_used[class_id] = self.class_indices[class_id].copy()\n",
    "            random.shuffle(self.indices_used[class_id])\n",
    "\n",
    "        # Generate balanced batches\n",
    "        while len(batches) * self.batch_size < self.num_samples_per_epoch:\n",
    "            batch = []\n",
    "            for class_id in self.indices_used:\n",
    "                if len(self.indices_used[class_id]) < self.samples_per_class:\n",
    "                    # If a class runs out of samples, reshuffle and replenish\n",
    "                    self.indices_used[class_id] = self.class_indices[class_id].copy()\n",
    "                    random.shuffle(self.indices_used[class_id])\n",
    "\n",
    "                # Take `samples_per_class` indices from the current class\n",
    "                batch.extend(self.indices_used[class_id][:self.samples_per_class])\n",
    "                self.indices_used[class_id] = self.indices_used[class_id][self.samples_per_class:]\n",
    "\n",
    "            # Shuffle the batch and append\n",
    "            random.shuffle(batch)\n",
    "            batches.append(batch)\n",
    "\n",
    "        return iter(batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Total number of batches per epoch\n",
    "        return self.num_samples_per_epoch // self.batch_size"
   ],
   "id": "d5d08879cfc9d799",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define a dictionary to store datasets and DataLoaders\n",
    "datasets = {}\n",
    "dataloaders = {}\n",
    "\n",
    "# Iterate over all experience datasets (1, 2, 3)\n",
    "for exp_id in [1, 2, 3]:\n",
    "    # Ensure the dataset exists\n",
    "    if f\"train_{exp_id}\" in globals():\n",
    "        train_data = globals()[f\"train_{exp_id}\"]\n",
    "        val_data = globals()[f\"valid_{exp_id}\"]\n",
    "        test_data = globals()[f\"test_{exp_id}\"]\n",
    "\n",
    "        # Create dataset instances\n",
    "        datasets[f\"train_{exp_id}\"] = BalancedDataset(data_frame=train_data, root_dir=root_dir)\n",
    "        datasets[f\"valid_{exp_id}\"] = BalancedDataset(data_frame=val_data, root_dir=root_dir)\n",
    "        datasets[f\"test_{exp_id}\"] = BalancedDataset(data_frame=test_data, root_dir=root_dir)\n",
    "\n",
    "        # Create batch samplers for balanced training\n",
    "        train_sampler = BalancedBatchSampler(data_frame=train_data, batch_size=15, samples_per_class=5)\n",
    "        val_sampler = BalancedBatchSampler(data_frame=val_data, batch_size=15, samples_per_class=5)\n",
    "        test_sampler = BalancedBatchSampler(data_frame=test_data, batch_size=15, samples_per_class=5)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        dataloaders[f\"train_{exp_id}\"] = DataLoader(datasets[f\"train_{exp_id}\"], batch_sampler=train_sampler, shuffle=False)\n",
    "        dataloaders[f\"valid_{exp_id}\"] = DataLoader(datasets[f\"valid_{exp_id}\"], batch_sampler=val_sampler, shuffle=False)\n",
    "        dataloaders[f\"test_{exp_id}\"] = DataLoader(datasets[f\"test_{exp_id}\"], batch_sampler=test_sampler)\n",
    "\n",
    "        # Print dataset lengths\n",
    "        print(f\"   Experience {exp_id} datasets and DataLoaders created successfully!\")\n",
    "        print(f\"   Train dataset length: {len(datasets[f'train_{exp_id}'])}\")\n",
    "        print(f\"   Validation dataset length: {len(datasets[f'valid_{exp_id}'])}\")\n",
    "        print(f\"   Test dataset length: {len(datasets[f'test_{exp_id}'])}\")"
   ],
   "id": "d19ddec286b9fbfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Checking class distribution in each dataset",
   "id": "9180cb3e72c81f3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def count_classes(dataset):\n",
    "    # Extract labels from the dataset's data attribute (assuming labels are in column 1)\n",
    "    values = [x for x in dataset.data.iloc[:, 1]]\n",
    "    # Convert the list of values to a tensor.\n",
    "    t = torch.tensor(values)\n",
    "    # Convert the tensor to a NumPy array and count the classes.\n",
    "    return Counter(t.numpy())\n",
    "\n",
    "print(\"Class distribution in Train Dataset 1:\", count_classes(datasets[\"train_1\"]))\n",
    "print(\"Class distribution in Train Dataset 2:\", count_classes(datasets[\"train_2\"]))\n",
    "print(\"Class distribution in Train Dataset 3:\", count_classes(datasets[\"train_3\"]))\n",
    "print(\"Class distribution in Validation Dataset 1:\", count_classes(datasets[\"valid_1\"]))\n",
    "print(\"Class distribution in Validation Dataset 2:\", count_classes(datasets[\"valid_2\"]))\n",
    "print(\"Class distribution in Validation Dataset 3:\", count_classes(datasets[\"valid_3\"]))\n",
    "print(\"Class distribution in Test Dataset 1:\", count_classes(datasets[\"test_1\"]))\n",
    "print(\"Class distribution in Test Dataset 2:\", count_classes(datasets[\"test_2\"]))\n",
    "print(\"Class distribution in Test Dataset 3:\", count_classes(datasets[\"test_3\"]))"
   ],
   "id": "96784ab22b358e59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating experience datasets",
   "id": "f4a234f763d772c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Experience 1 datasets (just single datasets)\n",
    "exp1_train = datasets[\"train_1\"]\n",
    "exp1_valid = datasets[\"valid_1\"]\n",
    "exp1_test  = datasets[\"test_1\"]\n",
    "\n",
    "# Experience 1_2 datasets (concatenating the corresponding datasets)\n",
    "exp1_2_train = ConcatDataset([datasets[\"train_1\"], datasets[\"train_2\"]])\n",
    "exp1_2_valid = ConcatDataset([datasets[\"valid_1\"], datasets[\"valid_2\"]])\n",
    "exp1_2_test  = ConcatDataset([datasets[\"test_1\"],  datasets[\"test_2\"]])\n",
    "\n",
    "# Experience 1_2_3 datasets (concatenating all three experiences)\n",
    "exp1_2_3_train = ConcatDataset([datasets[\"train_1\"], datasets[\"train_2\"], datasets[\"train_3\"]])\n",
    "exp1_2_3_valid = ConcatDataset([datasets[\"valid_1\"], datasets[\"valid_2\"], datasets[\"valid_3\"]])\n",
    "exp1_2_3_test  = ConcatDataset([datasets[\"test_1\"],  datasets[\"test_2\"],  datasets[\"test_3\"]])"
   ],
   "id": "794b7a7beae8f8b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Checking class distribution in each experience dataset",
   "id": "45ac6737aadc6ea6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def count_classes(dataset):\n",
    "    counts = Counter()\n",
    "    # If the dataset is a ConcatDataset, iterate through its sub-datasets\n",
    "    if isinstance(dataset, ConcatDataset):\n",
    "        for d in dataset.datasets:\n",
    "            values = [x for x in d.data.iloc[:, 1]]  # assuming labels are in column 1\n",
    "            t = torch.tensor(values)\n",
    "            counts.update(Counter(t.numpy()))\n",
    "    else:\n",
    "        values = [x for x in dataset.data.iloc[:, 1]]\n",
    "        t = torch.tensor(values)\n",
    "        counts = Counter(t.numpy())\n",
    "    return counts\n",
    "\n",
    "# Assuming you have already defined the new experience datasets:\n",
    "# Experience 1 datasets\n",
    "print(\"Class distribution in Experience 1 train dataset:\", count_classes(exp1_train))\n",
    "print(\"Class distribution in Experience 1 valid dataset:\", count_classes(exp1_valid))\n",
    "print(\"Class distribution in Experience 1 test dataset:\", count_classes(exp1_test))\n",
    "\n",
    "# Experience 1_2 datasets\n",
    "print(\"Class distribution in Experience 1_2 train dataset:\", count_classes(exp1_2_train))\n",
    "print(\"Class distribution in Experience 1_2 valid dataset:\", count_classes(exp1_2_valid))\n",
    "print(\"Class distribution in Experience 1_2 test dataset:\", count_classes(exp1_2_test))\n",
    "\n",
    "# Experience 1_2_3 datasets\n",
    "print(\"Class distribution in Experience 1_2_3 train dataset:\", count_classes(exp1_2_3_train))\n",
    "print(\"Class distribution in Experience 1_2_3 valid dataset:\", count_classes(exp1_2_3_valid))\n",
    "print(\"Class distribution in Experience 1_2_3 test dataset:\", count_classes(exp1_2_3_test))"
   ],
   "id": "e8255614bb752dc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Benchmark experiment",
   "id": "66eb8c7c0cd152a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from models.cnn_models import SimpleCNN\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Assume that you have already defined your following datasets:\n",
    "#   exp1_train, exp1_valid, exp1_test,\n",
    "#   exp1_2_train, exp1_2_valid, exp1_2_test,\n",
    "#   exp1_2_3_train, exp1_2_3_valid, exp1_2_3_test\n",
    "#\n",
    "# Also assume that your model class (SimpleCNN) and confusion matrix\n",
    "# class (ConfusionMatrix) are defined.\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Define the experiment configurations in a dictionary.\n",
    "experiments = {\n",
    "    \"experience_1\": (exp1_train, exp1_valid, exp1_test),\n",
    "    \"experience_1_2\": (exp1_2_train, exp1_2_valid, exp1_2_test),\n",
    "    \"experience_1_2_3\": (exp1_2_3_train, exp1_2_3_valid, exp1_2_3_test)\n",
    "}\n",
    "\n",
    "# Create the top-level benchmark experiment folder.\n",
    "benchmark_folder = \"benchmark_experiment\"\n",
    "os.makedirs(benchmark_folder, exist_ok=True)\n",
    "\n",
    "# Training settings\n",
    "num_epochs = 30\n",
    "batch_size = 15\n",
    "num_classes = 3  # update if needed\n",
    "\n",
    "# Loop over each experiment configuration.\n",
    "for exp_name, (train_dataset, val_dataset, test_dataset) in experiments.items():\n",
    "    print(f\"\\nStarting experiment: {exp_name}\\n\")\n",
    "    \n",
    "    # Create a subfolder for this experiment.\n",
    "    exp_folder = os.path.join(benchmark_folder, exp_name)\n",
    "    os.makedirs(exp_folder, exist_ok=True)\n",
    "    \n",
    "    # Set the best model path (e.g., benchmark_experiment/experience_1/model_experience_1.pth)\n",
    "    best_model_path = os.path.join(exp_folder, f\"model_{exp_name}.pth\")\n",
    "    \n",
    "    # Create DataLoaders for train, validation, and test.\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Set device to GPU if available.\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Initialize model, loss function, optimizer, and scheduler.\n",
    "    model = SimpleCNN(num_classes=num_classes).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    \n",
    "    # Initialize confusion matrix trackers.\n",
    "    train_cm = ConfusionMatrix(task='multiclass', num_classes=num_classes).to(device)\n",
    "    val_cm = ConfusionMatrix(task='multiclass', num_classes=num_classes).to(device)\n",
    "    \n",
    "    # For plotting losses.\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # Create CSV file to store epoch losses in the experiment folder.\n",
    "    csv_file_path = os.path.join(exp_folder, \"training_validation_losses.csv\")\n",
    "    header = [\"Epoch\", \"Training Loss\", \"Validation Loss\"]\n",
    "    if not os.path.exists(csv_file_path):\n",
    "        with open(csv_file_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(header)\n",
    "    \n",
    "    best_val_accuracy = 0.0\n",
    "    start_epoch = 0  # always start fresh for each experiment\n",
    "    \n",
    "    # ----------------- Training and Validation Loop -----------------\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        class_counts = [0] * num_classes\n",
    "        \n",
    "        # Training phase with progress bar.\n",
    "        for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            print(f\"Outputs (Raw): {outputs}\")  # Log raw outputs\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            # Update confusion matrix and class counts.\n",
    "            train_cm.update(predicted, labels)\n",
    "            for label in labels:\n",
    "                class_counts[label.item()] += 1\n",
    "                \n",
    "            # Print predicted vs actual labels for each batch.\n",
    "            for i in range(len(labels)):\n",
    "                print(f\"Predicted: {predicted[i].item()}, Actual: {labels[i].item()}\")\n",
    "        \n",
    "        train_epoch_loss = running_loss / total_samples\n",
    "        train_epoch_accuracy = correct_predictions / total_samples\n",
    "        print(f\"Training Loss: {train_epoch_loss:.4f}, Training Accuracy: {train_epoch_accuracy:.4f}\")\n",
    "        print(f\"Training Class Distribution: {class_counts}\")\n",
    "        \n",
    "        # Update learning rate scheduler.\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_losses.append(train_epoch_loss)\n",
    "        \n",
    "        # Compute and save training confusion matrix.\n",
    "        cm_train = train_cm.compute()\n",
    "        print(f\"Training Confusion Matrix:\\n{cm_train}\")\n",
    "        sns.heatmap(cm_train.cpu().numpy(), annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title(f'Training Confusion Matrix - Epoch {epoch + 1}')\n",
    "        output_path_train = os.path.join(exp_folder, f\"training_confusion_matrix_epoch_{epoch + 1}.png\")\n",
    "        plt.savefig(output_path_train)\n",
    "        plt.clf()  # Clear the plot\n",
    "        print(f\"Training Confusion Matrix saved to: {output_path_train}\")\n",
    "        train_cm.reset()\n",
    "        \n",
    "        # ----------------- Validation Phase -----------------\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_samples = 0\n",
    "        val_class_counts = [0] * num_classes\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                print(f\"Outputs (Raw): {outputs}\")  # Log raw outputs\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct_predictions += (predicted == labels).sum().item()\n",
    "                val_total_samples += labels.size(0)\n",
    "                \n",
    "                val_cm.update(predicted, labels)\n",
    "                for label in labels:\n",
    "                    val_class_counts[label.item()] += 1\n",
    "                \n",
    "                for i in range(len(labels)):\n",
    "                    print(f\"Predicted: {predicted[i].item()}, Actual: {labels[i].item()}\")\n",
    "        \n",
    "        val_epoch_loss = val_loss / val_total_samples\n",
    "        val_epoch_accuracy = val_correct_predictions / val_total_samples\n",
    "        print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy:.4f}\")\n",
    "        print(f\"Validation Class Distribution: {val_class_counts}\")\n",
    "        val_losses.append(val_epoch_loss)\n",
    "        \n",
    "        cm_val = val_cm.compute()\n",
    "        print(f\"Validation Confusion Matrix:\\n{cm_val}\")\n",
    "        sns.heatmap(cm_val.cpu().numpy(), annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title(f'Validation Confusion Matrix - Epoch {epoch + 1}')\n",
    "        output_path_val = os.path.join(exp_folder, f\"validation_confusion_matrix_epoch_{epoch + 1}.png\")\n",
    "        plt.savefig(output_path_val)\n",
    "        plt.clf()\n",
    "        print(f\"Validation Confusion Matrix saved to: {output_path_val}\")\n",
    "        val_cm.reset()\n",
    "        \n",
    "        # Save the best model if validation accuracy improves.\n",
    "        if val_epoch_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_epoch_accuracy\n",
    "            torch.save({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"scheduler_state\": scheduler.state_dict(),\n",
    "                \"best_val_accuracy\": best_val_accuracy\n",
    "            }, best_model_path)\n",
    "            print(f\"Saved best model for {exp_name} at epoch {epoch + 1} with accuracy {best_val_accuracy:.4f}\")\n",
    "        \n",
    "        # Append losses to CSV.\n",
    "        with open(csv_file_path, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([epoch + 1, train_epoch_loss, val_epoch_loss])\n",
    "    \n",
    "    print(f\"Experiment {exp_name} training complete. Losses saved to: {csv_file_path}\")\n",
    "    \n",
    "    # ----------------- Testing Phase -----------------\n",
    "    def test_model(model, test_loader):\n",
    "        model.eval()\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        test_class_counts = [0] * num_classes\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                for label in labels:\n",
    "                    test_class_counts[label.item()] += 1\n",
    "                for i in range(len(labels)):\n",
    "                    print(f\"Predicted: {predicted[i].item()}, Actual: {labels[i].item()}\")\n",
    "        avg_accuracy = correct_predictions / total_samples\n",
    "        print(f\"Test Accuracy: {avg_accuracy:.4f}\")\n",
    "        print(f\"Test Class Distribution: {test_class_counts}\")\n",
    "        \n",
    "        # Compute confusion matrix using sklearn\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        cm_test = confusion_matrix(all_labels, all_predictions, labels=list(range(num_classes)))\n",
    "        print(f\"Test Confusion Matrix:\\n{cm_test}\")\n",
    "        \n",
    "        sns.heatmap(cm_test, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Test Confusion Matrix')\n",
    "        output_path_test = os.path.join(exp_folder, \"test_confusion_matrix.png\")\n",
    "        plt.savefig(output_path_test)\n",
    "        plt.clf()\n",
    "        print(f\"Test Confusion Matrix saved to: {output_path_test}\")\n",
    "\n",
    "    \n",
    "    test_model(model, test_loader)\n",
    "    \n",
    "    # (Optionally, you can also plot the training and validation losses for each experiment.)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', color='blue')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', color='red')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training and Validation Losses for {exp_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    loss_plot_path = os.path.join(exp_folder, \"training_validation_loss.png\")\n",
    "    plt.savefig(loss_plot_path)\n",
    "    plt.clf()\n",
    "    print(f\"Training and Validation Loss plot saved to: {loss_plot_path}\")\n",
    "\n",
    "print(\"\\nAll benchmark experiments completed.\")"
   ],
   "id": "96f2be13ef5c1514",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1677100730c47f3c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
