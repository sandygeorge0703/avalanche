{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing libraries",
   "id": "cf83250ee7f63eeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, Sampler, SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "from tqdm import tqdm  \n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.utils.data import ConcatDataset\n",
    "import random\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "# Allow loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ],
   "id": "b8061d6902ab803b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating dataset for multiple parts",
   "id": "e5880ea370f06f28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define file paths as constants\n",
    "CSV_FILE_PATH = r'C:\\Users\\Sandhra George\\avalanche\\data\\dataset.csv'\n",
    "ROOT_DIR_PATH = r'C:\\Users\\Sandhra George\\avalanche\\caxton_dataset'  # Common parent directory\n",
    "\n",
    "# Load data into a DataFrame for easier processing\n",
    "data = pd.read_csv(CSV_FILE_PATH)\n",
    "\n",
    "# Filter the dataset to include images containing \"print24\", \"print131\", or \"print0\"\n",
    "pattern = 'print24|print131|print0|print46|print86|print109'\n",
    "data_filtered = data[data.iloc[:, 0].str.contains(pattern, na=False)]\n",
    "\n",
    "# Update the first column to include both the print folder and the image filename.\n",
    "# The regex now captures the folder name (print24, print131, or print0) and the image filename.\n",
    "data_filtered.iloc[:, 0] = data_filtered.iloc[:, 0].str.replace(\n",
    "    r'.*?/(print24|print131|print0|print46|print86|print109)/(image-\\d+\\.jpg)', \n",
    "    r'\\1/\\2', \n",
    "    regex=True\n",
    ")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"First rows of filtered DataFrame:\")\n",
    "print(data_filtered.head())\n",
    "\n",
    "print(\"\\nLast rows of filtered DataFrame:\")\n",
    "print(data_filtered.tail())"
   ],
   "id": "d3bbf0a5d513fd0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analysing the target hotend temperature column",
   "id": "5d0423ac0a8bc90c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract unique temperatures in the 'target_hotend' column and sort them\n",
    "unique_temperatures = sorted(data_filtered['target_hotend'].unique())  # Sort temperatures in ascending order\n",
    "\n",
    "# Calculate the full range of temperatures (min and max)\n",
    "temperature_min = data_filtered['target_hotend'].min()\n",
    "temperature_max = data_filtered['target_hotend'].max()\n",
    "\n",
    "# Print the unique temperatures (sorted), count, and full range\n",
    "print(\"\\nUnique target hotend temperatures in the dataset (sorted):\")\n",
    "print(unique_temperatures)\n",
    "print(f\"\\nNumber of unique target hotend temperatures: {len(unique_temperatures)}\")\n",
    "print(f\"Temperature range: {temperature_min} to {temperature_max}\")"
   ],
   "id": "f29c405cf341b9ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a random temperature sub list and new dataframes with equal class distribution",
   "id": "a22e7cd8879fcbeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract unique temperatures and sort them\n",
    "unique_temperatures = sorted(data_filtered['target_hotend'].unique())  # Sort temperatures in ascending order\n",
    "\n",
    "# Check if we have enough unique temperatures to select from\n",
    "if len(unique_temperatures) >= 69:\n",
    "    # Select the lowest and highest temperatures\n",
    "    temperature_min = unique_temperatures[0]\n",
    "    temperature_max = unique_temperatures[-1]\n",
    "\n",
    "    # Remove the lowest and highest temperatures from the unique temperatures list\n",
    "    remaining_temperatures = [temp for temp in unique_temperatures if temp != temperature_min and temp != temperature_max]\n",
    "\n",
    "    # Randomly select 40 other temperatures from the remaining ones\n",
    "    random_temperatures = random.sample(remaining_temperatures, 50)\n",
    "\n",
    "    # Add the random temperatures to the temperature_sublist\n",
    "    temperature_sublist = [temperature_min, temperature_max] + random_temperatures\n",
    "    \n",
    "    # Sort from lowest to highest hotend temperature\n",
    "    temperature_sublist = sorted(temperature_sublist)\n",
    "\n",
    "    # Print the temperature sublist\n",
    "    print(\"\\nTemperature sublist:\")\n",
    "    print(temperature_sublist)\n",
    "    \n",
    "    # Split into three experience groups\n",
    "    split_size = len(temperature_sublist) // 3\n",
    "    experience_1 = temperature_sublist[:split_size]  # First third\n",
    "    experience_2 = temperature_sublist[split_size:2*split_size]  # Second third\n",
    "    experience_3 = temperature_sublist[2*split_size:]  # Last third\n",
    "\n",
    "    # Print the results\n",
    "    print(\"\\nExperience Group 1:\", experience_1)\n",
    "    print(\"\\nExperience Group 2:\", experience_2)\n",
    "    print(\"\\nExperience Group 3:\", experience_3)\n",
    "else:\n",
    "    print(\"Not enough unique temperatures to select from. At least 50 unique temperatures are required.\")\n",
    "    experience_1 = experience_2 = experience_3 = []\n",
    "\n",
    "# Initialize a dictionary to store DataFrames for each class per experience\n",
    "experience_datasets = {1: {}, 2: {}, 3: {}}\n",
    "\n",
    "# Iterate through the three experience groups\n",
    "for exp_id, experience_temps in enumerate([experience_1, experience_2, experience_3], start=1):\n",
    "    if not experience_temps:\n",
    "        print(f\"Skipping Experience {exp_id} due to insufficient temperatures.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing Experience {exp_id} with temperatures: {experience_temps}...\")\n",
    "\n",
    "    # Filter the dataset based on the current experience's temperature range\n",
    "    exp_data = data_filtered[data_filtered['target_hotend'].isin(experience_temps)]\n",
    "    \n",
    "    # Check if exp_data is empty after filtering\n",
    "    if exp_data.empty:\n",
    "        print(f\"No data found for Experience {exp_id} with temperatures {experience_temps}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Create a dictionary to store class-wise data for this experience\n",
    "    class_datasets = {}\n",
    "\n",
    "    # Iterate through each class (0, 1, 2) and filter data\n",
    "    for class_id in [0, 1, 2]:\n",
    "        class_data = exp_data[exp_data['hotend_class'] == class_id]\n",
    "        \n",
    "        if class_data.empty:\n",
    "            print(f\"Warning: Class {class_id} in Experience {exp_id} has no data!\")\n",
    "        else:\n",
    "            class_datasets[class_id] = class_data\n",
    "            print(f\"Class {class_id} dataset size in Experience {exp_id}: {len(class_data)}\")\n",
    "\n",
    "    # Ensure that all classes have data before proceeding to balance\n",
    "    if len(class_datasets) != 3:\n",
    "        print(f\"Skipping Experience {exp_id} because one or more classes are missing data!\")\n",
    "        continue  # Skip processing this experience if any class has no data\n",
    "\n",
    "    # Find the smallest class size in this experience\n",
    "    min_class_size = min(len(class_datasets[class_id]) for class_id in class_datasets)\n",
    "    print(f\"Smallest class size in Experience {exp_id}: {min_class_size}\")\n",
    "\n",
    "    # Balance the dataset for this experience\n",
    "    balanced_data = []\n",
    "\n",
    "    for class_id in class_datasets:\n",
    "        class_data = class_datasets[class_id]\n",
    "        # Randomly sample 'min_class_size' images from the class data to balance class distribution\n",
    "        sampled_class_data = class_data.sample(n=min_class_size, random_state=42)  # Sample equally\n",
    "        balanced_data.append(sampled_class_data)\n",
    "\n",
    "    # Combine all class data for this experience into one balanced dataset\n",
    "    balanced_dataset = pd.concat(balanced_data).reset_index(drop=True)\n",
    "\n",
    "    # Shuffle the final balanced dataset\n",
    "    balanced_dataset = balanced_dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Store the balanced dataset in the experience_datasets dictionary\n",
    "    experience_datasets[exp_id] = balanced_dataset\n",
    "\n",
    "    # Print summary for this experience\n",
    "    print(f\"\\nBalanced dataset size for Experience {exp_id}: {len(balanced_dataset)}\")\n",
    "    print(\"Number of images in each class after balancing:\")\n",
    "\n",
    "    for class_id in [0, 1, 2]:\n",
    "        class_count = len(balanced_dataset[balanced_dataset['hotend_class'] == class_id])\n",
    "        print(f\"Class {class_id}: {class_count} images\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Print the first few rows for verification\n",
    "for exp_id in [1, 2, 3]:\n",
    "    if exp_id in experience_datasets:\n",
    "        print(f\"\\nFirst five rows of Experience {exp_id} dataset:\")\n",
    "        print(experience_datasets[exp_id].head())"
   ],
   "id": "47acde363e257d88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Checking the class distribution of all the experience datasets",
   "id": "32f7aecc5666b507"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Iterate over all experience datasets (1, 2, 3)\n",
    "for exp_id in [1, 2, 3]:\n",
    "    # Check if the experience dataset exists (in case an experience was skipped)\n",
    "    if exp_id in experience_datasets:\n",
    "        # Select only the 'img_path' and 'hotend_class' columns\n",
    "        balanced_dataset_filtered = experience_datasets[exp_id][['img_path', 'hotend_class']]\n",
    "\n",
    "        # Check the class distribution in the filtered dataset\n",
    "        class_distribution = balanced_dataset_filtered['hotend_class'].value_counts()\n",
    "        \n",
    "        # Print the class distribution for the current experience\n",
    "        print(f\"\\nClass distribution for Experience {exp_id}:\")\n",
    "        print(class_distribution)"
   ],
   "id": "84535699bd125895",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Printing the indices, the classes, and the number of images in each class",
   "id": "77f6b191f590e6f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Iterate over all experience datasets (1, 2, 3)\n",
    "for exp_id in [1, 2, 3]:\n",
    "    # Check if the experience dataset exists (in case an experience was skipped)\n",
    "    if exp_id in experience_datasets:\n",
    "        # Select only the 'img_path' and 'hotend_class' columns for the current experience dataset\n",
    "        balanced_dataset_filtered = experience_datasets[exp_id][['img_path', 'hotend_class']]\n",
    "\n",
    "        # Get the class distribution for the current experience dataset\n",
    "        class_distribution = balanced_dataset_filtered['hotend_class'].value_counts()\n",
    "        \n",
    "        # Step 1: Print the indices, the classes, and the number of images in each class\n",
    "        print(f\"\\n--- Experience {exp_id} ---\")\n",
    "        for class_label in class_distribution.index:\n",
    "            # Get all indices for the current class\n",
    "            class_indices = balanced_dataset_filtered[balanced_dataset_filtered['hotend_class'] == class_label].index.tolist()\n",
    "\n",
    "            # Count the number of images for the current class\n",
    "            num_images_in_class = len(class_indices)\n",
    "\n",
    "            # Print the details for this class\n",
    "            print(f\"\\nClass: {class_label} (Total images: {num_images_in_class})\")\n",
    "            print(\"Indices: \", class_indices)\n",
    "            print(f\"Number of images in class {class_label}: {num_images_in_class}\")\n",
    "\n",
    "        # Step 2: Get the number of unique classes\n",
    "        num_classes = len(class_distribution)\n",
    "\n",
    "        # Step 3: Set a small batch size\n",
    "        small_batch_size = 15  # You can change this to a value like 32, 64, etc.\n",
    "\n",
    "        # Step 4: Calculate the number of samples per class per batch\n",
    "        samples_per_class = small_batch_size // num_classes  # Ensure it's divisible\n",
    "\n",
    "        # Make sure we don't ask for more samples than available in the smallest class\n",
    "        samples_per_class = min(samples_per_class, class_distribution.min())\n",
    "\n",
    "        # Step 5: Calculate the total batch size\n",
    "        batch_size = samples_per_class * num_classes\n",
    "\n",
    "        print(f\"\\nRecommended Small Batch Size for Experience {exp_id}: {batch_size}\")\n",
    "        print(f\"Samples per class in Experience {exp_id}: {samples_per_class}\")\n",
    "        print(\"-\" * 50)  # To separate each experience's results"
   ],
   "id": "49fc331070b94ce1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create training, validation, and testing datasets",
   "id": "1be9c1eebf9fd709"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Iterate over all experience datasets (1, 2, 3)\n",
    "for exp_id in [1, 2, 3]:\n",
    "    # Check if the experience dataset exists (in case an experience was skipped)\n",
    "    if exp_id in experience_datasets:\n",
    "        # Select only the 'img_path' and 'hotend_class' columns for the current experience dataset\n",
    "        balanced_dataset_filtered = experience_datasets[exp_id][['img_path', 'hotend_class']]\n",
    "\n",
    "        # Number of images per class (this will be the same after balancing)\n",
    "        num_images_per_class = len(balanced_dataset_filtered) // 3  # Assuming there are 3 classes (0, 1, 2)\n",
    "\n",
    "        # Calculate the number of samples per class for train, validation, and test sets\n",
    "        train_size = int(0.7 * num_images_per_class)\n",
    "        valid_size = int(0.15 * num_images_per_class)\n",
    "        test_size = num_images_per_class - train_size - valid_size\n",
    "\n",
    "        # Lists to hold indices for each class's dataset (train, validation, test)\n",
    "        train_indices, valid_indices, test_indices = [], [], []\n",
    "\n",
    "        # Split the data by class (assuming classes are 0, 1, 2)\n",
    "        for class_label in [0, 1, 2]:\n",
    "            class_data = balanced_dataset_filtered[balanced_dataset_filtered['hotend_class'] == class_label].index.tolist()\n",
    "\n",
    "            # Shuffle the indices of the current class\n",
    "            random.shuffle(class_data)\n",
    "\n",
    "            # Split the indices for each class into train, validation, and test\n",
    "            train_indices.extend(class_data[:train_size])\n",
    "            valid_indices.extend(class_data[train_size:train_size + valid_size])\n",
    "            test_indices.extend(class_data[train_size + valid_size:])\n",
    "\n",
    "        # Sort the indices to ensure consistent processing\n",
    "        train_indices, valid_indices, test_indices = sorted(train_indices), sorted(valid_indices), sorted(test_indices)\n",
    "\n",
    "        # Create DataFrames for train, validation, and test sets based on the indices\n",
    "        globals()[f'train_{exp_id}'] = balanced_dataset_filtered.loc[train_indices].reset_index(drop=True)\n",
    "        globals()[f'valid_{exp_id}'] = balanced_dataset_filtered.loc[valid_indices].reset_index(drop=True)\n",
    "        globals()[f'test_{exp_id}'] = balanced_dataset_filtered.loc[test_indices].reset_index(drop=True)\n",
    "\n",
    "        # Count class distribution for each of the datasets\n",
    "        def count_class_distribution(indices):\n",
    "            class_counts = [0, 0, 0]  # Assuming 3 classes (0, 1, 2)\n",
    "            for index in indices:\n",
    "                class_label = balanced_dataset_filtered.loc[index, 'hotend_class']\n",
    "                class_counts[class_label] += 1\n",
    "            return class_counts\n",
    "\n",
    "        # Count class distribution for each of the datasets\n",
    "        train_class_distribution = count_class_distribution(train_indices)\n",
    "        valid_class_distribution = count_class_distribution(valid_indices)\n",
    "        test_class_distribution = count_class_distribution(test_indices)\n",
    "\n",
    "        # Print the class distribution and dataset sizes\n",
    "        print(f\"\\n--- Experience {exp_id} ---\")\n",
    "        print(f\"Train set size: {len(train_indices)} | Class distribution: {train_class_distribution}\")\n",
    "        print(f\"Validation set size: {len(valid_indices)} | Class distribution: {valid_class_distribution}\")\n",
    "        print(f\"Test set size: {len(test_indices)} | Class distribution: {test_class_distribution}\")\n",
    "\n",
    "        print(f\"Experience {exp_id} datasets created successfully!\\n\")\n",
    "\n",
    "# Now, the datasets are directly available as:\n",
    "# train_1, valid_1, test_1, train_2, valid_2, test_2, train_3, valid_3, test_3"
   ],
   "id": "cb6e91a94bc66fc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check for Missing or Invalid Labels in Training, Validation, and Test Data",
   "id": "9c6d9800330d9cf0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for any missing labels or invalid labels\n",
    "print(train_1['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(train_1['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(train_2['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(train_2['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(train_3['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(train_3['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(valid_1['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(valid_1['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(valid_2['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(valid_2['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(valid_3['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(valid_3['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(test_1['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(test_1['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(test_2['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(test_2['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values\n",
    "\n",
    "print(test_3['hotend_class'].isnull().sum())  # Count missing labels\n",
    "print(test_3['hotend_class'].unique())  # Check unique labels to ensure there are no unexpected values"
   ],
   "id": "9013740cba3d35b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BalancedBatchSampler class",
   "id": "f288ab510f111651"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class BalancedBatchSampler(torch.utils.data.Sampler):\n",
    "    def __init__(self, data_frame, batch_size=15, samples_per_class=5):\n",
    "        \"\"\"\n",
    "        data_frame: Pandas DataFrame with image paths and their respective class labels.\n",
    "        batch_size: Total batch size.\n",
    "        samples_per_class: Number of samples to draw from each class per batch.\n",
    "        \"\"\"\n",
    "        self.data_frame = data_frame\n",
    "        self.batch_size = batch_size\n",
    "        self.samples_per_class = samples_per_class\n",
    "        self.num_classes = len(data_frame['hotend_class'].unique())\n",
    "        \n",
    "        if self.batch_size % self.num_classes != 0:\n",
    "            raise ValueError(\"Batch size must be divisible by the number of classes.\")\n",
    "\n",
    "        # Build a dictionary of indices per class.\n",
    "        self.class_indices = {\n",
    "            class_id: self.data_frame[self.data_frame['hotend_class'] == class_id].index.tolist()\n",
    "            for class_id in self.data_frame['hotend_class'].unique()\n",
    "        }\n",
    "        for class_id in self.class_indices:\n",
    "            random.shuffle(self.class_indices[class_id])\n",
    "        self.num_samples_per_epoch = sum(len(indices) for indices in self.class_indices.values())\n",
    "        self.indices_used = {class_id: [] for class_id in self.class_indices}\n",
    "    \n",
    "    def __iter__(self):\n",
    "        batches = []\n",
    "        # Replenish indices for each class.\n",
    "        for class_id in self.class_indices:\n",
    "            if not self.class_indices[class_id]:\n",
    "                raise ValueError(f\"Class {class_id} has no samples. Cannot form balanced batches.\")\n",
    "            self.indices_used[class_id] = self.class_indices[class_id].copy()\n",
    "            random.shuffle(self.indices_used[class_id])\n",
    "        # Generate balanced batches.\n",
    "        while len(batches) * self.batch_size < self.num_samples_per_epoch:\n",
    "            batch = []\n",
    "            for class_id in self.indices_used:\n",
    "                if len(self.indices_used[class_id]) < self.samples_per_class:\n",
    "                    self.indices_used[class_id] = self.class_indices[class_id].copy()\n",
    "                    random.shuffle(self.indices_used[class_id])\n",
    "                batch.extend(self.indices_used[class_id][:self.samples_per_class])\n",
    "                self.indices_used[class_id] = self.indices_used[class_id][self.samples_per_class:]\n",
    "            random.shuffle(batch)\n",
    "            batches.append(batch)\n",
    "        return iter(batches)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples_per_epoch // self.batch_size"
   ],
   "id": "811ae227ec729e72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BalancedDataset Class",
   "id": "6a109876853c92de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class BalancedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_frame, root_dir, transform=None, debug=False, max_retries=5):\n",
    "        self.debug = debug\n",
    "        self.root_dir = root_dir\n",
    "        # Reset index to ensure proper positional indexing.\n",
    "        self.data = data_frame.reset_index(drop=True)\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.max_retries = max_retries\n",
    "        if self.debug:\n",
    "            print(f\"Dataset length (filtered): {len(self.data)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        attempts = 0\n",
    "        original_idx = idx\n",
    "        while attempts < self.max_retries:\n",
    "            idx = idx % len(self.data)\n",
    "            try:\n",
    "                # Use .iloc for positional indexing.\n",
    "                row = self.data.iloc[idx]\n",
    "                img_path = row.iloc[0].strip()  # e.g., \"print24/image-123.jpg\"\n",
    "                full_img_path = os.path.join(self.root_dir, img_path)\n",
    "                label = row.iloc[1]\n",
    "                image = Image.open(full_img_path).convert('RGB')\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                return image, label\n",
    "            except Exception as e:\n",
    "                if self.debug:\n",
    "                    print(f\"Error loading image at index {idx} ({full_img_path}): {e}\")\n",
    "                # Try the next index.\n",
    "                idx += 1\n",
    "                attempts += 1\n",
    "        # If max_retries reached without success, raise an error.\n",
    "        raise RuntimeError(f\"Max retries ({self.max_retries}) exceeded for index {original_idx}.\")"
   ],
   "id": "22fb7e2b62df8e8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filter and Reindex Function",
   "id": "9406da0a9050d687"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#####################################\n",
    "# 3. Filter and Reindex Function\n",
    "#####################################\n",
    "def filter_and_reindex(data_frame, root_dir):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame to include only rows with valid image paths\n",
    "    and then reindexes the DataFrame so that indices are contiguous.\n",
    "    \"\"\"\n",
    "    valid_indices = []\n",
    "    allowed_folders = {\"print24\", \"print131\", \"print0\", \"print46\",\"print86\",\"print109\"}\n",
    "    for idx in range(len(data_frame)):\n",
    "        img_path = data_frame.iloc[idx, 0].strip()\n",
    "        parts = img_path.split('/')\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        folder, file_name = parts[0], parts[1]\n",
    "        if folder not in allowed_folders:\n",
    "            continue\n",
    "        if not file_name.startswith(\"image-\"):\n",
    "            continue\n",
    "        full_img_path = os.path.join(root_dir, folder, file_name)\n",
    "        if os.path.exists(full_img_path):\n",
    "            valid_indices.append(idx)\n",
    "    filtered_df = data_frame.iloc[valid_indices].reset_index(drop=True)\n",
    "    return filtered_df"
   ],
   "id": "b30ce1500147a39f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Function to Print Random Batch Distributions",
   "id": "79b3921989359ba5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#####################################\n",
    "# 4. Function to Print Random Batch Distributions\n",
    "#####################################\n",
    "def print_random_batches_from_loader(loader, num_batches=3, dataset_name=\"Dataset\"):\n",
    "    print(f\"\\nRandom batch label distributions for {dataset_name}:\")\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        if batch_idx >= num_batches:\n",
    "            break\n",
    "        label_counts = Counter(labels.numpy())\n",
    "        print(f\"Batch {batch_idx + 1} distribution: {label_counts}\")"
   ],
   "id": "50502d61575c0f0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#####################################\n",
    "# 5. Main Code: Loop Over Experiments (1, 2, 3)\n",
    "#####################################\n",
    "\n",
    "# Define the root directory\n",
    "ROOT_DIR_PATH = r'C:\\Users\\Sandhra George\\avalanche\\caxton_dataset'\n",
    "root_dir = ROOT_DIR_PATH\n",
    "\n",
    "# Loop over experiment numbers.\n",
    "for exp_id in [1, 2, 3]:\n",
    "    print(f\"\\n=== Processing Experience {exp_id} ===\")\n",
    "    # Access the corresponding global DataFrames.\n",
    "    # Ensure these DataFrames (train_1, train_2, etc.) are defined.\n",
    "    original_train_df = globals()[f\"train_{exp_id}\"]\n",
    "    original_valid_df = globals()[f\"valid_{exp_id}\"]\n",
    "    original_test_df  = globals()[f\"test_{exp_id}\"]\n",
    "\n",
    "    # Filter and reindex for each split.\n",
    "    filtered_train_data = filter_and_reindex(original_train_df, root_dir)\n",
    "    filtered_valid_data = filter_and_reindex(original_valid_df, root_dir)\n",
    "    filtered_test_data  = filter_and_reindex(original_test_df, root_dir)\n",
    "\n",
    "    # Create dataset instances using the filtered DataFrames.\n",
    "    train_dataset = BalancedDataset(filtered_train_data, root_dir, debug=False)\n",
    "    valid_dataset = BalancedDataset(filtered_valid_data, root_dir, debug=False)\n",
    "    test_dataset  = BalancedDataset(filtered_test_data, root_dir, debug=False)\n",
    "\n",
    "    # Create balanced batch samplers using the same filtered DataFrames.\n",
    "    train_sampler = BalancedBatchSampler(data_frame=filtered_train_data, batch_size=15, samples_per_class=5)\n",
    "    valid_sampler = BalancedBatchSampler(data_frame=filtered_valid_data, batch_size=15, samples_per_class=5)\n",
    "    test_sampler  = BalancedBatchSampler(data_frame=filtered_test_data,  batch_size=15, samples_per_class=5)\n",
    "\n",
    "    # Create DataLoaders using the custom balanced batch samplers.\n",
    "    train_loader = DataLoader(train_dataset, batch_sampler=train_sampler)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_sampler=valid_sampler)\n",
    "    test_loader  = DataLoader(test_dataset,  batch_sampler=test_sampler)\n",
    "\n",
    "    # Print random batch distributions for each split.\n",
    "    print_random_batches_from_loader(train_loader, num_batches=3, dataset_name=f\"Experience {exp_id} Train\")\n",
    "    print_random_batches_from_loader(valid_loader, num_batches=3, dataset_name=f\"Experience {exp_id} Validation\")\n",
    "    print_random_batches_from_loader(test_loader,  num_batches=3, dataset_name=f\"Experience {exp_id} Test\")"
   ],
   "id": "562987ae34ec2e05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Checking class distribution in each dataset",
   "id": "9180cb3e72c81f3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_class_distribution(df):\n",
    "    \"\"\"\n",
    "    Count occurrences of each class in the 'hotend_class' column of the DataFrame.\n",
    "    \"\"\"\n",
    "    return Counter(df['hotend_class'])\n",
    "\n",
    "# Loop over all experiments (assuming they are named train_1, valid_1, test_1, etc.)\n",
    "for exp_id in [1, 2, 3]:\n",
    "    # Retrieve each dataset using globals()\n",
    "    train_df = globals()[f\"train_{exp_id}\"]\n",
    "    valid_df = globals()[f\"valid_{exp_id}\"]\n",
    "    test_df  = globals()[f\"test_{exp_id}\"]\n",
    "    \n",
    "    # Count the class distribution\n",
    "    train_dist = count_class_distribution(train_df)\n",
    "    valid_dist = count_class_distribution(valid_df)\n",
    "    test_dist  = count_class_distribution(test_df)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"\\n--- Experience {exp_id} ---\")\n",
    "    print(f\"Train dataset size: {len(train_df)} | Class distribution: {train_dist}\")\n",
    "    print(f\"Validation dataset size: {len(valid_df)} | Class distribution: {valid_dist}\")\n",
    "    print(f\"Test dataset size: {len(test_df)} | Class distribution: {test_dist}\")"
   ],
   "id": "96784ab22b358e59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating experience datasets",
   "id": "f4a234f763d772c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "def wrap_dataset(ds, root_dir):\n",
    "    \"\"\"\n",
    "    Given ds, which may be a BalancedDataset (with a .data attribute)\n",
    "    or a plain DataFrame, return a new BalancedDataset constructed\n",
    "    from the underlying DataFrame with a reset index.\n",
    "    \"\"\"\n",
    "    if hasattr(ds, 'data'):\n",
    "        df = ds.data.reset_index(drop=True)\n",
    "    else:\n",
    "        # Assume ds is a DataFrame.\n",
    "        df = ds.reset_index(drop=True)\n",
    "    return BalancedDataset(df, root_dir, debug=False)\n",
    "\n",
    "# Experience 1 datasets (single datasets)\n",
    "exp1_train = globals()[\"train_1\"]\n",
    "exp1_valid = globals()[\"valid_1\"]\n",
    "exp1_test  = globals()[\"test_1\"]\n",
    "\n",
    "# For Experience 1_2, re-wrap the underlying DataFrames and then concatenate.\n",
    "exp1_2_train = ConcatDataset([\n",
    "    wrap_dataset(globals()[\"train_1\"], root_dir),\n",
    "    wrap_dataset(globals()[\"train_2\"], root_dir)\n",
    "])\n",
    "exp1_2_valid = ConcatDataset([\n",
    "    wrap_dataset(globals()[\"valid_1\"], root_dir),\n",
    "    wrap_dataset(globals()[\"valid_2\"], root_dir)\n",
    "])\n",
    "exp1_2_test = ConcatDataset([\n",
    "    wrap_dataset(globals()[\"test_1\"], root_dir),\n",
    "    wrap_dataset(globals()[\"test_2\"], root_dir)\n",
    "])\n",
    "\n",
    "# For Experience 1_2_3, re-wrap and concatenate datasets from experiences 1, 2, and 3.\n",
    "exp1_2_3_train = ConcatDataset([\n",
    "    wrap_dataset(globals()[\"train_1\"], root_dir),\n",
    "    wrap_dataset(globals()[\"train_2\"], root_dir),\n",
    "    wrap_dataset(globals()[\"train_3\"], root_dir)\n",
    "])\n",
    "exp1_2_3_valid = ConcatDataset([\n",
    "    wrap_dataset(globals()[\"valid_1\"], root_dir),\n",
    "    wrap_dataset(globals()[\"valid_2\"], root_dir),\n",
    "    wrap_dataset(globals()[\"valid_3\"], root_dir)\n",
    "])\n",
    "exp1_2_3_test = ConcatDataset([\n",
    "    wrap_dataset(globals()[\"test_1\"], root_dir),\n",
    "    wrap_dataset(globals()[\"test_2\"], root_dir),\n",
    "    wrap_dataset(globals()[\"test_3\"], root_dir)\n",
    "])"
   ],
   "id": "794b7a7beae8f8b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_balanced_loader(dataset, root_dir, batch_size=15, samples_per_class=5):\n",
    "    \"\"\"\n",
    "    Given an experience dataset (plain DataFrame, BalancedDataset, or ConcatDataset),\n",
    "    create a DataLoader using a BalancedBatchSampler built from the underlying data.\n",
    "    \"\"\"\n",
    "    # If dataset is a plain DataFrame, wrap it.\n",
    "    if isinstance(dataset, pd.DataFrame):\n",
    "        dataset = BalancedDataset(dataset, root_dir, debug=False)\n",
    "    \n",
    "    # Determine the DataFrame to use for the sampler.\n",
    "    if hasattr(dataset, 'data'):\n",
    "        data_for_sampler = dataset.data.reset_index(drop=True)\n",
    "    elif isinstance(dataset, ConcatDataset):\n",
    "        data_frames = []\n",
    "        for d in dataset.datasets:\n",
    "            if hasattr(d, 'data'):\n",
    "                data_frames.append(d.data.reset_index(drop=True))\n",
    "            elif isinstance(d, pd.DataFrame):\n",
    "                data_frames.append(d.reset_index(drop=True))\n",
    "            else:\n",
    "                raise ValueError(\"Sub-dataset type not recognized.\")\n",
    "        data_for_sampler = pd.concat(data_frames, ignore_index=True)\n",
    "    else:\n",
    "        raise ValueError(\"Dataset type not recognized for sampler creation.\")\n",
    "    \n",
    "    sampler = BalancedBatchSampler(data_frame=data_for_sampler, batch_size=batch_size, samples_per_class=samples_per_class)\n",
    "    loader = DataLoader(dataset, batch_sampler=sampler)\n",
    "    return loader"
   ],
   "id": "93b974ad0fdb91b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# Create DataLoaders for each experience dataset.\n",
    "# =============================================================================\n",
    "\n",
    "exp1_train_loader    = create_balanced_loader(exp1_train, root_dir, batch_size=15, samples_per_class=5)\n",
    "exp1_valid_loader    = create_balanced_loader(exp1_valid, root_dir, batch_size=15, samples_per_class=5)\n",
    "exp1_test_loader     = create_balanced_loader(exp1_test,  root_dir, batch_size=15, samples_per_class=5)\n",
    "\n",
    "exp1_2_train_loader  = create_balanced_loader(exp1_2_train, root_dir, batch_size=15, samples_per_class=5)\n",
    "exp1_2_valid_loader  = create_balanced_loader(exp1_2_valid, root_dir, batch_size=15, samples_per_class=5)\n",
    "exp1_2_test_loader   = create_balanced_loader(exp1_2_test,  root_dir, batch_size=15, samples_per_class=5)\n",
    "\n",
    "exp1_2_3_train_loader = create_balanced_loader(exp1_2_3_train, root_dir, batch_size=15, samples_per_class=5)\n",
    "exp1_2_3_valid_loader = create_balanced_loader(exp1_2_3_valid, root_dir, batch_size=15, samples_per_class=5)\n",
    "exp1_2_3_test_loader  = create_balanced_loader(exp1_2_3_test,  root_dir, batch_size=15, samples_per_class=5)"
   ],
   "id": "8098bcb29d86670e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_batches_from_loader(loader, num_batches=3, dataset_name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Iterates through the given DataLoader and prints the label distribution\n",
    "    for the first `num_batches` batches.\n",
    "    \n",
    "    Args:\n",
    "        loader (DataLoader): The DataLoader to iterate over.\n",
    "        num_batches (int): Number of batches to print.\n",
    "        dataset_name (str): Name of the dataset (for printing purposes).\n",
    "    \"\"\"\n",
    "    print(f\"\\nBatch label distributions for {dataset_name}:\")\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        if batch_idx >= num_batches:\n",
    "            break\n",
    "        # Ensure labels are on CPU and convert to a numpy array for counting.\n",
    "        label_counts = Counter(labels.cpu().numpy())\n",
    "        print(f\"Batch {batch_idx + 1} distribution: {label_counts}\")"
   ],
   "id": "4316ff627bae3b0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For Experience 1:\n",
    "print_batches_from_loader(exp1_train_loader, num_batches=3, dataset_name=\"Experience 1 Train\")\n",
    "print_batches_from_loader(exp1_valid_loader, num_batches=3, dataset_name=\"Experience 1 Validation\")\n",
    "print_batches_from_loader(exp1_test_loader,  num_batches=3, dataset_name=\"Experience 1 Test\")\n",
    "\n",
    "# For Experience 1_2:\n",
    "print_batches_from_loader(exp1_2_train_loader, num_batches=3, dataset_name=\"Experience 1_2 Train\")\n",
    "print_batches_from_loader(exp1_2_valid_loader, num_batches=3, dataset_name=\"Experience 1_2 Validation\")\n",
    "print_batches_from_loader(exp1_2_test_loader,  num_batches=3, dataset_name=\"Experience 1_2 Test\")\n",
    "\n",
    "# For Experience 1_2_3:\n",
    "print_batches_from_loader(exp1_2_3_train_loader, num_batches=3, dataset_name=\"Experience 1_2_3 Train\")\n",
    "print_batches_from_loader(exp1_2_3_valid_loader, num_batches=3, dataset_name=\"Experience 1_2_3 Validation\")\n",
    "print_batches_from_loader(exp1_2_3_test_loader,  num_batches=3, dataset_name=\"Experience 1_2_3 Test\")"
   ],
   "id": "dfc48f88b1409dfd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Checking class distribution in each experience dataset",
   "id": "45ac6737aadc6ea6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "from torch.utils.data import ConcatDataset\n",
    "import pandas as pd\n",
    "\n",
    "def count_classes(dataset):\n",
    "    counts = Counter()\n",
    "    \n",
    "    # If the dataset is a plain DataFrame:\n",
    "    if isinstance(dataset, pd.DataFrame):\n",
    "        values = dataset.iloc[:, 1].tolist()\n",
    "        counts.update(values)\n",
    "    # If it's a ConcatDataset:\n",
    "    elif isinstance(dataset, ConcatDataset):\n",
    "        for d in dataset.datasets:\n",
    "            if isinstance(d, pd.DataFrame):\n",
    "                values = d.iloc[:, 1].tolist()\n",
    "            elif hasattr(d, 'data'):\n",
    "                values = d.data.iloc[:, 1].tolist()\n",
    "            else:\n",
    "                raise ValueError(\"Sub-dataset type not recognized.\")\n",
    "            counts.update(values)\n",
    "    # If it's an object with a 'data' attribute:\n",
    "    elif hasattr(dataset, 'data'):\n",
    "        values = dataset.data.iloc[:, 1].tolist()\n",
    "        counts.update(values)\n",
    "    else:\n",
    "        raise ValueError(\"Dataset type not recognized.\")\n",
    "    \n",
    "    return counts\n",
    "\n",
    "# Now, print the class distributions for your experience datasets.\n",
    "# For Experience 1:\n",
    "print(\"Class distribution in Experience 1 train dataset:\", count_classes(exp1_train))\n",
    "print(\"Class distribution in Experience 1 valid dataset:\", count_classes(exp1_valid))\n",
    "print(\"Class distribution in Experience 1 test dataset:\", count_classes(exp1_test))\n",
    "\n",
    "# For Experience 1_2:\n",
    "print(\"Class distribution in Experience 1_2 train dataset:\", count_classes(exp1_2_train))\n",
    "print(\"Class distribution in Experience 1_2 valid dataset:\", count_classes(exp1_2_valid))\n",
    "print(\"Class distribution in Experience 1_2 test dataset:\", count_classes(exp1_2_test))\n",
    "\n",
    "# For Experience 1_2_3:\n",
    "print(\"Class distribution in Experience 1_2_3 train dataset:\", count_classes(exp1_2_3_train))\n",
    "print(\"Class distribution in Experience 1_2_3 valid dataset:\", count_classes(exp1_2_3_valid))\n",
    "print(\"Class distribution in Experience 1_2_3 test dataset:\", count_classes(exp1_2_3_test))"
   ],
   "id": "e8255614bb752dc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_dataset_size(dataset):\n",
    "    # If the dataset is a plain DataFrame:\n",
    "    if isinstance(dataset, pd.DataFrame):\n",
    "        return len(dataset)\n",
    "    # If it's a ConcatDataset:\n",
    "    elif isinstance(dataset, ConcatDataset):\n",
    "        return sum(len(d) for d in dataset.datasets)\n",
    "    # If it has a __len__ attribute (like BalancedDataset)\n",
    "    elif hasattr(dataset, '__len__'):\n",
    "        return len(dataset)\n",
    "    else:\n",
    "        raise ValueError(\"Dataset type not recognized.\")\n",
    "\n",
    "# Now, print the sizes and class distributions for your experience datasets.\n",
    "# For Experience 1:\n",
    "print(\"Size of Experience 1 train dataset:\", get_dataset_size(exp1_train))\n",
    "print(\"Class distribution in Experience 1 train dataset:\", count_classes(exp1_train))\n",
    "print(\"Size of Experience 1 valid dataset:\", get_dataset_size(exp1_valid))\n",
    "print(\"Class distribution in Experience 1 valid dataset:\", count_classes(exp1_valid))\n",
    "print(\"Size of Experience 1 test dataset:\", get_dataset_size(exp1_test))\n",
    "print(\"Class distribution in Experience 1 test dataset:\", count_classes(exp1_test))\n",
    "\n",
    "# For Experience 1_2:\n",
    "print(\"Size of Experience 1_2 train dataset:\", get_dataset_size(exp1_2_train))\n",
    "print(\"Class distribution in Experience 1_2 train dataset:\", count_classes(exp1_2_train))\n",
    "print(\"Size of Experience 1_2 valid dataset:\", get_dataset_size(exp1_2_valid))\n",
    "print(\"Class distribution in Experience 1_2 valid dataset:\", count_classes(exp1_2_valid))\n",
    "print(\"Size of Experience 1_2 test dataset:\", get_dataset_size(exp1_2_test))\n",
    "print(\"Class distribution in Experience 1_2 test dataset:\", count_classes(exp1_2_test))\n",
    "\n",
    "# For Experience 1_2_3:\n",
    "print(\"Size of Experience 1_2_3 train dataset:\", get_dataset_size(exp1_2_3_train))\n",
    "print(\"Class distribution in Experience 1_2_3 train dataset:\", count_classes(exp1_2_3_train))\n",
    "print(\"Size of Experience 1_2_3 valid dataset:\", get_dataset_size(exp1_2_3_valid))\n",
    "print(\"Class distribution in Experience 1_2_3 valid dataset:\", count_classes(exp1_2_3_valid))\n",
    "print(\"Size of Experience 1_2_3 test dataset:\", get_dataset_size(exp1_2_3_test))\n",
    "print(\"Class distribution in Experience 1_2_3 test dataset:\", count_classes(exp1_2_3_test))"
   ],
   "id": "95553f4275041966",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Benchmark experiment with training and validation accuracy plot",
   "id": "66eb8c7c0cd152a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from models.cnn_models import SimpleCNN\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define the experiment configurations in a dictionary.\n",
    "experiments = {\n",
    "    #\"experience_1\": (exp1_train, exp1_valid, exp1_test),\n",
    "    #\"experience_1_2\": (exp1_2_train, exp1_2_valid, exp1_2_test),\n",
    "    \"experience_1_2_3\": (exp1_2_3_train, exp1_2_3_valid, exp1_2_3_test)\n",
    "}\n",
    "\n",
    "# Create a mapping between experiment names and your new DataLoader variables.\n",
    "# (Make sure these variables are already created: exp1_train_loader, exp1_valid_loader, etc.)\n",
    "# For example:\n",
    "#   \"experience_1\" --> exp1_train_loader, exp1_valid_loader, exp1_test_loader\n",
    "#   \"experience_1_2\" --> exp1_2_train_loader, exp1_2_valid_loader, exp1_2_test_loader\n",
    "#   \"experience_1_2_3\" --> exp1_2_3_train_loader, exp1_2_3_valid_loader, exp1_2_3_test_loader\n",
    "\n",
    "# Get the current working directory and define the benchmark folder.\n",
    "current_dir = os.getcwd()\n",
    "benchmark_folder = os.path.join(current_dir, \"benchmark_experiment_increased_data\")\n",
    "os.makedirs(benchmark_folder, exist_ok=True)\n",
    "print(f\"Benchmark folder created at: {benchmark_folder}\")\n",
    "\n",
    "# Training settings\n",
    "num_epochs = 30\n",
    "num_classes = 3  # update if needed\n",
    "\n",
    "# Loop over each experiment configuration.\n",
    "for exp_name, _ in experiments.items():\n",
    "    print(f\"\\nStarting experiment: {exp_name}\\n\")\n",
    "    \n",
    "    # Create a subfolder for this experiment.\n",
    "    exp_folder = os.path.join(benchmark_folder, exp_name)\n",
    "    os.makedirs(exp_folder, exist_ok=True)\n",
    "    \n",
    "    # Set the best model path.\n",
    "    best_model_path = os.path.join(exp_folder, f\"model_{exp_name}.pth\")\n",
    "    \n",
    "    # Retrieve the appropriate pre-created DataLoaders.\n",
    "    if exp_name == \"experience_1\":\n",
    "        train_loader = exp1_train_loader\n",
    "        val_loader = exp1_valid_loader\n",
    "        test_loader = exp1_test_loader\n",
    "    elif exp_name == \"experience_1_2\":\n",
    "        train_loader = exp1_2_train_loader\n",
    "        val_loader = exp1_2_valid_loader\n",
    "        test_loader = exp1_2_test_loader\n",
    "    elif exp_name == \"experience_1_2_3\":\n",
    "        train_loader = exp1_2_3_train_loader\n",
    "        val_loader = exp1_2_3_valid_loader\n",
    "        test_loader = exp1_2_3_test_loader\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown experiment name: {exp_name}\")\n",
    "    \n",
    "    # Set device to GPU if available.\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Initialize model, loss function, optimizer, and scheduler.\n",
    "    model = SimpleCNN(num_classes=num_classes).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    \n",
    "    # Initialize confusion matrix trackers.\n",
    "    train_cm = ConfusionMatrix(task='multiclass', num_classes=num_classes).to(device)\n",
    "    val_cm = ConfusionMatrix(task='multiclass', num_classes=num_classes).to(device)\n",
    "    \n",
    "    # For plotting losses and accuracies.\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Create CSV file to store epoch losses and accuracies.\n",
    "    csv_file_path = os.path.join(exp_folder, \"training_validation_losses.csv\")\n",
    "    header = [\"Epoch\", \"Training Loss\", \"Training Accuracy\", \"Validation Loss\", \"Validation Accuracy\"]\n",
    "    if not os.path.exists(csv_file_path):\n",
    "        with open(csv_file_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(header)\n",
    "    \n",
    "    best_val_accuracy = 0.0\n",
    "    start_epoch = 0  # always start fresh for each experiment\n",
    "    \n",
    "    # ----------------- Training and Validation Loop -----------------\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        class_counts = [0] * num_classes\n",
    "        \n",
    "        # Training phase with progress bar.\n",
    "        for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            #print(f\"Outputs (Raw): {outputs}\")  # Log raw outputs\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            # Update confusion matrix and class counts.\n",
    "            train_cm.update(predicted, labels)\n",
    "            for label in labels:\n",
    "                class_counts[label.item()] += 1\n",
    "                \n",
    "            # Print predicted vs actual labels for each batch.\n",
    "            #for i in range(len(labels)):\n",
    "                #print(f\"Predicted: {predicted[i].item()}, Actual: {labels[i].item()}\")\n",
    "        \n",
    "        train_epoch_loss = running_loss / total_samples\n",
    "        train_epoch_accuracy = correct_predictions / total_samples\n",
    "        print(f\"Training Loss: {train_epoch_loss:.4f}, Training Accuracy: {train_epoch_accuracy:.4f}\")\n",
    "        print(f\"Training Class Distribution: {class_counts}\")\n",
    "        \n",
    "        # Update learning rate scheduler.\n",
    "        scheduler.step()\n",
    "        train_losses.append(train_epoch_loss)\n",
    "        train_accuracies.append(train_epoch_accuracy)\n",
    "        \n",
    "        # Compute and save training confusion matrix.\n",
    "        cm_train = train_cm.compute()\n",
    "        print(f\"Training Confusion Matrix:\\n{cm_train}\")\n",
    "        sns.heatmap(cm_train.cpu().numpy(), annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title(f'Training Confusion Matrix - Epoch {epoch + 1}')\n",
    "        output_path_train = os.path.join(exp_folder, f\"training_confusion_matrix_epoch_{epoch + 1}.png\")\n",
    "        plt.savefig(output_path_train)\n",
    "        plt.clf()  # Clear the plot\n",
    "        print(f\"Training Confusion Matrix saved to: {output_path_train}\")\n",
    "        train_cm.reset()\n",
    "        \n",
    "        # ----------------- Validation Phase -----------------\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_samples = 0\n",
    "        val_class_counts = [0] * num_classes\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                #print(f\"Outputs (Raw): {outputs}\")  # Log raw outputs\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct_predictions += (predicted == labels).sum().item()\n",
    "                val_total_samples += labels.size(0)\n",
    "                \n",
    "                val_cm.update(predicted, labels)\n",
    "                for label in labels:\n",
    "                    val_class_counts[label.item()] += 1\n",
    "                \n",
    "                #for i in range(len(labels)):\n",
    "                    #print(f\"Predicted: {predicted[i].item()}, Actual: {labels[i].item()}\")\n",
    "        \n",
    "        val_epoch_loss = val_loss / val_total_samples\n",
    "        val_epoch_accuracy = val_correct_predictions / val_total_samples\n",
    "        print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy:.4f}\")\n",
    "        print(f\"Validation Class Distribution: {val_class_counts}\")\n",
    "        val_losses.append(val_epoch_loss)\n",
    "        val_accuracies.append(val_epoch_accuracy)\n",
    "        \n",
    "        cm_val = val_cm.compute()\n",
    "        print(f\"Validation Confusion Matrix:\\n{cm_val}\")\n",
    "        sns.heatmap(cm_val.cpu().numpy(), annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title(f'Validation Confusion Matrix - Epoch {epoch + 1}')\n",
    "        output_path_val = os.path.join(exp_folder, f\"validation_confusion_matrix_epoch_{epoch + 1}.png\")\n",
    "        plt.savefig(output_path_val)\n",
    "        plt.clf()\n",
    "        print(f\"Validation Confusion Matrix saved to: {output_path_val}\")\n",
    "        val_cm.reset()\n",
    "        \n",
    "        # Save the best model if validation accuracy improves.\n",
    "        if val_epoch_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_epoch_accuracy\n",
    "            torch.save({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"scheduler_state\": scheduler.state_dict(),\n",
    "                \"best_val_accuracy\": best_val_accuracy\n",
    "            }, best_model_path)\n",
    "            print(f\"Saved best model for {exp_name} at epoch {epoch + 1} with accuracy {best_val_accuracy:.4f}\")\n",
    "        \n",
    "        # Append losses and accuracies to CSV.\n",
    "        with open(csv_file_path, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([epoch + 1, train_epoch_loss, train_epoch_accuracy, val_epoch_loss, val_epoch_accuracy])\n",
    "    \n",
    "    print(f\"Experiment {exp_name} training complete. Losses saved to: {csv_file_path}\")\n",
    "    \n",
    "    # ----------------- Testing Phase -----------------\n",
    "    def test_model(model, test_loader):\n",
    "        model.eval()\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        test_class_counts = [0] * num_classes\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                for label in labels:\n",
    "                    test_class_counts[label.item()] += 1\n",
    "                #for i in range(len(labels)):\n",
    "                    #print(f\"Predicted: {predicted[i].item()}, Actual: {labels[i].item()}\")\n",
    "        avg_accuracy = correct_predictions / total_samples\n",
    "        print(f\"Test Accuracy: {avg_accuracy:.4f}\")\n",
    "        print(f\"Test Class Distribution: {test_class_counts}\")\n",
    "        \n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        cm_test = confusion_matrix(all_labels, all_predictions, labels=list(range(num_classes)))\n",
    "        print(f\"Test Confusion Matrix:\\n{cm_test}\")\n",
    "        \n",
    "        sns.heatmap(cm_test, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Test Confusion Matrix')\n",
    "        output_path_test = os.path.join(exp_folder, \"test_confusion_matrix.png\")\n",
    "        plt.savefig(output_path_test)\n",
    "        plt.clf()\n",
    "        print(f\"Test Confusion Matrix saved to: {output_path_test}\")\n",
    "    \n",
    "    test_model(model, test_loader)\n",
    "    \n",
    "    # Plot the training and validation losses.\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', color='blue')\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', color='red')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training and Validation Losses for {exp_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    loss_plot_path = os.path.join(exp_folder, \"training_validation_loss.png\")\n",
    "    plt.savefig(loss_plot_path)\n",
    "    plt.clf()\n",
    "    print(f\"Training and Validation Loss plot saved to: {loss_plot_path}\")\n",
    "    \n",
    "    # Plot the training and validation accuracies.\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy', color='blue')\n",
    "    plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy', color='red')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Training and Validation Accuracies for {exp_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    accuracy_plot_path = os.path.join(exp_folder, \"training_validation_accuracy.png\")\n",
    "    plt.savefig(accuracy_plot_path)\n",
    "    plt.clf()\n",
    "    print(f\"Training and Validation Accuracy plot saved to: {accuracy_plot_path}\")\n",
    "\n",
    "print(\"\\nAll benchmark experiments completed.\")"
   ],
   "id": "e514a99a4d40a6b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Checking image and label alignment",
   "id": "fca35b706aa073dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "def display_random_images(dataset, dataset_name, num_images=5, root_folder=r\"C:\\Users\\Sandhra George\\avalanche\\caxton_dataset\"):\n",
    "    \"\"\"\n",
    "    Display num_images random images from the given dataset along with their hotend class labels.\n",
    "    \n",
    "    If the underlying DataFrame has 2 columns:\n",
    "      - Column 0: relative image path (e.g., \"print46/image-8719.jpg\")\n",
    "      - Column 1: hotend class label\n",
    "    If the DataFrame has 3 (or more) columns, it ignores the first column and uses:\n",
    "      - Column 1: relative image path\n",
    "      - Column 2: hotend class label\n",
    "    \n",
    "    The full image path is constructed as:\n",
    "         root_folder/<relative image path>\n",
    "    \n",
    "    If the dataset is a ConcatDataset, the function iterates over its sub-datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    if hasattr(dataset, 'data'):\n",
    "        cols = dataset.data.shape[1]\n",
    "        if cols == 2:\n",
    "            # Structure: [image_path, hotend_label]\n",
    "            get_img_path = lambda row: row[0]\n",
    "            get_label   = lambda row: row[1]\n",
    "        elif cols >= 3:\n",
    "            # Structure: [extra, image_path, hotend_label, ...] – ignore the first column\n",
    "            get_img_path = lambda row: row[1]\n",
    "            get_label   = lambda row: row[2]\n",
    "        else:\n",
    "            print(f\"Dataset {dataset_name} does not have enough columns (got {cols}).\")\n",
    "            return\n",
    "\n",
    "        print(f\"Displaying {num_images} random images from: {dataset_name}\")\n",
    "        sample_indices = random.sample(range(len(dataset.data)), num_images)\n",
    "        for idx in sample_indices:\n",
    "            row = dataset.data.iloc[idx]\n",
    "            # Clean the strings: remove extra spaces and ensure correct separator\n",
    "            img_rel_path = str(get_img_path(row)).strip().replace(\"/\", os.path.sep)\n",
    "            label = str(get_label(row)).strip()\n",
    "            full_path = os.path.join(root_folder, img_rel_path)\n",
    "            \n",
    "            # Debug print: print the full path with repr to reveal any hidden characters\n",
    "            print(f\"Attempting to open: {repr(full_path)}\")\n",
    "            \n",
    "            if not os.path.exists(full_path):\n",
    "                print(f\"File does not exist: {repr(full_path)}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                img = Image.open(full_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error opening {full_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Hotend Class: {label}\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "    elif isinstance(dataset, ConcatDataset):\n",
    "        print(f\"Dataset '{dataset_name}' is a ConcatDataset; iterating through sub-datasets...\")\n",
    "        for i, subdataset in enumerate(dataset.datasets):\n",
    "            display_random_images(subdataset, f\"{dataset_name} - Subdataset {i}\", num_images, root_folder)\n",
    "    else:\n",
    "        print(\"Unsupported dataset type:\", type(dataset))\n",
    "\n",
    "# Example usage:\n",
    "display_random_images(exp1_train, \"Experience 1 Train Dataset\")\n",
    "display_random_images(exp1_valid, \"Experience 1 Valid Dataset\")\n",
    "display_random_images(exp1_test, \"Experience 1 Test Dataset\")\n",
    "\n",
    "display_random_images(exp1_2_train, \"Experience 1_2 Train Dataset\")\n",
    "display_random_images(exp1_2_valid, \"Experience 1_2 Valid Dataset\")\n",
    "display_random_images(exp1_2_test, \"Experience 1_2 Test Dataset\")\n",
    "\n",
    "display_random_images(exp1_2_3_train, \"Experience 1_2_3 Train Dataset\")\n",
    "display_random_images(exp1_2_3_valid, \"Experience 1_2_3 Valid Dataset\")\n",
    "display_random_images(exp1_2_3_test, \"Experience 1_2_3 Test Dataset\")"
   ],
   "id": "f9be2fc46a8b6774",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b175ddadaa945481",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
