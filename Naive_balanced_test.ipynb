{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing libraries ",
   "id": "7870155a64a40826"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:50:07.464672Z",
     "start_time": "2025-03-09T12:50:07.366871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, Sampler, SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "from tqdm import tqdm  \n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.utils.data import ConcatDataset\n",
    "import random\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "# Allow loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ],
   "id": "972f00a4cfa3d4db",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating dataset for multiple parts",
   "id": "ba51d4193a72afb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:52:13.704620Z",
     "start_time": "2025-03-09T12:52:09.998784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define file paths as constants\n",
    "CSV_FILE_PATH = r'C:\\Users\\Sandhra George\\avalanche\\data\\dataset.csv'\n",
    "ROOT_DIR_PATH = r'C:\\Users\\Sandhra George\\avalanche\\caxton_dataset'  # Common parent directory\n",
    "\n",
    "# Load data into a DataFrame for easier processing\n",
    "data = pd.read_csv(CSV_FILE_PATH)\n",
    "\n",
    "# Filter the dataset to include images containing \"print24\", \"print131\", or \"print0\"\n",
    "pattern = 'print24|print131|print0|print46|print82|print109'\n",
    "data_filtered = data[data.iloc[:, 0].str.contains(pattern, na=False)]\n",
    "\n",
    "# Update the first column to include both the print folder and the image filename.\n",
    "# The regex now captures the folder name (print24, print131, or print0) and the image filename.\n",
    "data_filtered.iloc[:, 0] = data_filtered.iloc[:, 0].str.replace(\n",
    "    r'.*?/(print24|print131|print0|print46|print82|print109)/(image-\\d+\\.jpg)', \n",
    "    r'\\1/\\2', \n",
    "    regex=True\n",
    ")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"First rows of filtered DataFrame:\")\n",
    "print(data_filtered.head())\n",
    "\n",
    "print(\"\\nLast rows of filtered DataFrame:\")\n",
    "print(data_filtered.tail())"
   ],
   "id": "adb488900c4619ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First rows of filtered DataFrame:\n",
      "              img_path               timestamp  flow_rate  feed_rate  \\\n",
      "0   print0/image-6.jpg  2020-10-08T13:12:50-34        100        100   \n",
      "1   print0/image-7.jpg  2020-10-08T13:12:50-80        100        100   \n",
      "2   print0/image-8.jpg  2020-10-08T13:12:51-27        100        100   \n",
      "3   print0/image-9.jpg  2020-10-08T13:12:51-74        100        100   \n",
      "4  print0/image-10.jpg  2020-10-08T13:12:52-20        100        100   \n",
      "\n",
      "   z_offset  target_hotend  hotend    bed  nozzle_tip_x  nozzle_tip_y  \\\n",
      "0       0.0          205.0  204.13  65.74           531           554   \n",
      "1       0.0          205.0  204.13  65.74           531           554   \n",
      "2       0.0          205.0  204.24  65.84           531           554   \n",
      "3       0.0          205.0  204.24  65.84           531           554   \n",
      "4       0.0          205.0  204.24  65.84           531           554   \n",
      "\n",
      "   img_num  print_id  flow_rate_class  feed_rate_class  z_offset_class  \\\n",
      "0        5         0                1                1               1   \n",
      "1        6         0                1                1               1   \n",
      "2        7         0                1                1               1   \n",
      "3        8         0                1                1               1   \n",
      "4        9         0                1                1               1   \n",
      "\n",
      "   hotend_class   img_mean    img_std  \n",
      "0             1  18.687230  13.809311  \n",
      "1             1  27.321104  22.875292  \n",
      "2             1  23.138174  17.933411  \n",
      "3             1  21.014212  17.120604  \n",
      "4             1  27.481729  15.091996  \n",
      "\n",
      "Last rows of filtered DataFrame:\n",
      "                        img_path               timestamp  flow_rate  \\\n",
      "685468  print131/image-30191.jpg  2020-10-05T18:15:10-95        121   \n",
      "685469  print131/image-30192.jpg  2020-10-05T18:15:11-42        121   \n",
      "685470  print131/image-30193.jpg  2020-10-05T18:15:11-88        121   \n",
      "685471  print131/image-30194.jpg  2020-10-05T18:15:12-34        121   \n",
      "685472  print131/image-30195.jpg  2020-10-05T18:15:12-81        121   \n",
      "\n",
      "        feed_rate  z_offset  target_hotend  hotend    bed  nozzle_tip_x  \\\n",
      "685468        154      0.11          186.0  187.53  64.62           581   \n",
      "685469        154      0.11          186.0  183.73  64.80           581   \n",
      "685470        154      0.11          186.0  183.73  64.80           581   \n",
      "685471        154      0.11          186.0  183.73  64.80           581   \n",
      "685472        154      0.11          186.0  183.73  64.80           581   \n",
      "\n",
      "        nozzle_tip_y  img_num  print_id  flow_rate_class  feed_rate_class  \\\n",
      "685468           497    30190       131                1                2   \n",
      "685469           497    30191       131                1                2   \n",
      "685470           497    30192       131                1                2   \n",
      "685471           497    30193       131                1                2   \n",
      "685472           497    30194       131                1                2   \n",
      "\n",
      "        z_offset_class  hotend_class   img_mean    img_std  \n",
      "685468               2             0  47.206367  47.890320  \n",
      "685469               2             0  46.294779  47.034876  \n",
      "685470               2             0  51.993301  49.586823  \n",
      "685471               2             0  50.805885  48.459762  \n",
      "685472               2             0  54.112451  50.927826  \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analysing the target hotend temperature column",
   "id": "b53bc861f34b792e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:52:18.347582Z",
     "start_time": "2025-03-09T12:52:18.244355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unique_temperatures = sorted(data_filtered['target_hotend'].unique())\n",
    "\n",
    "if len(unique_temperatures) >= 69:\n",
    "    temperature_min = unique_temperatures[0]\n",
    "    temperature_max = unique_temperatures[-1]\n",
    "    remaining_temperatures = [temp for temp in unique_temperatures if temp not in [temperature_min, temperature_max]]\n",
    "    random_temperatures = random.sample(remaining_temperatures, 50)\n",
    "    temperature_sublist = sorted([temperature_min, temperature_max] + random_temperatures)\n",
    "    \n",
    "    # Split the temperature sublist into three groups (roughly equal thirds)\n",
    "    split_size = len(temperature_sublist) // 3\n",
    "    experience_1 = temperature_sublist[:split_size]\n",
    "    experience_2 = temperature_sublist[split_size:2*split_size]\n",
    "    experience_3 = temperature_sublist[2*split_size:]\n",
    "    \n",
    "    print(\"Temperature sublist:\", temperature_sublist)\n",
    "    print(\"\\nExperience Group 1:\", experience_1)\n",
    "    print(\"Experience Group 2:\", experience_2)\n",
    "    print(\"Experience Group 3:\", experience_3)\n",
    "else:\n",
    "    print(\"Not enough unique temperatures to select from.\")\n",
    "    experience_1 = experience_2 = experience_3 = []\n",
    "\n",
    "# Create a dictionary to store balanced datasets (non-cumulative) for each experience\n",
    "experience_datasets = {}\n",
    "\n",
    "for exp_id, experience_temps in enumerate([experience_1, experience_2, experience_3], start=1):\n",
    "    if not experience_temps:\n",
    "        print(f\"Skipping Experience {exp_id} due to insufficient temperatures.\")\n",
    "        continue\n",
    "    print(f\"\\nProcessing Experience {exp_id} with temperatures: {experience_temps}...\")\n",
    "    \n",
    "    # Filter data for the current experience's temperatures\n",
    "    exp_data = data_filtered[data_filtered['target_hotend'].isin(experience_temps)]\n",
    "    if exp_data.empty:\n",
    "        print(f\"No data found for Experience {exp_id}. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Create dictionary for each class (assumed classes: 0, 1, 2)\n",
    "    class_datasets = {}\n",
    "    for class_id in [0, 1, 2]:\n",
    "        class_data = exp_data[exp_data['hotend_class'] == class_id]\n",
    "        if class_data.empty:\n",
    "            print(f\"Warning: Class {class_id} in Experience {exp_id} has no data!\")\n",
    "        else:\n",
    "            class_datasets[class_id] = class_data\n",
    "    \n",
    "    if len(class_datasets) != 3:\n",
    "        print(f\"Skipping Experience {exp_id} because one or more classes are missing data!\")\n",
    "        continue\n",
    "    \n",
    "    # Balance by sampling the minimum available images per class\n",
    "    min_class_size = min(len(class_datasets[c]) for c in class_datasets)\n",
    "    print(f\"Smallest class size in Experience {exp_id}: {min_class_size}\")\n",
    "    \n",
    "    balanced_data = [class_datasets[c].sample(n=min_class_size, random_state=42) for c in class_datasets]\n",
    "    balanced_dataset = pd.concat(balanced_data).reset_index(drop=True)\n",
    "    balanced_dataset = balanced_dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    experience_datasets[exp_id] = balanced_dataset\n",
    "    print(f\"Balanced dataset size for Experience {exp_id}: {len(balanced_dataset)}\")\n",
    "    for class_id in [0,1,2]:\n",
    "        count = len(balanced_dataset[balanced_dataset['hotend_class'] == class_id])\n",
    "        print(f\"Class {class_id} count: {count}\")"
   ],
   "id": "b8f64236c39dd314",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature sublist: [180.0, 181.0, 182.0, 184.0, 185.0, 186.0, 187.0, 188.0, 190.0, 191.0, 193.0, 195.0, 197.0, 198.0, 199.0, 200.0, 201.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 217.0, 218.0, 219.0, 221.0, 222.0, 223.0, 224.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 233.0, 234.0, 235.0, 236.0, 240.0, 244.0, 246.0, 247.0, 248.0, 250.0]\n",
      "\n",
      "Experience Group 1: [180.0, 181.0, 182.0, 184.0, 185.0, 186.0, 187.0, 188.0, 190.0, 191.0, 193.0, 195.0, 197.0, 198.0, 199.0, 200.0, 201.0]\n",
      "Experience Group 2: [203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 217.0, 218.0, 219.0, 221.0, 222.0]\n",
      "Experience Group 3: [223.0, 224.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 233.0, 234.0, 235.0, 236.0, 240.0, 244.0, 246.0, 247.0, 248.0, 250.0]\n",
      "\n",
      "Processing Experience 1 with temperatures: [180.0, 181.0, 182.0, 184.0, 185.0, 186.0, 187.0, 188.0, 190.0, 191.0, 193.0, 195.0, 197.0, 198.0, 199.0, 200.0, 201.0]...\n",
      "Smallest class size in Experience 1: 676\n",
      "Balanced dataset size for Experience 1: 2028\n",
      "Class 0 count: 676\n",
      "Class 1 count: 676\n",
      "Class 2 count: 676\n",
      "\n",
      "Processing Experience 2 with temperatures: [203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 217.0, 218.0, 219.0, 221.0, 222.0]...\n",
      "Smallest class size in Experience 2: 1955\n",
      "Balanced dataset size for Experience 2: 5865\n",
      "Class 0 count: 1955\n",
      "Class 1 count: 1955\n",
      "Class 2 count: 1955\n",
      "\n",
      "Processing Experience 3 with temperatures: [223.0, 224.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 233.0, 234.0, 235.0, 236.0, 240.0, 244.0, 246.0, 247.0, 248.0, 250.0]...\n",
      "Smallest class size in Experience 3: 746\n",
      "Balanced dataset size for Experience 3: 2238\n",
      "Class 0 count: 746\n",
      "Class 1 count: 746\n",
      "Class 2 count: 746\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:52:22.061094Z",
     "start_time": "2025-03-09T12:52:21.895580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Determine the overall minimum number of images per class across all experiences\n",
    "min_images_per_class_overall = min(\n",
    "    [min(experience_datasets[exp]['hotend_class'].value_counts()) for exp in experience_datasets]\n",
    ")\n",
    "print(\"Overall minimum images per class across experiences:\", min_images_per_class_overall)\n",
    "\n",
    "# Define split proportions\n",
    "train_prop = 0.7\n",
    "valid_prop = 0.15\n",
    "test_prop = 0.15\n",
    "\n",
    "samples_per_class_train = int(train_prop * min_images_per_class_overall)\n",
    "samples_per_class_valid = int(valid_prop * min_images_per_class_overall)\n",
    "# The test set gets the remaining images\n",
    "samples_per_class_test  = min_images_per_class_overall - samples_per_class_train - samples_per_class_valid\n",
    "\n",
    "print(\"Samples per class - Training:\", samples_per_class_train)\n",
    "print(\"Samples per class - Validation:\", samples_per_class_valid)\n",
    "print(\"Samples per class - Test:\", samples_per_class_test)\n",
    "\n",
    "# For each experience, re-sample the balanced dataset accordingly.\n",
    "for exp_id in [1, 2, 3]:\n",
    "    if exp_id not in experience_datasets:\n",
    "        continue\n",
    "    # Work only on the necessary columns\n",
    "    balanced_dataset_filtered = experience_datasets[exp_id][['img_path', 'hotend_class']]\n",
    "    \n",
    "    train_indices, valid_indices, test_indices = [], [], []\n",
    "    for class_label in [0, 1, 2]:\n",
    "        # Get indices for current class\n",
    "        class_indices = balanced_dataset_filtered[balanced_dataset_filtered['hotend_class'] == class_label].index.tolist()\n",
    "        random.shuffle(class_indices)\n",
    "        train_indices.extend(class_indices[:samples_per_class_train])\n",
    "        valid_indices.extend(class_indices[samples_per_class_train:samples_per_class_train + samples_per_class_valid])\n",
    "        test_indices.extend(class_indices[samples_per_class_train + samples_per_class_valid:\n",
    "                                           samples_per_class_train + samples_per_class_valid + samples_per_class_test])\n",
    "    \n",
    "    # Sort indices (optional, for consistency)\n",
    "    train_indices = sorted(train_indices)\n",
    "    valid_indices = sorted(valid_indices)\n",
    "    test_indices = sorted(test_indices)\n",
    "    \n",
    "    globals()[f'train_{exp_id}'] = balanced_dataset_filtered.loc[train_indices].reset_index(drop=True)\n",
    "    globals()[f'valid_{exp_id}'] = balanced_dataset_filtered.loc[valid_indices].reset_index(drop=True)\n",
    "    globals()[f'test_{exp_id}']  = balanced_dataset_filtered.loc[test_indices].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\n--- Experience {exp_id} Splits ---\")\n",
    "    print(f\"Train set size: {len(globals()[f'train_{exp_id}'])} (Expected: {samples_per_class_train*3})\")\n",
    "    print(f\"Validation set size: {len(globals()[f'valid_{exp_id}'])} (Expected: {samples_per_class_valid*3})\")\n",
    "    print(f\"Test set size: {len(globals()[f'test_{exp_id}'])} (Expected: {samples_per_class_test*3})\")\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        df = globals()[f'{split}_{exp_id}']\n",
    "        counts = df['hotend_class'].value_counts().to_dict()\n",
    "        print(f\"{split.capitalize()} class distribution: {counts}\")"
   ],
   "id": "31e7a38b483e34d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall minimum images per class across experiences: 676\n",
      "Samples per class - Training: 473\n",
      "Samples per class - Validation: 101\n",
      "Samples per class - Test: 102\n",
      "\n",
      "--- Experience 1 Splits ---\n",
      "Train set size: 1419 (Expected: 1419)\n",
      "Validation set size: 303 (Expected: 303)\n",
      "Test set size: 306 (Expected: 306)\n",
      "Train class distribution: {1: 473, 0: 473, 2: 473}\n",
      "Valid class distribution: {1: 101, 2: 101, 0: 101}\n",
      "Test class distribution: {2: 102, 0: 102, 1: 102}\n",
      "\n",
      "--- Experience 2 Splits ---\n",
      "Train set size: 1419 (Expected: 1419)\n",
      "Validation set size: 303 (Expected: 303)\n",
      "Test set size: 306 (Expected: 306)\n",
      "Train class distribution: {1: 473, 0: 473, 2: 473}\n",
      "Valid class distribution: {2: 101, 1: 101, 0: 101}\n",
      "Test class distribution: {0: 102, 2: 102, 1: 102}\n",
      "\n",
      "--- Experience 3 Splits ---\n",
      "Train set size: 1419 (Expected: 1419)\n",
      "Validation set size: 303 (Expected: 303)\n",
      "Test set size: 306 (Expected: 306)\n",
      "Train class distribution: {2: 473, 1: 473, 0: 473}\n",
      "Valid class distribution: {0: 101, 1: 101, 2: 101}\n",
      "Test class distribution: {0: 102, 2: 102, 1: 102}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BalancedBatchSamplerClass",
   "id": "ae0b1b11498250dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:52:26.479792Z",
     "start_time": "2025-03-09T12:52:26.458688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BalancedBatchSampler(torch.utils.data.Sampler):\n",
    "    def __init__(self, data_frame, batch_size=15, samples_per_class=5):\n",
    "        \"\"\"\n",
    "        data_frame: Pandas DataFrame with image paths and their respective class labels.\n",
    "        batch_size: Total batch size.\n",
    "        samples_per_class: Number of samples to draw from each class per batch.\n",
    "        \"\"\"\n",
    "        self.data_frame = data_frame\n",
    "        self.batch_size = batch_size\n",
    "        self.samples_per_class = samples_per_class\n",
    "        self.num_classes = len(data_frame['hotend_class'].unique())\n",
    "        \n",
    "        if self.batch_size % self.num_classes != 0:\n",
    "            raise ValueError(\"Batch size must be divisible by the number of classes.\")\n",
    "\n",
    "        # Build a dictionary of indices per class.\n",
    "        self.class_indices = {\n",
    "            class_id: self.data_frame[self.data_frame['hotend_class'] == class_id].index.tolist()\n",
    "            for class_id in self.data_frame['hotend_class'].unique()\n",
    "        }\n",
    "        for class_id in self.class_indices:\n",
    "            random.shuffle(self.class_indices[class_id])\n",
    "        self.num_samples_per_epoch = sum(len(indices) for indices in self.class_indices.values())\n",
    "        self.indices_used = {class_id: [] for class_id in self.class_indices}\n",
    "    \n",
    "    def __iter__(self):\n",
    "        indices_used = {cid: self.class_indices[cid].copy() for cid in self.class_indices}\n",
    "        for indices in indices_used.values():\n",
    "            random.shuffle(indices)\n",
    "        \n",
    "        num_batches = min(len(indices) for indices in indices_used.values()) // self.samples_per_class\n",
    "        batches = []\n",
    "        for b in range(num_batches):\n",
    "            print(f\"Before batch {b+1}, indices available per class:\")\n",
    "            for cid in indices_used:\n",
    "                print(f\"  Class {cid}: {len(indices_used[cid])} indices left\")\n",
    "            batch = []\n",
    "            for cid in self.class_indices:\n",
    "                batch.extend(indices_used[cid][:self.samples_per_class])\n",
    "                indices_used[cid] = indices_used[cid][self.samples_per_class:]\n",
    "            random.shuffle(batch)\n",
    "            batches.append(batch)\n",
    "        return iter(batches)\n",
    "\n",
    "\n",
    "# You can define __len__ to be a fixed number of batches per epoch if needed.\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(indices) for indices in self.class_indices.values()) // self.samples_per_class    "
   ],
   "id": "b69dbc1f5d8eb7de",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BalancedDataset Class",
   "id": "917a1dd3237b548b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:52:27.626086Z",
     "start_time": "2025-03-09T12:52:27.605436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BalancedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_frame, root_dir, transform=None, debug=False, max_retries=5):\n",
    "        self.debug = debug\n",
    "        self.root_dir = root_dir\n",
    "        # Reset index to ensure proper positional indexing.\n",
    "        self.data = data_frame.reset_index(drop=True)\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.max_retries = max_retries\n",
    "        if self.debug:\n",
    "            print(f\"Dataset length (filtered): {len(self.data)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Use .iloc for positional indexing.\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = row.iloc[0].strip()  # e.g., \"print24/image-123.jpg\"\n",
    "        full_img_path = os.path.join(self.root_dir, img_path)\n",
    "        label = row.iloc[1]\n",
    "        try:\n",
    "            image = Image.open(full_img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            if self.debug:\n",
    "                print(f\"Error loading image at index {idx} ({full_img_path}): {e}\")\n",
    "            # Instead of shifting the index, sample a replacement from the same class.\n",
    "            same_class_df = self.data[self.data.iloc[:, 1] == label]\n",
    "            if same_class_df.empty:\n",
    "                raise RuntimeError(f\"No replacement available for class {label}.\")\n",
    "            replacement_idx = random.choice(same_class_df.index.tolist())\n",
    "            # Try loading the replacement image.\n",
    "            row = self.data.iloc[replacement_idx]\n",
    "            img_path = row.iloc[0].strip()\n",
    "            full_img_path = os.path.join(self.root_dir, img_path)\n",
    "            try:\n",
    "                image = Image.open(full_img_path).convert('RGB')\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                return image, label\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"Failed to load replacement image for index {idx} (class {label}): {e}\")"
   ],
   "id": "4a2bb378afc4313a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filter and reindex function",
   "id": "acb3a26d34d94dfa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:33:28.502256Z",
     "start_time": "2025-03-09T13:33:28.481779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_and_reindex(data_frame, root_dir):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame to include only rows with valid image paths\n",
    "    and then reindexes the DataFrame so that indices are contiguous.\n",
    "    \"\"\"\n",
    "    valid_indices = []\n",
    "    allowed_folders = {\"print24\", \"print131\", \"print0\", \"print46\",\"print82\",\"print109\"}\n",
    "    for idx in range(len(data_frame)):\n",
    "        img_path = data_frame.iloc[idx, 0].strip()\n",
    "        parts = img_path.split('/')\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        folder, file_name = parts[0], parts[1]\n",
    "        if folder not in allowed_folders:\n",
    "            continue\n",
    "        if not file_name.startswith(\"image-\"):\n",
    "            continue\n",
    "        full_img_path = os.path.join(root_dir, folder, file_name)\n",
    "        if os.path.exists(full_img_path):\n",
    "            valid_indices.append(idx)\n",
    "    filtered_df = data_frame.iloc[valid_indices].reset_index(drop=True)\n",
    "    return filtered_df"
   ],
   "id": "434dc1c60c10c06",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Function to print random dataset batches",
   "id": "74b53fb914b3d8fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:52:29.674449Z",
     "start_time": "2025-03-09T12:52:29.663559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#####################################\n",
    "# 4. Function to Print Random Batch Distributions\n",
    "#####################################\n",
    "def print_random_batches_from_loader(loader, num_batches=3, dataset_name=\"Dataset\"):\n",
    "    print(f\"\\nRandom batch label distributions for {dataset_name}:\")\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        if batch_idx >= num_batches:\n",
    "            break\n",
    "        label_counts = Counter(labels.numpy())\n",
    "        print(f\"Batch {batch_idx + 1} distribution: {label_counts}\")"
   ],
   "id": "7180cffa6caf665c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:52:48.650607Z",
     "start_time": "2025-03-09T12:52:30.264673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the root directory\n",
    "ROOT_DIR_PATH = r'C:\\Users\\Sandhra George\\avalanche\\caxton_dataset'\n",
    "root_dir = ROOT_DIR_PATH\n",
    "\n",
    "# Loop over experiment numbers.\n",
    "for exp_id in [1, 2, 3]:\n",
    "    print(f\"\\n=== Processing Experience {exp_id} ===\")\n",
    "    # Access the corresponding global DataFrames.\n",
    "    # Ensure these DataFrames (train_1, train_2, etc.) are defined.\n",
    "    original_train_df = globals()[f\"train_{exp_id}\"]\n",
    "    original_valid_df = globals()[f\"valid_{exp_id}\"]\n",
    "    original_test_df  = globals()[f\"test_{exp_id}\"]\n",
    "\n",
    "    # Filter and reindex for each split.\n",
    "    filtered_train_data = filter_and_reindex(original_train_df, root_dir)\n",
    "    filtered_valid_data = filter_and_reindex(original_valid_df, root_dir)\n",
    "    filtered_test_data  = filter_and_reindex(original_test_df, root_dir)\n",
    "\n",
    "    # Create dataset instances using the filtered DataFrames.\n",
    "    train_dataset = BalancedDataset(filtered_train_data, root_dir, debug=False)\n",
    "    valid_dataset = BalancedDataset(filtered_valid_data, root_dir, debug=False)\n",
    "    test_dataset  = BalancedDataset(filtered_test_data, root_dir, debug=False)\n",
    "\n",
    "    # Create balanced batch samplers using the same filtered DataFrames.\n",
    "    train_sampler = BalancedBatchSampler(data_frame=filtered_train_data, batch_size=15, samples_per_class=5)\n",
    "    valid_sampler = BalancedBatchSampler(data_frame=filtered_valid_data, batch_size=15, samples_per_class=5)\n",
    "    test_sampler  = BalancedBatchSampler(data_frame=filtered_test_data,  batch_size=15, samples_per_class=5)\n",
    "\n",
    "    # Create DataLoaders using the custom balanced batch samplers.\n",
    "    train_loader = DataLoader(train_dataset, batch_sampler=train_sampler)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_sampler=valid_sampler)\n",
    "    test_loader  = DataLoader(test_dataset,  batch_sampler=test_sampler)\n",
    "\n",
    "    # Print random batch distributions for each split.\n",
    "    print_random_batches_from_loader(train_loader, num_batches=3, dataset_name=f\"Experience {exp_id} Train\")\n",
    "    print_random_batches_from_loader(valid_loader, num_batches=3, dataset_name=f\"Experience {exp_id} Validation\")\n",
    "    print_random_batches_from_loader(test_loader,  num_batches=3, dataset_name=f\"Experience {exp_id} Test\")"
   ],
   "id": "99fbf298c404efc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Experience 1 ===\n",
      "\n",
      "Random batch label distributions for Experience 1 Train:\n",
      "Before batch 1, indices available per class:\n",
      "  Class 1: 473 indices left\n",
      "  Class 0: 473 indices left\n",
      "  Class 2: 473 indices left\n",
      "Before batch 2, indices available per class:\n",
      "  Class 1: 468 indices left\n",
      "  Class 0: 468 indices left\n",
      "  Class 2: 468 indices left\n",
      "Before batch 3, indices available per class:\n",
      "  Class 1: 463 indices left\n",
      "  Class 0: 463 indices left\n",
      "  Class 2: 463 indices left\n",
      "Before batch 4, indices available per class:\n",
      "  Class 1: 458 indices left\n",
      "  Class 0: 458 indices left\n",
      "  Class 2: 458 indices left\n",
      "Before batch 5, indices available per class:\n",
      "  Class 1: 453 indices left\n",
      "  Class 0: 453 indices left\n",
      "  Class 2: 453 indices left\n",
      "Before batch 6, indices available per class:\n",
      "  Class 1: 448 indices left\n",
      "  Class 0: 448 indices left\n",
      "  Class 2: 448 indices left\n",
      "Before batch 7, indices available per class:\n",
      "  Class 1: 443 indices left\n",
      "  Class 0: 443 indices left\n",
      "  Class 2: 443 indices left\n",
      "Before batch 8, indices available per class:\n",
      "  Class 1: 438 indices left\n",
      "  Class 0: 438 indices left\n",
      "  Class 2: 438 indices left\n",
      "Before batch 9, indices available per class:\n",
      "  Class 1: 433 indices left\n",
      "  Class 0: 433 indices left\n",
      "  Class 2: 433 indices left\n",
      "Before batch 10, indices available per class:\n",
      "  Class 1: 428 indices left\n",
      "  Class 0: 428 indices left\n",
      "  Class 2: 428 indices left\n",
      "Before batch 11, indices available per class:\n",
      "  Class 1: 423 indices left\n",
      "  Class 0: 423 indices left\n",
      "  Class 2: 423 indices left\n",
      "Before batch 12, indices available per class:\n",
      "  Class 1: 418 indices left\n",
      "  Class 0: 418 indices left\n",
      "  Class 2: 418 indices left\n",
      "Before batch 13, indices available per class:\n",
      "  Class 1: 413 indices left\n",
      "  Class 0: 413 indices left\n",
      "  Class 2: 413 indices left\n",
      "Before batch 14, indices available per class:\n",
      "  Class 1: 408 indices left\n",
      "  Class 0: 408 indices left\n",
      "  Class 2: 408 indices left\n",
      "Before batch 15, indices available per class:\n",
      "  Class 1: 403 indices left\n",
      "  Class 0: 403 indices left\n",
      "  Class 2: 403 indices left\n",
      "Before batch 16, indices available per class:\n",
      "  Class 1: 398 indices left\n",
      "  Class 0: 398 indices left\n",
      "  Class 2: 398 indices left\n",
      "Before batch 17, indices available per class:\n",
      "  Class 1: 393 indices left\n",
      "  Class 0: 393 indices left\n",
      "  Class 2: 393 indices left\n",
      "Before batch 18, indices available per class:\n",
      "  Class 1: 388 indices left\n",
      "  Class 0: 388 indices left\n",
      "  Class 2: 388 indices left\n",
      "Before batch 19, indices available per class:\n",
      "  Class 1: 383 indices left\n",
      "  Class 0: 383 indices left\n",
      "  Class 2: 383 indices left\n",
      "Before batch 20, indices available per class:\n",
      "  Class 1: 378 indices left\n",
      "  Class 0: 378 indices left\n",
      "  Class 2: 378 indices left\n",
      "Before batch 21, indices available per class:\n",
      "  Class 1: 373 indices left\n",
      "  Class 0: 373 indices left\n",
      "  Class 2: 373 indices left\n",
      "Before batch 22, indices available per class:\n",
      "  Class 1: 368 indices left\n",
      "  Class 0: 368 indices left\n",
      "  Class 2: 368 indices left\n",
      "Before batch 23, indices available per class:\n",
      "  Class 1: 363 indices left\n",
      "  Class 0: 363 indices left\n",
      "  Class 2: 363 indices left\n",
      "Before batch 24, indices available per class:\n",
      "  Class 1: 358 indices left\n",
      "  Class 0: 358 indices left\n",
      "  Class 2: 358 indices left\n",
      "Before batch 25, indices available per class:\n",
      "  Class 1: 353 indices left\n",
      "  Class 0: 353 indices left\n",
      "  Class 2: 353 indices left\n",
      "Before batch 26, indices available per class:\n",
      "  Class 1: 348 indices left\n",
      "  Class 0: 348 indices left\n",
      "  Class 2: 348 indices left\n",
      "Before batch 27, indices available per class:\n",
      "  Class 1: 343 indices left\n",
      "  Class 0: 343 indices left\n",
      "  Class 2: 343 indices left\n",
      "Before batch 28, indices available per class:\n",
      "  Class 1: 338 indices left\n",
      "  Class 0: 338 indices left\n",
      "  Class 2: 338 indices left\n",
      "Before batch 29, indices available per class:\n",
      "  Class 1: 333 indices left\n",
      "  Class 0: 333 indices left\n",
      "  Class 2: 333 indices left\n",
      "Before batch 30, indices available per class:\n",
      "  Class 1: 328 indices left\n",
      "  Class 0: 328 indices left\n",
      "  Class 2: 328 indices left\n",
      "Before batch 31, indices available per class:\n",
      "  Class 1: 323 indices left\n",
      "  Class 0: 323 indices left\n",
      "  Class 2: 323 indices left\n",
      "Before batch 32, indices available per class:\n",
      "  Class 1: 318 indices left\n",
      "  Class 0: 318 indices left\n",
      "  Class 2: 318 indices left\n",
      "Before batch 33, indices available per class:\n",
      "  Class 1: 313 indices left\n",
      "  Class 0: 313 indices left\n",
      "  Class 2: 313 indices left\n",
      "Before batch 34, indices available per class:\n",
      "  Class 1: 308 indices left\n",
      "  Class 0: 308 indices left\n",
      "  Class 2: 308 indices left\n",
      "Before batch 35, indices available per class:\n",
      "  Class 1: 303 indices left\n",
      "  Class 0: 303 indices left\n",
      "  Class 2: 303 indices left\n",
      "Before batch 36, indices available per class:\n",
      "  Class 1: 298 indices left\n",
      "  Class 0: 298 indices left\n",
      "  Class 2: 298 indices left\n",
      "Before batch 37, indices available per class:\n",
      "  Class 1: 293 indices left\n",
      "  Class 0: 293 indices left\n",
      "  Class 2: 293 indices left\n",
      "Before batch 38, indices available per class:\n",
      "  Class 1: 288 indices left\n",
      "  Class 0: 288 indices left\n",
      "  Class 2: 288 indices left\n",
      "Before batch 39, indices available per class:\n",
      "  Class 1: 283 indices left\n",
      "  Class 0: 283 indices left\n",
      "  Class 2: 283 indices left\n",
      "Before batch 40, indices available per class:\n",
      "  Class 1: 278 indices left\n",
      "  Class 0: 278 indices left\n",
      "  Class 2: 278 indices left\n",
      "Before batch 41, indices available per class:\n",
      "  Class 1: 273 indices left\n",
      "  Class 0: 273 indices left\n",
      "  Class 2: 273 indices left\n",
      "Before batch 42, indices available per class:\n",
      "  Class 1: 268 indices left\n",
      "  Class 0: 268 indices left\n",
      "  Class 2: 268 indices left\n",
      "Before batch 43, indices available per class:\n",
      "  Class 1: 263 indices left\n",
      "  Class 0: 263 indices left\n",
      "  Class 2: 263 indices left\n",
      "Before batch 44, indices available per class:\n",
      "  Class 1: 258 indices left\n",
      "  Class 0: 258 indices left\n",
      "  Class 2: 258 indices left\n",
      "Before batch 45, indices available per class:\n",
      "  Class 1: 253 indices left\n",
      "  Class 0: 253 indices left\n",
      "  Class 2: 253 indices left\n",
      "Before batch 46, indices available per class:\n",
      "  Class 1: 248 indices left\n",
      "  Class 0: 248 indices left\n",
      "  Class 2: 248 indices left\n",
      "Before batch 47, indices available per class:\n",
      "  Class 1: 243 indices left\n",
      "  Class 0: 243 indices left\n",
      "  Class 2: 243 indices left\n",
      "Before batch 48, indices available per class:\n",
      "  Class 1: 238 indices left\n",
      "  Class 0: 238 indices left\n",
      "  Class 2: 238 indices left\n",
      "Before batch 49, indices available per class:\n",
      "  Class 1: 233 indices left\n",
      "  Class 0: 233 indices left\n",
      "  Class 2: 233 indices left\n",
      "Before batch 50, indices available per class:\n",
      "  Class 1: 228 indices left\n",
      "  Class 0: 228 indices left\n",
      "  Class 2: 228 indices left\n",
      "Before batch 51, indices available per class:\n",
      "  Class 1: 223 indices left\n",
      "  Class 0: 223 indices left\n",
      "  Class 2: 223 indices left\n",
      "Before batch 52, indices available per class:\n",
      "  Class 1: 218 indices left\n",
      "  Class 0: 218 indices left\n",
      "  Class 2: 218 indices left\n",
      "Before batch 53, indices available per class:\n",
      "  Class 1: 213 indices left\n",
      "  Class 0: 213 indices left\n",
      "  Class 2: 213 indices left\n",
      "Before batch 54, indices available per class:\n",
      "  Class 1: 208 indices left\n",
      "  Class 0: 208 indices left\n",
      "  Class 2: 208 indices left\n",
      "Before batch 55, indices available per class:\n",
      "  Class 1: 203 indices left\n",
      "  Class 0: 203 indices left\n",
      "  Class 2: 203 indices left\n",
      "Before batch 56, indices available per class:\n",
      "  Class 1: 198 indices left\n",
      "  Class 0: 198 indices left\n",
      "  Class 2: 198 indices left\n",
      "Before batch 57, indices available per class:\n",
      "  Class 1: 193 indices left\n",
      "  Class 0: 193 indices left\n",
      "  Class 2: 193 indices left\n",
      "Before batch 58, indices available per class:\n",
      "  Class 1: 188 indices left\n",
      "  Class 0: 188 indices left\n",
      "  Class 2: 188 indices left\n",
      "Before batch 59, indices available per class:\n",
      "  Class 1: 183 indices left\n",
      "  Class 0: 183 indices left\n",
      "  Class 2: 183 indices left\n",
      "Before batch 60, indices available per class:\n",
      "  Class 1: 178 indices left\n",
      "  Class 0: 178 indices left\n",
      "  Class 2: 178 indices left\n",
      "Before batch 61, indices available per class:\n",
      "  Class 1: 173 indices left\n",
      "  Class 0: 173 indices left\n",
      "  Class 2: 173 indices left\n",
      "Before batch 62, indices available per class:\n",
      "  Class 1: 168 indices left\n",
      "  Class 0: 168 indices left\n",
      "  Class 2: 168 indices left\n",
      "Before batch 63, indices available per class:\n",
      "  Class 1: 163 indices left\n",
      "  Class 0: 163 indices left\n",
      "  Class 2: 163 indices left\n",
      "Before batch 64, indices available per class:\n",
      "  Class 1: 158 indices left\n",
      "  Class 0: 158 indices left\n",
      "  Class 2: 158 indices left\n",
      "Before batch 65, indices available per class:\n",
      "  Class 1: 153 indices left\n",
      "  Class 0: 153 indices left\n",
      "  Class 2: 153 indices left\n",
      "Before batch 66, indices available per class:\n",
      "  Class 1: 148 indices left\n",
      "  Class 0: 148 indices left\n",
      "  Class 2: 148 indices left\n",
      "Before batch 67, indices available per class:\n",
      "  Class 1: 143 indices left\n",
      "  Class 0: 143 indices left\n",
      "  Class 2: 143 indices left\n",
      "Before batch 68, indices available per class:\n",
      "  Class 1: 138 indices left\n",
      "  Class 0: 138 indices left\n",
      "  Class 2: 138 indices left\n",
      "Before batch 69, indices available per class:\n",
      "  Class 1: 133 indices left\n",
      "  Class 0: 133 indices left\n",
      "  Class 2: 133 indices left\n",
      "Before batch 70, indices available per class:\n",
      "  Class 1: 128 indices left\n",
      "  Class 0: 128 indices left\n",
      "  Class 2: 128 indices left\n",
      "Before batch 71, indices available per class:\n",
      "  Class 1: 123 indices left\n",
      "  Class 0: 123 indices left\n",
      "  Class 2: 123 indices left\n",
      "Before batch 72, indices available per class:\n",
      "  Class 1: 118 indices left\n",
      "  Class 0: 118 indices left\n",
      "  Class 2: 118 indices left\n",
      "Before batch 73, indices available per class:\n",
      "  Class 1: 113 indices left\n",
      "  Class 0: 113 indices left\n",
      "  Class 2: 113 indices left\n",
      "Before batch 74, indices available per class:\n",
      "  Class 1: 108 indices left\n",
      "  Class 0: 108 indices left\n",
      "  Class 2: 108 indices left\n",
      "Before batch 75, indices available per class:\n",
      "  Class 1: 103 indices left\n",
      "  Class 0: 103 indices left\n",
      "  Class 2: 103 indices left\n",
      "Before batch 76, indices available per class:\n",
      "  Class 1: 98 indices left\n",
      "  Class 0: 98 indices left\n",
      "  Class 2: 98 indices left\n",
      "Before batch 77, indices available per class:\n",
      "  Class 1: 93 indices left\n",
      "  Class 0: 93 indices left\n",
      "  Class 2: 93 indices left\n",
      "Before batch 78, indices available per class:\n",
      "  Class 1: 88 indices left\n",
      "  Class 0: 88 indices left\n",
      "  Class 2: 88 indices left\n",
      "Before batch 79, indices available per class:\n",
      "  Class 1: 83 indices left\n",
      "  Class 0: 83 indices left\n",
      "  Class 2: 83 indices left\n",
      "Before batch 80, indices available per class:\n",
      "  Class 1: 78 indices left\n",
      "  Class 0: 78 indices left\n",
      "  Class 2: 78 indices left\n",
      "Before batch 81, indices available per class:\n",
      "  Class 1: 73 indices left\n",
      "  Class 0: 73 indices left\n",
      "  Class 2: 73 indices left\n",
      "Before batch 82, indices available per class:\n",
      "  Class 1: 68 indices left\n",
      "  Class 0: 68 indices left\n",
      "  Class 2: 68 indices left\n",
      "Before batch 83, indices available per class:\n",
      "  Class 1: 63 indices left\n",
      "  Class 0: 63 indices left\n",
      "  Class 2: 63 indices left\n",
      "Before batch 84, indices available per class:\n",
      "  Class 1: 58 indices left\n",
      "  Class 0: 58 indices left\n",
      "  Class 2: 58 indices left\n",
      "Before batch 85, indices available per class:\n",
      "  Class 1: 53 indices left\n",
      "  Class 0: 53 indices left\n",
      "  Class 2: 53 indices left\n",
      "Before batch 86, indices available per class:\n",
      "  Class 1: 48 indices left\n",
      "  Class 0: 48 indices left\n",
      "  Class 2: 48 indices left\n",
      "Before batch 87, indices available per class:\n",
      "  Class 1: 43 indices left\n",
      "  Class 0: 43 indices left\n",
      "  Class 2: 43 indices left\n",
      "Before batch 88, indices available per class:\n",
      "  Class 1: 38 indices left\n",
      "  Class 0: 38 indices left\n",
      "  Class 2: 38 indices left\n",
      "Before batch 89, indices available per class:\n",
      "  Class 1: 33 indices left\n",
      "  Class 0: 33 indices left\n",
      "  Class 2: 33 indices left\n",
      "Before batch 90, indices available per class:\n",
      "  Class 1: 28 indices left\n",
      "  Class 0: 28 indices left\n",
      "  Class 2: 28 indices left\n",
      "Before batch 91, indices available per class:\n",
      "  Class 1: 23 indices left\n",
      "  Class 0: 23 indices left\n",
      "  Class 2: 23 indices left\n",
      "Before batch 92, indices available per class:\n",
      "  Class 1: 18 indices left\n",
      "  Class 0: 18 indices left\n",
      "  Class 2: 18 indices left\n",
      "Before batch 93, indices available per class:\n",
      "  Class 1: 13 indices left\n",
      "  Class 0: 13 indices left\n",
      "  Class 2: 13 indices left\n",
      "Before batch 94, indices available per class:\n",
      "  Class 1: 8 indices left\n",
      "  Class 0: 8 indices left\n",
      "  Class 2: 8 indices left\n",
      "Batch 1 distribution: Counter({0: 5, 1: 5, 2: 5})\n",
      "Batch 2 distribution: Counter({2: 5, 0: 5, 1: 5})\n",
      "Batch 3 distribution: Counter({1: 5, 2: 5, 0: 5})\n",
      "\n",
      "Random batch label distributions for Experience 1 Validation:\n",
      "Before batch 1, indices available per class:\n",
      "  Class 1: 101 indices left\n",
      "  Class 2: 101 indices left\n",
      "  Class 0: 101 indices left\n",
      "Before batch 2, indices available per class:\n",
      "  Class 1: 96 indices left\n",
      "  Class 2: 96 indices left\n",
      "  Class 0: 96 indices left\n",
      "Before batch 3, indices available per class:\n",
      "  Class 1: 91 indices left\n",
      "  Class 2: 91 indices left\n",
      "  Class 0: 91 indices left\n",
      "Before batch 4, indices available per class:\n",
      "  Class 1: 86 indices left\n",
      "  Class 2: 86 indices left\n",
      "  Class 0: 86 indices left\n",
      "Before batch 5, indices available per class:\n",
      "  Class 1: 81 indices left\n",
      "  Class 2: 81 indices left\n",
      "  Class 0: 81 indices left\n",
      "Before batch 6, indices available per class:\n",
      "  Class 1: 76 indices left\n",
      "  Class 2: 76 indices left\n",
      "  Class 0: 76 indices left\n",
      "Before batch 7, indices available per class:\n",
      "  Class 1: 71 indices left\n",
      "  Class 2: 71 indices left\n",
      "  Class 0: 71 indices left\n",
      "Before batch 8, indices available per class:\n",
      "  Class 1: 66 indices left\n",
      "  Class 2: 66 indices left\n",
      "  Class 0: 66 indices left\n",
      "Before batch 9, indices available per class:\n",
      "  Class 1: 61 indices left\n",
      "  Class 2: 61 indices left\n",
      "  Class 0: 61 indices left\n",
      "Before batch 10, indices available per class:\n",
      "  Class 1: 56 indices left\n",
      "  Class 2: 56 indices left\n",
      "  Class 0: 56 indices left\n",
      "Before batch 11, indices available per class:\n",
      "  Class 1: 51 indices left\n",
      "  Class 2: 51 indices left\n",
      "  Class 0: 51 indices left\n",
      "Before batch 12, indices available per class:\n",
      "  Class 1: 46 indices left\n",
      "  Class 2: 46 indices left\n",
      "  Class 0: 46 indices left\n",
      "Before batch 13, indices available per class:\n",
      "  Class 1: 41 indices left\n",
      "  Class 2: 41 indices left\n",
      "  Class 0: 41 indices left\n",
      "Before batch 14, indices available per class:\n",
      "  Class 1: 36 indices left\n",
      "  Class 2: 36 indices left\n",
      "  Class 0: 36 indices left\n",
      "Before batch 15, indices available per class:\n",
      "  Class 1: 31 indices left\n",
      "  Class 2: 31 indices left\n",
      "  Class 0: 31 indices left\n",
      "Before batch 16, indices available per class:\n",
      "  Class 1: 26 indices left\n",
      "  Class 2: 26 indices left\n",
      "  Class 0: 26 indices left\n",
      "Before batch 17, indices available per class:\n",
      "  Class 1: 21 indices left\n",
      "  Class 2: 21 indices left\n",
      "  Class 0: 21 indices left\n",
      "Before batch 18, indices available per class:\n",
      "  Class 1: 16 indices left\n",
      "  Class 2: 16 indices left\n",
      "  Class 0: 16 indices left\n",
      "Before batch 19, indices available per class:\n",
      "  Class 1: 11 indices left\n",
      "  Class 2: 11 indices left\n",
      "  Class 0: 11 indices left\n",
      "Before batch 20, indices available per class:\n",
      "  Class 1: 6 indices left\n",
      "  Class 2: 6 indices left\n",
      "  Class 0: 6 indices left\n",
      "Batch 1 distribution: Counter({0: 5, 2: 5, 1: 5})\n",
      "Batch 2 distribution: Counter({2: 5, 1: 5, 0: 5})\n",
      "Batch 3 distribution: Counter({0: 5, 2: 5, 1: 5})\n",
      "\n",
      "Random batch label distributions for Experience 1 Test:\n",
      "Before batch 1, indices available per class:\n",
      "  Class 2: 102 indices left\n",
      "  Class 0: 102 indices left\n",
      "  Class 1: 102 indices left\n",
      "Before batch 2, indices available per class:\n",
      "  Class 2: 97 indices left\n",
      "  Class 0: 97 indices left\n",
      "  Class 1: 97 indices left\n",
      "Before batch 3, indices available per class:\n",
      "  Class 2: 92 indices left\n",
      "  Class 0: 92 indices left\n",
      "  Class 1: 92 indices left\n",
      "Before batch 4, indices available per class:\n",
      "  Class 2: 87 indices left\n",
      "  Class 0: 87 indices left\n",
      "  Class 1: 87 indices left\n",
      "Before batch 5, indices available per class:\n",
      "  Class 2: 82 indices left\n",
      "  Class 0: 82 indices left\n",
      "  Class 1: 82 indices left\n",
      "Before batch 6, indices available per class:\n",
      "  Class 2: 77 indices left\n",
      "  Class 0: 77 indices left\n",
      "  Class 1: 77 indices left\n",
      "Before batch 7, indices available per class:\n",
      "  Class 2: 72 indices left\n",
      "  Class 0: 72 indices left\n",
      "  Class 1: 72 indices left\n",
      "Before batch 8, indices available per class:\n",
      "  Class 2: 67 indices left\n",
      "  Class 0: 67 indices left\n",
      "  Class 1: 67 indices left\n",
      "Before batch 9, indices available per class:\n",
      "  Class 2: 62 indices left\n",
      "  Class 0: 62 indices left\n",
      "  Class 1: 62 indices left\n",
      "Before batch 10, indices available per class:\n",
      "  Class 2: 57 indices left\n",
      "  Class 0: 57 indices left\n",
      "  Class 1: 57 indices left\n",
      "Before batch 11, indices available per class:\n",
      "  Class 2: 52 indices left\n",
      "  Class 0: 52 indices left\n",
      "  Class 1: 52 indices left\n",
      "Before batch 12, indices available per class:\n",
      "  Class 2: 47 indices left\n",
      "  Class 0: 47 indices left\n",
      "  Class 1: 47 indices left\n",
      "Before batch 13, indices available per class:\n",
      "  Class 2: 42 indices left\n",
      "  Class 0: 42 indices left\n",
      "  Class 1: 42 indices left\n",
      "Before batch 14, indices available per class:\n",
      "  Class 2: 37 indices left\n",
      "  Class 0: 37 indices left\n",
      "  Class 1: 37 indices left\n",
      "Before batch 15, indices available per class:\n",
      "  Class 2: 32 indices left\n",
      "  Class 0: 32 indices left\n",
      "  Class 1: 32 indices left\n",
      "Before batch 16, indices available per class:\n",
      "  Class 2: 27 indices left\n",
      "  Class 0: 27 indices left\n",
      "  Class 1: 27 indices left\n",
      "Before batch 17, indices available per class:\n",
      "  Class 2: 22 indices left\n",
      "  Class 0: 22 indices left\n",
      "  Class 1: 22 indices left\n",
      "Before batch 18, indices available per class:\n",
      "  Class 2: 17 indices left\n",
      "  Class 0: 17 indices left\n",
      "  Class 1: 17 indices left\n",
      "Before batch 19, indices available per class:\n",
      "  Class 2: 12 indices left\n",
      "  Class 0: 12 indices left\n",
      "  Class 1: 12 indices left\n",
      "Before batch 20, indices available per class:\n",
      "  Class 2: 7 indices left\n",
      "  Class 0: 7 indices left\n",
      "  Class 1: 7 indices left\n",
      "Batch 1 distribution: Counter({2: 5, 0: 5, 1: 5})\n",
      "Batch 2 distribution: Counter({1: 5, 0: 5, 2: 5})\n",
      "Batch 3 distribution: Counter({1: 5, 2: 5, 0: 5})\n",
      "\n",
      "=== Processing Experience 2 ===\n",
      "\n",
      "Random batch label distributions for Experience 2 Train:\n",
      "Before batch 1, indices available per class:\n",
      "  Class 1: 473 indices left\n",
      "  Class 0: 473 indices left\n",
      "  Class 2: 473 indices left\n",
      "Before batch 2, indices available per class:\n",
      "  Class 1: 468 indices left\n",
      "  Class 0: 468 indices left\n",
      "  Class 2: 468 indices left\n",
      "Before batch 3, indices available per class:\n",
      "  Class 1: 463 indices left\n",
      "  Class 0: 463 indices left\n",
      "  Class 2: 463 indices left\n",
      "Before batch 4, indices available per class:\n",
      "  Class 1: 458 indices left\n",
      "  Class 0: 458 indices left\n",
      "  Class 2: 458 indices left\n",
      "Before batch 5, indices available per class:\n",
      "  Class 1: 453 indices left\n",
      "  Class 0: 453 indices left\n",
      "  Class 2: 453 indices left\n",
      "Before batch 6, indices available per class:\n",
      "  Class 1: 448 indices left\n",
      "  Class 0: 448 indices left\n",
      "  Class 2: 448 indices left\n",
      "Before batch 7, indices available per class:\n",
      "  Class 1: 443 indices left\n",
      "  Class 0: 443 indices left\n",
      "  Class 2: 443 indices left\n",
      "Before batch 8, indices available per class:\n",
      "  Class 1: 438 indices left\n",
      "  Class 0: 438 indices left\n",
      "  Class 2: 438 indices left\n",
      "Before batch 9, indices available per class:\n",
      "  Class 1: 433 indices left\n",
      "  Class 0: 433 indices left\n",
      "  Class 2: 433 indices left\n",
      "Before batch 10, indices available per class:\n",
      "  Class 1: 428 indices left\n",
      "  Class 0: 428 indices left\n",
      "  Class 2: 428 indices left\n",
      "Before batch 11, indices available per class:\n",
      "  Class 1: 423 indices left\n",
      "  Class 0: 423 indices left\n",
      "  Class 2: 423 indices left\n",
      "Before batch 12, indices available per class:\n",
      "  Class 1: 418 indices left\n",
      "  Class 0: 418 indices left\n",
      "  Class 2: 418 indices left\n",
      "Before batch 13, indices available per class:\n",
      "  Class 1: 413 indices left\n",
      "  Class 0: 413 indices left\n",
      "  Class 2: 413 indices left\n",
      "Before batch 14, indices available per class:\n",
      "  Class 1: 408 indices left\n",
      "  Class 0: 408 indices left\n",
      "  Class 2: 408 indices left\n",
      "Before batch 15, indices available per class:\n",
      "  Class 1: 403 indices left\n",
      "  Class 0: 403 indices left\n",
      "  Class 2: 403 indices left\n",
      "Before batch 16, indices available per class:\n",
      "  Class 1: 398 indices left\n",
      "  Class 0: 398 indices left\n",
      "  Class 2: 398 indices left\n",
      "Before batch 17, indices available per class:\n",
      "  Class 1: 393 indices left\n",
      "  Class 0: 393 indices left\n",
      "  Class 2: 393 indices left\n",
      "Before batch 18, indices available per class:\n",
      "  Class 1: 388 indices left\n",
      "  Class 0: 388 indices left\n",
      "  Class 2: 388 indices left\n",
      "Before batch 19, indices available per class:\n",
      "  Class 1: 383 indices left\n",
      "  Class 0: 383 indices left\n",
      "  Class 2: 383 indices left\n",
      "Before batch 20, indices available per class:\n",
      "  Class 1: 378 indices left\n",
      "  Class 0: 378 indices left\n",
      "  Class 2: 378 indices left\n",
      "Before batch 21, indices available per class:\n",
      "  Class 1: 373 indices left\n",
      "  Class 0: 373 indices left\n",
      "  Class 2: 373 indices left\n",
      "Before batch 22, indices available per class:\n",
      "  Class 1: 368 indices left\n",
      "  Class 0: 368 indices left\n",
      "  Class 2: 368 indices left\n",
      "Before batch 23, indices available per class:\n",
      "  Class 1: 363 indices left\n",
      "  Class 0: 363 indices left\n",
      "  Class 2: 363 indices left\n",
      "Before batch 24, indices available per class:\n",
      "  Class 1: 358 indices left\n",
      "  Class 0: 358 indices left\n",
      "  Class 2: 358 indices left\n",
      "Before batch 25, indices available per class:\n",
      "  Class 1: 353 indices left\n",
      "  Class 0: 353 indices left\n",
      "  Class 2: 353 indices left\n",
      "Before batch 26, indices available per class:\n",
      "  Class 1: 348 indices left\n",
      "  Class 0: 348 indices left\n",
      "  Class 2: 348 indices left\n",
      "Before batch 27, indices available per class:\n",
      "  Class 1: 343 indices left\n",
      "  Class 0: 343 indices left\n",
      "  Class 2: 343 indices left\n",
      "Before batch 28, indices available per class:\n",
      "  Class 1: 338 indices left\n",
      "  Class 0: 338 indices left\n",
      "  Class 2: 338 indices left\n",
      "Before batch 29, indices available per class:\n",
      "  Class 1: 333 indices left\n",
      "  Class 0: 333 indices left\n",
      "  Class 2: 333 indices left\n",
      "Before batch 30, indices available per class:\n",
      "  Class 1: 328 indices left\n",
      "  Class 0: 328 indices left\n",
      "  Class 2: 328 indices left\n",
      "Before batch 31, indices available per class:\n",
      "  Class 1: 323 indices left\n",
      "  Class 0: 323 indices left\n",
      "  Class 2: 323 indices left\n",
      "Before batch 32, indices available per class:\n",
      "  Class 1: 318 indices left\n",
      "  Class 0: 318 indices left\n",
      "  Class 2: 318 indices left\n",
      "Before batch 33, indices available per class:\n",
      "  Class 1: 313 indices left\n",
      "  Class 0: 313 indices left\n",
      "  Class 2: 313 indices left\n",
      "Before batch 34, indices available per class:\n",
      "  Class 1: 308 indices left\n",
      "  Class 0: 308 indices left\n",
      "  Class 2: 308 indices left\n",
      "Before batch 35, indices available per class:\n",
      "  Class 1: 303 indices left\n",
      "  Class 0: 303 indices left\n",
      "  Class 2: 303 indices left\n",
      "Before batch 36, indices available per class:\n",
      "  Class 1: 298 indices left\n",
      "  Class 0: 298 indices left\n",
      "  Class 2: 298 indices left\n",
      "Before batch 37, indices available per class:\n",
      "  Class 1: 293 indices left\n",
      "  Class 0: 293 indices left\n",
      "  Class 2: 293 indices left\n",
      "Before batch 38, indices available per class:\n",
      "  Class 1: 288 indices left\n",
      "  Class 0: 288 indices left\n",
      "  Class 2: 288 indices left\n",
      "Before batch 39, indices available per class:\n",
      "  Class 1: 283 indices left\n",
      "  Class 0: 283 indices left\n",
      "  Class 2: 283 indices left\n",
      "Before batch 40, indices available per class:\n",
      "  Class 1: 278 indices left\n",
      "  Class 0: 278 indices left\n",
      "  Class 2: 278 indices left\n",
      "Before batch 41, indices available per class:\n",
      "  Class 1: 273 indices left\n",
      "  Class 0: 273 indices left\n",
      "  Class 2: 273 indices left\n",
      "Before batch 42, indices available per class:\n",
      "  Class 1: 268 indices left\n",
      "  Class 0: 268 indices left\n",
      "  Class 2: 268 indices left\n",
      "Before batch 43, indices available per class:\n",
      "  Class 1: 263 indices left\n",
      "  Class 0: 263 indices left\n",
      "  Class 2: 263 indices left\n",
      "Before batch 44, indices available per class:\n",
      "  Class 1: 258 indices left\n",
      "  Class 0: 258 indices left\n",
      "  Class 2: 258 indices left\n",
      "Before batch 45, indices available per class:\n",
      "  Class 1: 253 indices left\n",
      "  Class 0: 253 indices left\n",
      "  Class 2: 253 indices left\n",
      "Before batch 46, indices available per class:\n",
      "  Class 1: 248 indices left\n",
      "  Class 0: 248 indices left\n",
      "  Class 2: 248 indices left\n",
      "Before batch 47, indices available per class:\n",
      "  Class 1: 243 indices left\n",
      "  Class 0: 243 indices left\n",
      "  Class 2: 243 indices left\n",
      "Before batch 48, indices available per class:\n",
      "  Class 1: 238 indices left\n",
      "  Class 0: 238 indices left\n",
      "  Class 2: 238 indices left\n",
      "Before batch 49, indices available per class:\n",
      "  Class 1: 233 indices left\n",
      "  Class 0: 233 indices left\n",
      "  Class 2: 233 indices left\n",
      "Before batch 50, indices available per class:\n",
      "  Class 1: 228 indices left\n",
      "  Class 0: 228 indices left\n",
      "  Class 2: 228 indices left\n",
      "Before batch 51, indices available per class:\n",
      "  Class 1: 223 indices left\n",
      "  Class 0: 223 indices left\n",
      "  Class 2: 223 indices left\n",
      "Before batch 52, indices available per class:\n",
      "  Class 1: 218 indices left\n",
      "  Class 0: 218 indices left\n",
      "  Class 2: 218 indices left\n",
      "Before batch 53, indices available per class:\n",
      "  Class 1: 213 indices left\n",
      "  Class 0: 213 indices left\n",
      "  Class 2: 213 indices left\n",
      "Before batch 54, indices available per class:\n",
      "  Class 1: 208 indices left\n",
      "  Class 0: 208 indices left\n",
      "  Class 2: 208 indices left\n",
      "Before batch 55, indices available per class:\n",
      "  Class 1: 203 indices left\n",
      "  Class 0: 203 indices left\n",
      "  Class 2: 203 indices left\n",
      "Before batch 56, indices available per class:\n",
      "  Class 1: 198 indices left\n",
      "  Class 0: 198 indices left\n",
      "  Class 2: 198 indices left\n",
      "Before batch 57, indices available per class:\n",
      "  Class 1: 193 indices left\n",
      "  Class 0: 193 indices left\n",
      "  Class 2: 193 indices left\n",
      "Before batch 58, indices available per class:\n",
      "  Class 1: 188 indices left\n",
      "  Class 0: 188 indices left\n",
      "  Class 2: 188 indices left\n",
      "Before batch 59, indices available per class:\n",
      "  Class 1: 183 indices left\n",
      "  Class 0: 183 indices left\n",
      "  Class 2: 183 indices left\n",
      "Before batch 60, indices available per class:\n",
      "  Class 1: 178 indices left\n",
      "  Class 0: 178 indices left\n",
      "  Class 2: 178 indices left\n",
      "Before batch 61, indices available per class:\n",
      "  Class 1: 173 indices left\n",
      "  Class 0: 173 indices left\n",
      "  Class 2: 173 indices left\n",
      "Before batch 62, indices available per class:\n",
      "  Class 1: 168 indices left\n",
      "  Class 0: 168 indices left\n",
      "  Class 2: 168 indices left\n",
      "Before batch 63, indices available per class:\n",
      "  Class 1: 163 indices left\n",
      "  Class 0: 163 indices left\n",
      "  Class 2: 163 indices left\n",
      "Before batch 64, indices available per class:\n",
      "  Class 1: 158 indices left\n",
      "  Class 0: 158 indices left\n",
      "  Class 2: 158 indices left\n",
      "Before batch 65, indices available per class:\n",
      "  Class 1: 153 indices left\n",
      "  Class 0: 153 indices left\n",
      "  Class 2: 153 indices left\n",
      "Before batch 66, indices available per class:\n",
      "  Class 1: 148 indices left\n",
      "  Class 0: 148 indices left\n",
      "  Class 2: 148 indices left\n",
      "Before batch 67, indices available per class:\n",
      "  Class 1: 143 indices left\n",
      "  Class 0: 143 indices left\n",
      "  Class 2: 143 indices left\n",
      "Before batch 68, indices available per class:\n",
      "  Class 1: 138 indices left\n",
      "  Class 0: 138 indices left\n",
      "  Class 2: 138 indices left\n",
      "Before batch 69, indices available per class:\n",
      "  Class 1: 133 indices left\n",
      "  Class 0: 133 indices left\n",
      "  Class 2: 133 indices left\n",
      "Before batch 70, indices available per class:\n",
      "  Class 1: 128 indices left\n",
      "  Class 0: 128 indices left\n",
      "  Class 2: 128 indices left\n",
      "Before batch 71, indices available per class:\n",
      "  Class 1: 123 indices left\n",
      "  Class 0: 123 indices left\n",
      "  Class 2: 123 indices left\n",
      "Before batch 72, indices available per class:\n",
      "  Class 1: 118 indices left\n",
      "  Class 0: 118 indices left\n",
      "  Class 2: 118 indices left\n",
      "Before batch 73, indices available per class:\n",
      "  Class 1: 113 indices left\n",
      "  Class 0: 113 indices left\n",
      "  Class 2: 113 indices left\n",
      "Before batch 74, indices available per class:\n",
      "  Class 1: 108 indices left\n",
      "  Class 0: 108 indices left\n",
      "  Class 2: 108 indices left\n",
      "Before batch 75, indices available per class:\n",
      "  Class 1: 103 indices left\n",
      "  Class 0: 103 indices left\n",
      "  Class 2: 103 indices left\n",
      "Before batch 76, indices available per class:\n",
      "  Class 1: 98 indices left\n",
      "  Class 0: 98 indices left\n",
      "  Class 2: 98 indices left\n",
      "Before batch 77, indices available per class:\n",
      "  Class 1: 93 indices left\n",
      "  Class 0: 93 indices left\n",
      "  Class 2: 93 indices left\n",
      "Before batch 78, indices available per class:\n",
      "  Class 1: 88 indices left\n",
      "  Class 0: 88 indices left\n",
      "  Class 2: 88 indices left\n",
      "Before batch 79, indices available per class:\n",
      "  Class 1: 83 indices left\n",
      "  Class 0: 83 indices left\n",
      "  Class 2: 83 indices left\n",
      "Before batch 80, indices available per class:\n",
      "  Class 1: 78 indices left\n",
      "  Class 0: 78 indices left\n",
      "  Class 2: 78 indices left\n",
      "Before batch 81, indices available per class:\n",
      "  Class 1: 73 indices left\n",
      "  Class 0: 73 indices left\n",
      "  Class 2: 73 indices left\n",
      "Before batch 82, indices available per class:\n",
      "  Class 1: 68 indices left\n",
      "  Class 0: 68 indices left\n",
      "  Class 2: 68 indices left\n",
      "Before batch 83, indices available per class:\n",
      "  Class 1: 63 indices left\n",
      "  Class 0: 63 indices left\n",
      "  Class 2: 63 indices left\n",
      "Before batch 84, indices available per class:\n",
      "  Class 1: 58 indices left\n",
      "  Class 0: 58 indices left\n",
      "  Class 2: 58 indices left\n",
      "Before batch 85, indices available per class:\n",
      "  Class 1: 53 indices left\n",
      "  Class 0: 53 indices left\n",
      "  Class 2: 53 indices left\n",
      "Before batch 86, indices available per class:\n",
      "  Class 1: 48 indices left\n",
      "  Class 0: 48 indices left\n",
      "  Class 2: 48 indices left\n",
      "Before batch 87, indices available per class:\n",
      "  Class 1: 43 indices left\n",
      "  Class 0: 43 indices left\n",
      "  Class 2: 43 indices left\n",
      "Before batch 88, indices available per class:\n",
      "  Class 1: 38 indices left\n",
      "  Class 0: 38 indices left\n",
      "  Class 2: 38 indices left\n",
      "Before batch 89, indices available per class:\n",
      "  Class 1: 33 indices left\n",
      "  Class 0: 33 indices left\n",
      "  Class 2: 33 indices left\n",
      "Before batch 90, indices available per class:\n",
      "  Class 1: 28 indices left\n",
      "  Class 0: 28 indices left\n",
      "  Class 2: 28 indices left\n",
      "Before batch 91, indices available per class:\n",
      "  Class 1: 23 indices left\n",
      "  Class 0: 23 indices left\n",
      "  Class 2: 23 indices left\n",
      "Before batch 92, indices available per class:\n",
      "  Class 1: 18 indices left\n",
      "  Class 0: 18 indices left\n",
      "  Class 2: 18 indices left\n",
      "Before batch 93, indices available per class:\n",
      "  Class 1: 13 indices left\n",
      "  Class 0: 13 indices left\n",
      "  Class 2: 13 indices left\n",
      "Before batch 94, indices available per class:\n",
      "  Class 1: 8 indices left\n",
      "  Class 0: 8 indices left\n",
      "  Class 2: 8 indices left\n",
      "Batch 1 distribution: Counter({0: 5, 1: 5, 2: 5})\n",
      "Batch 2 distribution: Counter({2: 5, 1: 5, 0: 5})\n",
      "Batch 3 distribution: Counter({1: 5, 2: 5, 0: 5})\n",
      "\n",
      "Random batch label distributions for Experience 2 Validation:\n",
      "Before batch 1, indices available per class:\n",
      "  Class 2: 101 indices left\n",
      "  Class 1: 101 indices left\n",
      "  Class 0: 101 indices left\n",
      "Before batch 2, indices available per class:\n",
      "  Class 2: 96 indices left\n",
      "  Class 1: 96 indices left\n",
      "  Class 0: 96 indices left\n",
      "Before batch 3, indices available per class:\n",
      "  Class 2: 91 indices left\n",
      "  Class 1: 91 indices left\n",
      "  Class 0: 91 indices left\n",
      "Before batch 4, indices available per class:\n",
      "  Class 2: 86 indices left\n",
      "  Class 1: 86 indices left\n",
      "  Class 0: 86 indices left\n",
      "Before batch 5, indices available per class:\n",
      "  Class 2: 81 indices left\n",
      "  Class 1: 81 indices left\n",
      "  Class 0: 81 indices left\n",
      "Before batch 6, indices available per class:\n",
      "  Class 2: 76 indices left\n",
      "  Class 1: 76 indices left\n",
      "  Class 0: 76 indices left\n",
      "Before batch 7, indices available per class:\n",
      "  Class 2: 71 indices left\n",
      "  Class 1: 71 indices left\n",
      "  Class 0: 71 indices left\n",
      "Before batch 8, indices available per class:\n",
      "  Class 2: 66 indices left\n",
      "  Class 1: 66 indices left\n",
      "  Class 0: 66 indices left\n",
      "Before batch 9, indices available per class:\n",
      "  Class 2: 61 indices left\n",
      "  Class 1: 61 indices left\n",
      "  Class 0: 61 indices left\n",
      "Before batch 10, indices available per class:\n",
      "  Class 2: 56 indices left\n",
      "  Class 1: 56 indices left\n",
      "  Class 0: 56 indices left\n",
      "Before batch 11, indices available per class:\n",
      "  Class 2: 51 indices left\n",
      "  Class 1: 51 indices left\n",
      "  Class 0: 51 indices left\n",
      "Before batch 12, indices available per class:\n",
      "  Class 2: 46 indices left\n",
      "  Class 1: 46 indices left\n",
      "  Class 0: 46 indices left\n",
      "Before batch 13, indices available per class:\n",
      "  Class 2: 41 indices left\n",
      "  Class 1: 41 indices left\n",
      "  Class 0: 41 indices left\n",
      "Before batch 14, indices available per class:\n",
      "  Class 2: 36 indices left\n",
      "  Class 1: 36 indices left\n",
      "  Class 0: 36 indices left\n",
      "Before batch 15, indices available per class:\n",
      "  Class 2: 31 indices left\n",
      "  Class 1: 31 indices left\n",
      "  Class 0: 31 indices left\n",
      "Before batch 16, indices available per class:\n",
      "  Class 2: 26 indices left\n",
      "  Class 1: 26 indices left\n",
      "  Class 0: 26 indices left\n",
      "Before batch 17, indices available per class:\n",
      "  Class 2: 21 indices left\n",
      "  Class 1: 21 indices left\n",
      "  Class 0: 21 indices left\n",
      "Before batch 18, indices available per class:\n",
      "  Class 2: 16 indices left\n",
      "  Class 1: 16 indices left\n",
      "  Class 0: 16 indices left\n",
      "Before batch 19, indices available per class:\n",
      "  Class 2: 11 indices left\n",
      "  Class 1: 11 indices left\n",
      "  Class 0: 11 indices left\n",
      "Before batch 20, indices available per class:\n",
      "  Class 2: 6 indices left\n",
      "  Class 1: 6 indices left\n",
      "  Class 0: 6 indices left\n",
      "Batch 1 distribution: Counter({1: 5, 0: 5, 2: 5})\n",
      "Batch 2 distribution: Counter({0: 5, 1: 5, 2: 5})\n",
      "Batch 3 distribution: Counter({1: 5, 2: 5, 0: 5})\n",
      "\n",
      "Random batch label distributions for Experience 2 Test:\n",
      "Before batch 1, indices available per class:\n",
      "  Class 0: 102 indices left\n",
      "  Class 2: 102 indices left\n",
      "  Class 1: 102 indices left\n",
      "Before batch 2, indices available per class:\n",
      "  Class 0: 97 indices left\n",
      "  Class 2: 97 indices left\n",
      "  Class 1: 97 indices left\n",
      "Before batch 3, indices available per class:\n",
      "  Class 0: 92 indices left\n",
      "  Class 2: 92 indices left\n",
      "  Class 1: 92 indices left\n",
      "Before batch 4, indices available per class:\n",
      "  Class 0: 87 indices left\n",
      "  Class 2: 87 indices left\n",
      "  Class 1: 87 indices left\n",
      "Before batch 5, indices available per class:\n",
      "  Class 0: 82 indices left\n",
      "  Class 2: 82 indices left\n",
      "  Class 1: 82 indices left\n",
      "Before batch 6, indices available per class:\n",
      "  Class 0: 77 indices left\n",
      "  Class 2: 77 indices left\n",
      "  Class 1: 77 indices left\n",
      "Before batch 7, indices available per class:\n",
      "  Class 0: 72 indices left\n",
      "  Class 2: 72 indices left\n",
      "  Class 1: 72 indices left\n",
      "Before batch 8, indices available per class:\n",
      "  Class 0: 67 indices left\n",
      "  Class 2: 67 indices left\n",
      "  Class 1: 67 indices left\n",
      "Before batch 9, indices available per class:\n",
      "  Class 0: 62 indices left\n",
      "  Class 2: 62 indices left\n",
      "  Class 1: 62 indices left\n",
      "Before batch 10, indices available per class:\n",
      "  Class 0: 57 indices left\n",
      "  Class 2: 57 indices left\n",
      "  Class 1: 57 indices left\n",
      "Before batch 11, indices available per class:\n",
      "  Class 0: 52 indices left\n",
      "  Class 2: 52 indices left\n",
      "  Class 1: 52 indices left\n",
      "Before batch 12, indices available per class:\n",
      "  Class 0: 47 indices left\n",
      "  Class 2: 47 indices left\n",
      "  Class 1: 47 indices left\n",
      "Before batch 13, indices available per class:\n",
      "  Class 0: 42 indices left\n",
      "  Class 2: 42 indices left\n",
      "  Class 1: 42 indices left\n",
      "Before batch 14, indices available per class:\n",
      "  Class 0: 37 indices left\n",
      "  Class 2: 37 indices left\n",
      "  Class 1: 37 indices left\n",
      "Before batch 15, indices available per class:\n",
      "  Class 0: 32 indices left\n",
      "  Class 2: 32 indices left\n",
      "  Class 1: 32 indices left\n",
      "Before batch 16, indices available per class:\n",
      "  Class 0: 27 indices left\n",
      "  Class 2: 27 indices left\n",
      "  Class 1: 27 indices left\n",
      "Before batch 17, indices available per class:\n",
      "  Class 0: 22 indices left\n",
      "  Class 2: 22 indices left\n",
      "  Class 1: 22 indices left\n",
      "Before batch 18, indices available per class:\n",
      "  Class 0: 17 indices left\n",
      "  Class 2: 17 indices left\n",
      "  Class 1: 17 indices left\n",
      "Before batch 19, indices available per class:\n",
      "  Class 0: 12 indices left\n",
      "  Class 2: 12 indices left\n",
      "  Class 1: 12 indices left\n",
      "Before batch 20, indices available per class:\n",
      "  Class 0: 7 indices left\n",
      "  Class 2: 7 indices left\n",
      "  Class 1: 7 indices left\n",
      "Batch 1 distribution: Counter({0: 5, 1: 5, 2: 5})\n",
      "Batch 2 distribution: Counter({0: 5, 2: 5, 1: 5})\n",
      "Batch 3 distribution: Counter({0: 5, 2: 5, 1: 5})\n",
      "\n",
      "=== Processing Experience 3 ===\n",
      "\n",
      "Random batch label distributions for Experience 3 Train:\n",
      "Before batch 1, indices available per class:\n",
      "  Class 2: 473 indices left\n",
      "  Class 1: 473 indices left\n",
      "  Class 0: 473 indices left\n",
      "Before batch 2, indices available per class:\n",
      "  Class 2: 468 indices left\n",
      "  Class 1: 468 indices left\n",
      "  Class 0: 468 indices left\n",
      "Before batch 3, indices available per class:\n",
      "  Class 2: 463 indices left\n",
      "  Class 1: 463 indices left\n",
      "  Class 0: 463 indices left\n",
      "Before batch 4, indices available per class:\n",
      "  Class 2: 458 indices left\n",
      "  Class 1: 458 indices left\n",
      "  Class 0: 458 indices left\n",
      "Before batch 5, indices available per class:\n",
      "  Class 2: 453 indices left\n",
      "  Class 1: 453 indices left\n",
      "  Class 0: 453 indices left\n",
      "Before batch 6, indices available per class:\n",
      "  Class 2: 448 indices left\n",
      "  Class 1: 448 indices left\n",
      "  Class 0: 448 indices left\n",
      "Before batch 7, indices available per class:\n",
      "  Class 2: 443 indices left\n",
      "  Class 1: 443 indices left\n",
      "  Class 0: 443 indices left\n",
      "Before batch 8, indices available per class:\n",
      "  Class 2: 438 indices left\n",
      "  Class 1: 438 indices left\n",
      "  Class 0: 438 indices left\n",
      "Before batch 9, indices available per class:\n",
      "  Class 2: 433 indices left\n",
      "  Class 1: 433 indices left\n",
      "  Class 0: 433 indices left\n",
      "Before batch 10, indices available per class:\n",
      "  Class 2: 428 indices left\n",
      "  Class 1: 428 indices left\n",
      "  Class 0: 428 indices left\n",
      "Before batch 11, indices available per class:\n",
      "  Class 2: 423 indices left\n",
      "  Class 1: 423 indices left\n",
      "  Class 0: 423 indices left\n",
      "Before batch 12, indices available per class:\n",
      "  Class 2: 418 indices left\n",
      "  Class 1: 418 indices left\n",
      "  Class 0: 418 indices left\n",
      "Before batch 13, indices available per class:\n",
      "  Class 2: 413 indices left\n",
      "  Class 1: 413 indices left\n",
      "  Class 0: 413 indices left\n",
      "Before batch 14, indices available per class:\n",
      "  Class 2: 408 indices left\n",
      "  Class 1: 408 indices left\n",
      "  Class 0: 408 indices left\n",
      "Before batch 15, indices available per class:\n",
      "  Class 2: 403 indices left\n",
      "  Class 1: 403 indices left\n",
      "  Class 0: 403 indices left\n",
      "Before batch 16, indices available per class:\n",
      "  Class 2: 398 indices left\n",
      "  Class 1: 398 indices left\n",
      "  Class 0: 398 indices left\n",
      "Before batch 17, indices available per class:\n",
      "  Class 2: 393 indices left\n",
      "  Class 1: 393 indices left\n",
      "  Class 0: 393 indices left\n",
      "Before batch 18, indices available per class:\n",
      "  Class 2: 388 indices left\n",
      "  Class 1: 388 indices left\n",
      "  Class 0: 388 indices left\n",
      "Before batch 19, indices available per class:\n",
      "  Class 2: 383 indices left\n",
      "  Class 1: 383 indices left\n",
      "  Class 0: 383 indices left\n",
      "Before batch 20, indices available per class:\n",
      "  Class 2: 378 indices left\n",
      "  Class 1: 378 indices left\n",
      "  Class 0: 378 indices left\n",
      "Before batch 21, indices available per class:\n",
      "  Class 2: 373 indices left\n",
      "  Class 1: 373 indices left\n",
      "  Class 0: 373 indices left\n",
      "Before batch 22, indices available per class:\n",
      "  Class 2: 368 indices left\n",
      "  Class 1: 368 indices left\n",
      "  Class 0: 368 indices left\n",
      "Before batch 23, indices available per class:\n",
      "  Class 2: 363 indices left\n",
      "  Class 1: 363 indices left\n",
      "  Class 0: 363 indices left\n",
      "Before batch 24, indices available per class:\n",
      "  Class 2: 358 indices left\n",
      "  Class 1: 358 indices left\n",
      "  Class 0: 358 indices left\n",
      "Before batch 25, indices available per class:\n",
      "  Class 2: 353 indices left\n",
      "  Class 1: 353 indices left\n",
      "  Class 0: 353 indices left\n",
      "Before batch 26, indices available per class:\n",
      "  Class 2: 348 indices left\n",
      "  Class 1: 348 indices left\n",
      "  Class 0: 348 indices left\n",
      "Before batch 27, indices available per class:\n",
      "  Class 2: 343 indices left\n",
      "  Class 1: 343 indices left\n",
      "  Class 0: 343 indices left\n",
      "Before batch 28, indices available per class:\n",
      "  Class 2: 338 indices left\n",
      "  Class 1: 338 indices left\n",
      "  Class 0: 338 indices left\n",
      "Before batch 29, indices available per class:\n",
      "  Class 2: 333 indices left\n",
      "  Class 1: 333 indices left\n",
      "  Class 0: 333 indices left\n",
      "Before batch 30, indices available per class:\n",
      "  Class 2: 328 indices left\n",
      "  Class 1: 328 indices left\n",
      "  Class 0: 328 indices left\n",
      "Before batch 31, indices available per class:\n",
      "  Class 2: 323 indices left\n",
      "  Class 1: 323 indices left\n",
      "  Class 0: 323 indices left\n",
      "Before batch 32, indices available per class:\n",
      "  Class 2: 318 indices left\n",
      "  Class 1: 318 indices left\n",
      "  Class 0: 318 indices left\n",
      "Before batch 33, indices available per class:\n",
      "  Class 2: 313 indices left\n",
      "  Class 1: 313 indices left\n",
      "  Class 0: 313 indices left\n",
      "Before batch 34, indices available per class:\n",
      "  Class 2: 308 indices left\n",
      "  Class 1: 308 indices left\n",
      "  Class 0: 308 indices left\n",
      "Before batch 35, indices available per class:\n",
      "  Class 2: 303 indices left\n",
      "  Class 1: 303 indices left\n",
      "  Class 0: 303 indices left\n",
      "Before batch 36, indices available per class:\n",
      "  Class 2: 298 indices left\n",
      "  Class 1: 298 indices left\n",
      "  Class 0: 298 indices left\n",
      "Before batch 37, indices available per class:\n",
      "  Class 2: 293 indices left\n",
      "  Class 1: 293 indices left\n",
      "  Class 0: 293 indices left\n",
      "Before batch 38, indices available per class:\n",
      "  Class 2: 288 indices left\n",
      "  Class 1: 288 indices left\n",
      "  Class 0: 288 indices left\n",
      "Before batch 39, indices available per class:\n",
      "  Class 2: 283 indices left\n",
      "  Class 1: 283 indices left\n",
      "  Class 0: 283 indices left\n",
      "Before batch 40, indices available per class:\n",
      "  Class 2: 278 indices left\n",
      "  Class 1: 278 indices left\n",
      "  Class 0: 278 indices left\n",
      "Before batch 41, indices available per class:\n",
      "  Class 2: 273 indices left\n",
      "  Class 1: 273 indices left\n",
      "  Class 0: 273 indices left\n",
      "Before batch 42, indices available per class:\n",
      "  Class 2: 268 indices left\n",
      "  Class 1: 268 indices left\n",
      "  Class 0: 268 indices left\n",
      "Before batch 43, indices available per class:\n",
      "  Class 2: 263 indices left\n",
      "  Class 1: 263 indices left\n",
      "  Class 0: 263 indices left\n",
      "Before batch 44, indices available per class:\n",
      "  Class 2: 258 indices left\n",
      "  Class 1: 258 indices left\n",
      "  Class 0: 258 indices left\n",
      "Before batch 45, indices available per class:\n",
      "  Class 2: 253 indices left\n",
      "  Class 1: 253 indices left\n",
      "  Class 0: 253 indices left\n",
      "Before batch 46, indices available per class:\n",
      "  Class 2: 248 indices left\n",
      "  Class 1: 248 indices left\n",
      "  Class 0: 248 indices left\n",
      "Before batch 47, indices available per class:\n",
      "  Class 2: 243 indices left\n",
      "  Class 1: 243 indices left\n",
      "  Class 0: 243 indices left\n",
      "Before batch 48, indices available per class:\n",
      "  Class 2: 238 indices left\n",
      "  Class 1: 238 indices left\n",
      "  Class 0: 238 indices left\n",
      "Before batch 49, indices available per class:\n",
      "  Class 2: 233 indices left\n",
      "  Class 1: 233 indices left\n",
      "  Class 0: 233 indices left\n",
      "Before batch 50, indices available per class:\n",
      "  Class 2: 228 indices left\n",
      "  Class 1: 228 indices left\n",
      "  Class 0: 228 indices left\n",
      "Before batch 51, indices available per class:\n",
      "  Class 2: 223 indices left\n",
      "  Class 1: 223 indices left\n",
      "  Class 0: 223 indices left\n",
      "Before batch 52, indices available per class:\n",
      "  Class 2: 218 indices left\n",
      "  Class 1: 218 indices left\n",
      "  Class 0: 218 indices left\n",
      "Before batch 53, indices available per class:\n",
      "  Class 2: 213 indices left\n",
      "  Class 1: 213 indices left\n",
      "  Class 0: 213 indices left\n",
      "Before batch 54, indices available per class:\n",
      "  Class 2: 208 indices left\n",
      "  Class 1: 208 indices left\n",
      "  Class 0: 208 indices left\n",
      "Before batch 55, indices available per class:\n",
      "  Class 2: 203 indices left\n",
      "  Class 1: 203 indices left\n",
      "  Class 0: 203 indices left\n",
      "Before batch 56, indices available per class:\n",
      "  Class 2: 198 indices left\n",
      "  Class 1: 198 indices left\n",
      "  Class 0: 198 indices left\n",
      "Before batch 57, indices available per class:\n",
      "  Class 2: 193 indices left\n",
      "  Class 1: 193 indices left\n",
      "  Class 0: 193 indices left\n",
      "Before batch 58, indices available per class:\n",
      "  Class 2: 188 indices left\n",
      "  Class 1: 188 indices left\n",
      "  Class 0: 188 indices left\n",
      "Before batch 59, indices available per class:\n",
      "  Class 2: 183 indices left\n",
      "  Class 1: 183 indices left\n",
      "  Class 0: 183 indices left\n",
      "Before batch 60, indices available per class:\n",
      "  Class 2: 178 indices left\n",
      "  Class 1: 178 indices left\n",
      "  Class 0: 178 indices left\n",
      "Before batch 61, indices available per class:\n",
      "  Class 2: 173 indices left\n",
      "  Class 1: 173 indices left\n",
      "  Class 0: 173 indices left\n",
      "Before batch 62, indices available per class:\n",
      "  Class 2: 168 indices left\n",
      "  Class 1: 168 indices left\n",
      "  Class 0: 168 indices left\n",
      "Before batch 63, indices available per class:\n",
      "  Class 2: 163 indices left\n",
      "  Class 1: 163 indices left\n",
      "  Class 0: 163 indices left\n",
      "Before batch 64, indices available per class:\n",
      "  Class 2: 158 indices left\n",
      "  Class 1: 158 indices left\n",
      "  Class 0: 158 indices left\n",
      "Before batch 65, indices available per class:\n",
      "  Class 2: 153 indices left\n",
      "  Class 1: 153 indices left\n",
      "  Class 0: 153 indices left\n",
      "Before batch 66, indices available per class:\n",
      "  Class 2: 148 indices left\n",
      "  Class 1: 148 indices left\n",
      "  Class 0: 148 indices left\n",
      "Before batch 67, indices available per class:\n",
      "  Class 2: 143 indices left\n",
      "  Class 1: 143 indices left\n",
      "  Class 0: 143 indices left\n",
      "Before batch 68, indices available per class:\n",
      "  Class 2: 138 indices left\n",
      "  Class 1: 138 indices left\n",
      "  Class 0: 138 indices left\n",
      "Before batch 69, indices available per class:\n",
      "  Class 2: 133 indices left\n",
      "  Class 1: 133 indices left\n",
      "  Class 0: 133 indices left\n",
      "Before batch 70, indices available per class:\n",
      "  Class 2: 128 indices left\n",
      "  Class 1: 128 indices left\n",
      "  Class 0: 128 indices left\n",
      "Before batch 71, indices available per class:\n",
      "  Class 2: 123 indices left\n",
      "  Class 1: 123 indices left\n",
      "  Class 0: 123 indices left\n",
      "Before batch 72, indices available per class:\n",
      "  Class 2: 118 indices left\n",
      "  Class 1: 118 indices left\n",
      "  Class 0: 118 indices left\n",
      "Before batch 73, indices available per class:\n",
      "  Class 2: 113 indices left\n",
      "  Class 1: 113 indices left\n",
      "  Class 0: 113 indices left\n",
      "Before batch 74, indices available per class:\n",
      "  Class 2: 108 indices left\n",
      "  Class 1: 108 indices left\n",
      "  Class 0: 108 indices left\n",
      "Before batch 75, indices available per class:\n",
      "  Class 2: 103 indices left\n",
      "  Class 1: 103 indices left\n",
      "  Class 0: 103 indices left\n",
      "Before batch 76, indices available per class:\n",
      "  Class 2: 98 indices left\n",
      "  Class 1: 98 indices left\n",
      "  Class 0: 98 indices left\n",
      "Before batch 77, indices available per class:\n",
      "  Class 2: 93 indices left\n",
      "  Class 1: 93 indices left\n",
      "  Class 0: 93 indices left\n",
      "Before batch 78, indices available per class:\n",
      "  Class 2: 88 indices left\n",
      "  Class 1: 88 indices left\n",
      "  Class 0: 88 indices left\n",
      "Before batch 79, indices available per class:\n",
      "  Class 2: 83 indices left\n",
      "  Class 1: 83 indices left\n",
      "  Class 0: 83 indices left\n",
      "Before batch 80, indices available per class:\n",
      "  Class 2: 78 indices left\n",
      "  Class 1: 78 indices left\n",
      "  Class 0: 78 indices left\n",
      "Before batch 81, indices available per class:\n",
      "  Class 2: 73 indices left\n",
      "  Class 1: 73 indices left\n",
      "  Class 0: 73 indices left\n",
      "Before batch 82, indices available per class:\n",
      "  Class 2: 68 indices left\n",
      "  Class 1: 68 indices left\n",
      "  Class 0: 68 indices left\n",
      "Before batch 83, indices available per class:\n",
      "  Class 2: 63 indices left\n",
      "  Class 1: 63 indices left\n",
      "  Class 0: 63 indices left\n",
      "Before batch 84, indices available per class:\n",
      "  Class 2: 58 indices left\n",
      "  Class 1: 58 indices left\n",
      "  Class 0: 58 indices left\n",
      "Before batch 85, indices available per class:\n",
      "  Class 2: 53 indices left\n",
      "  Class 1: 53 indices left\n",
      "  Class 0: 53 indices left\n",
      "Before batch 86, indices available per class:\n",
      "  Class 2: 48 indices left\n",
      "  Class 1: 48 indices left\n",
      "  Class 0: 48 indices left\n",
      "Before batch 87, indices available per class:\n",
      "  Class 2: 43 indices left\n",
      "  Class 1: 43 indices left\n",
      "  Class 0: 43 indices left\n",
      "Before batch 88, indices available per class:\n",
      "  Class 2: 38 indices left\n",
      "  Class 1: 38 indices left\n",
      "  Class 0: 38 indices left\n",
      "Before batch 89, indices available per class:\n",
      "  Class 2: 33 indices left\n",
      "  Class 1: 33 indices left\n",
      "  Class 0: 33 indices left\n",
      "Before batch 90, indices available per class:\n",
      "  Class 2: 28 indices left\n",
      "  Class 1: 28 indices left\n",
      "  Class 0: 28 indices left\n",
      "Before batch 91, indices available per class:\n",
      "  Class 2: 23 indices left\n",
      "  Class 1: 23 indices left\n",
      "  Class 0: 23 indices left\n",
      "Before batch 92, indices available per class:\n",
      "  Class 2: 18 indices left\n",
      "  Class 1: 18 indices left\n",
      "  Class 0: 18 indices left\n",
      "Before batch 93, indices available per class:\n",
      "  Class 2: 13 indices left\n",
      "  Class 1: 13 indices left\n",
      "  Class 0: 13 indices left\n",
      "Before batch 94, indices available per class:\n",
      "  Class 2: 8 indices left\n",
      "  Class 1: 8 indices left\n",
      "  Class 0: 8 indices left\n",
      "Batch 1 distribution: Counter({2: 5, 1: 5, 0: 5})\n",
      "Batch 2 distribution: Counter({2: 5, 0: 5, 1: 5})\n",
      "Batch 3 distribution: Counter({1: 5, 0: 5, 2: 5})\n",
      "\n",
      "Random batch label distributions for Experience 3 Validation:\n",
      "Before batch 1, indices available per class:\n",
      "  Class 0: 101 indices left\n",
      "  Class 1: 101 indices left\n",
      "  Class 2: 101 indices left\n",
      "Before batch 2, indices available per class:\n",
      "  Class 0: 96 indices left\n",
      "  Class 1: 96 indices left\n",
      "  Class 2: 96 indices left\n",
      "Before batch 3, indices available per class:\n",
      "  Class 0: 91 indices left\n",
      "  Class 1: 91 indices left\n",
      "  Class 2: 91 indices left\n",
      "Before batch 4, indices available per class:\n",
      "  Class 0: 86 indices left\n",
      "  Class 1: 86 indices left\n",
      "  Class 2: 86 indices left\n",
      "Before batch 5, indices available per class:\n",
      "  Class 0: 81 indices left\n",
      "  Class 1: 81 indices left\n",
      "  Class 2: 81 indices left\n",
      "Before batch 6, indices available per class:\n",
      "  Class 0: 76 indices left\n",
      "  Class 1: 76 indices left\n",
      "  Class 2: 76 indices left\n",
      "Before batch 7, indices available per class:\n",
      "  Class 0: 71 indices left\n",
      "  Class 1: 71 indices left\n",
      "  Class 2: 71 indices left\n",
      "Before batch 8, indices available per class:\n",
      "  Class 0: 66 indices left\n",
      "  Class 1: 66 indices left\n",
      "  Class 2: 66 indices left\n",
      "Before batch 9, indices available per class:\n",
      "  Class 0: 61 indices left\n",
      "  Class 1: 61 indices left\n",
      "  Class 2: 61 indices left\n",
      "Before batch 10, indices available per class:\n",
      "  Class 0: 56 indices left\n",
      "  Class 1: 56 indices left\n",
      "  Class 2: 56 indices left\n",
      "Before batch 11, indices available per class:\n",
      "  Class 0: 51 indices left\n",
      "  Class 1: 51 indices left\n",
      "  Class 2: 51 indices left\n",
      "Before batch 12, indices available per class:\n",
      "  Class 0: 46 indices left\n",
      "  Class 1: 46 indices left\n",
      "  Class 2: 46 indices left\n",
      "Before batch 13, indices available per class:\n",
      "  Class 0: 41 indices left\n",
      "  Class 1: 41 indices left\n",
      "  Class 2: 41 indices left\n",
      "Before batch 14, indices available per class:\n",
      "  Class 0: 36 indices left\n",
      "  Class 1: 36 indices left\n",
      "  Class 2: 36 indices left\n",
      "Before batch 15, indices available per class:\n",
      "  Class 0: 31 indices left\n",
      "  Class 1: 31 indices left\n",
      "  Class 2: 31 indices left\n",
      "Before batch 16, indices available per class:\n",
      "  Class 0: 26 indices left\n",
      "  Class 1: 26 indices left\n",
      "  Class 2: 26 indices left\n",
      "Before batch 17, indices available per class:\n",
      "  Class 0: 21 indices left\n",
      "  Class 1: 21 indices left\n",
      "  Class 2: 21 indices left\n",
      "Before batch 18, indices available per class:\n",
      "  Class 0: 16 indices left\n",
      "  Class 1: 16 indices left\n",
      "  Class 2: 16 indices left\n",
      "Before batch 19, indices available per class:\n",
      "  Class 0: 11 indices left\n",
      "  Class 1: 11 indices left\n",
      "  Class 2: 11 indices left\n",
      "Before batch 20, indices available per class:\n",
      "  Class 0: 6 indices left\n",
      "  Class 1: 6 indices left\n",
      "  Class 2: 6 indices left\n",
      "Batch 1 distribution: Counter({0: 5, 1: 5, 2: 5})\n",
      "Batch 2 distribution: Counter({0: 5, 1: 5, 2: 5})\n",
      "Batch 3 distribution: Counter({2: 5, 1: 5, 0: 5})\n",
      "\n",
      "Random batch label distributions for Experience 3 Test:\n",
      "Before batch 1, indices available per class:\n",
      "  Class 0: 102 indices left\n",
      "  Class 2: 102 indices left\n",
      "  Class 1: 102 indices left\n",
      "Before batch 2, indices available per class:\n",
      "  Class 0: 97 indices left\n",
      "  Class 2: 97 indices left\n",
      "  Class 1: 97 indices left\n",
      "Before batch 3, indices available per class:\n",
      "  Class 0: 92 indices left\n",
      "  Class 2: 92 indices left\n",
      "  Class 1: 92 indices left\n",
      "Before batch 4, indices available per class:\n",
      "  Class 0: 87 indices left\n",
      "  Class 2: 87 indices left\n",
      "  Class 1: 87 indices left\n",
      "Before batch 5, indices available per class:\n",
      "  Class 0: 82 indices left\n",
      "  Class 2: 82 indices left\n",
      "  Class 1: 82 indices left\n",
      "Before batch 6, indices available per class:\n",
      "  Class 0: 77 indices left\n",
      "  Class 2: 77 indices left\n",
      "  Class 1: 77 indices left\n",
      "Before batch 7, indices available per class:\n",
      "  Class 0: 72 indices left\n",
      "  Class 2: 72 indices left\n",
      "  Class 1: 72 indices left\n",
      "Before batch 8, indices available per class:\n",
      "  Class 0: 67 indices left\n",
      "  Class 2: 67 indices left\n",
      "  Class 1: 67 indices left\n",
      "Before batch 9, indices available per class:\n",
      "  Class 0: 62 indices left\n",
      "  Class 2: 62 indices left\n",
      "  Class 1: 62 indices left\n",
      "Before batch 10, indices available per class:\n",
      "  Class 0: 57 indices left\n",
      "  Class 2: 57 indices left\n",
      "  Class 1: 57 indices left\n",
      "Before batch 11, indices available per class:\n",
      "  Class 0: 52 indices left\n",
      "  Class 2: 52 indices left\n",
      "  Class 1: 52 indices left\n",
      "Before batch 12, indices available per class:\n",
      "  Class 0: 47 indices left\n",
      "  Class 2: 47 indices left\n",
      "  Class 1: 47 indices left\n",
      "Before batch 13, indices available per class:\n",
      "  Class 0: 42 indices left\n",
      "  Class 2: 42 indices left\n",
      "  Class 1: 42 indices left\n",
      "Before batch 14, indices available per class:\n",
      "  Class 0: 37 indices left\n",
      "  Class 2: 37 indices left\n",
      "  Class 1: 37 indices left\n",
      "Before batch 15, indices available per class:\n",
      "  Class 0: 32 indices left\n",
      "  Class 2: 32 indices left\n",
      "  Class 1: 32 indices left\n",
      "Before batch 16, indices available per class:\n",
      "  Class 0: 27 indices left\n",
      "  Class 2: 27 indices left\n",
      "  Class 1: 27 indices left\n",
      "Before batch 17, indices available per class:\n",
      "  Class 0: 22 indices left\n",
      "  Class 2: 22 indices left\n",
      "  Class 1: 22 indices left\n",
      "Before batch 18, indices available per class:\n",
      "  Class 0: 17 indices left\n",
      "  Class 2: 17 indices left\n",
      "  Class 1: 17 indices left\n",
      "Before batch 19, indices available per class:\n",
      "  Class 0: 12 indices left\n",
      "  Class 2: 12 indices left\n",
      "  Class 1: 12 indices left\n",
      "Before batch 20, indices available per class:\n",
      "  Class 0: 7 indices left\n",
      "  Class 2: 7 indices left\n",
      "  Class 1: 7 indices left\n",
      "Batch 1 distribution: Counter({2: 5, 0: 5, 1: 5})\n",
      "Batch 2 distribution: Counter({2: 5, 1: 5, 0: 5})\n",
      "Batch 3 distribution: Counter({2: 5, 1: 5, 0: 5})\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Checking class distribution in each dataset",
   "id": "b08ae68b8ef0f2bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:52:49.875301Z",
     "start_time": "2025-03-09T12:52:49.856784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_class_distribution(df):\n",
    "    \"\"\"\n",
    "    Count occurrences of each class in the 'hotend_class' column of the DataFrame.\n",
    "    \"\"\"\n",
    "    return Counter(df['hotend_class'])\n",
    "\n",
    "# Loop over all experiments (assuming they are named train_1, valid_1, test_1, etc.)\n",
    "for exp_id in [1, 2, 3]:\n",
    "    # Retrieve each dataset using globals()\n",
    "    train_df = globals()[f\"train_{exp_id}\"]\n",
    "    valid_df = globals()[f\"valid_{exp_id}\"]\n",
    "    test_df  = globals()[f\"test_{exp_id}\"]\n",
    "    \n",
    "    # Count the class distribution\n",
    "    train_dist = count_class_distribution(train_df)\n",
    "    valid_dist = count_class_distribution(valid_df)\n",
    "    test_dist  = count_class_distribution(test_df)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"\\n--- Experience {exp_id} ---\")\n",
    "    print(f\"Train dataset size: {len(train_df)} | Class distribution: {train_dist}\")\n",
    "    print(f\"Validation dataset size: {len(valid_df)} | Class distribution: {valid_dist}\")\n",
    "    print(f\"Test dataset size: {len(test_df)} | Class distribution: {test_dist}\")"
   ],
   "id": "ce66fbf6167fc579",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experience 1 ---\n",
      "Train dataset size: 1419 | Class distribution: Counter({1: 473, 0: 473, 2: 473})\n",
      "Validation dataset size: 303 | Class distribution: Counter({1: 101, 2: 101, 0: 101})\n",
      "Test dataset size: 306 | Class distribution: Counter({2: 102, 0: 102, 1: 102})\n",
      "\n",
      "--- Experience 2 ---\n",
      "Train dataset size: 1419 | Class distribution: Counter({1: 473, 0: 473, 2: 473})\n",
      "Validation dataset size: 303 | Class distribution: Counter({2: 101, 1: 101, 0: 101})\n",
      "Test dataset size: 306 | Class distribution: Counter({0: 102, 2: 102, 1: 102})\n",
      "\n",
      "--- Experience 3 ---\n",
      "Train dataset size: 1419 | Class distribution: Counter({2: 473, 1: 473, 0: 473})\n",
      "Validation dataset size: 303 | Class distribution: Counter({0: 101, 1: 101, 2: 101})\n",
      "Test dataset size: 306 | Class distribution: Counter({0: 102, 2: 102, 1: 102})\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating a Naive Class which inherits from AvalancheDataset and contains all the expected functions",
   "id": "6f07f8ff5e4c2d8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:53:14.163732Z",
     "start_time": "2025-03-09T12:53:14.132046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from avalanche.benchmarks.utils import AvalancheDataset, DataAttribute\n",
    "from avalanche.benchmarks.utils.transforms import TupleTransform\n",
    "\n",
    "class NaiveCompatibleBalancedDataset(AvalancheDataset):\n",
    "    def __init__(self, data_frame, root_dir=None, transform=None, task_label=0, indices=None):\n",
    "        \"\"\"\n",
    "        Custom dataset compatible with Naive that inherits from AvalancheDataset.\n",
    "        It loads images from disk, applies transforms, and provides sample-wise\n",
    "        attributes for targets and task labels.\n",
    "        \n",
    "        Args:\n",
    "            data_frame (pd.DataFrame or list): If a DataFrame, it must contain columns\n",
    "                'image_path' and 'hotend_class'. If a list, it is assumed to be a pre-built\n",
    "                list of datasets (used in subset calls).\n",
    "            root_dir (str, optional): Directory where images are stored. Must be provided if data_frame is a DataFrame.\n",
    "            transform (callable, optional): Transformations to apply.\n",
    "            task_label (int, optional): Task label for continual learning.\n",
    "            indices (Sequence[int], optional): Optional indices for subsetting.\n",
    "        \"\"\"\n",
    "        # If data_frame is a list, assume this is a call from subset() and forward the call.\n",
    "        if isinstance(data_frame, list):\n",
    "            super().__init__(data_frame, indices=indices)\n",
    "            return\n",
    "\n",
    "        # Otherwise, data_frame is a DataFrame. Ensure root_dir is provided.\n",
    "        if root_dir is None:\n",
    "            raise ValueError(\"root_dir must be provided when data_frame is a DataFrame\")\n",
    "        \n",
    "        # Reset DataFrame index for consistency.\n",
    "        self.data = data_frame.reset_index(drop=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.task_label = task_label\n",
    "\n",
    "        # Define a default transform if none provided.\n",
    "        default_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        # Wrap the transform in TupleTransform so that it applies only to the image element.\n",
    "        self._transform_groups = {\n",
    "            \"train\": TupleTransform([transform or default_transform]),\n",
    "            \"eval\": TupleTransform([transform or default_transform])\n",
    "        }\n",
    "        \n",
    "        # Ensure required columns exist.\n",
    "        if 'hotend_class' not in self.data.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'hotend_class' for labels.\")\n",
    "        if 'image_path' not in self.data.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'image_path' for image paths.\")\n",
    "        \n",
    "        # Validate image paths and obtain valid indices.\n",
    "        valid_indices = self.get_valid_indices()\n",
    "        if len(valid_indices) == 0:\n",
    "            raise ValueError(\"No valid image paths found.\")\n",
    "        \n",
    "        # Compute targets and task labels for valid samples.\n",
    "        targets_data = torch.tensor(self.data.loc[valid_indices, 'hotend_class'].values)\n",
    "        targets_task_labels_data = torch.full_like(targets_data, self.task_label)\n",
    "        \n",
    "        # Prepare sample entries (one per valid image).\n",
    "        samples = []\n",
    "        for idx in valid_indices:\n",
    "            img_name = self.data.loc[idx, 'image_path'].strip()\n",
    "            full_img_path = os.path.join(self.root_dir, img_name)\n",
    "            label = int(self.data.loc[idx, 'hotend_class'])\n",
    "            samples.append({\n",
    "                \"img_path\": full_img_path,\n",
    "                \"label\": label,\n",
    "                \"task_label\": self.task_label\n",
    "            })\n",
    "        \n",
    "        # Define an internal basic dataset that loads images.\n",
    "        class BasicDataset(Dataset):\n",
    "            def __init__(self, samples):\n",
    "                self.samples = samples\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.samples)\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                sample = self.samples[idx]\n",
    "                img_path = sample[\"img_path\"]\n",
    "                try:\n",
    "                    # Load the image (ensure it is a PIL image).\n",
    "                    image = Image.open(img_path).convert('RGB')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {img_path}: {e}\")\n",
    "                    # If an error occurs, try the next sample.\n",
    "                    return self.__getitem__((idx + 1) % len(self.samples))\n",
    "                return image, sample[\"label\"], sample[\"task_label\"]\n",
    "        \n",
    "        basic_dataset = BasicDataset(samples)\n",
    "        \n",
    "        # Create data attributes.\n",
    "        data_attributes = [\n",
    "            DataAttribute(targets_data, name=\"targets\", use_in_getitem=True),\n",
    "            DataAttribute(targets_task_labels_data, name=\"targets_task_labels\", use_in_getitem=True)\n",
    "        ]\n",
    "        \n",
    "        # IMPORTANT: Pass the basic_dataset inside a list so that AvalancheDataset\n",
    "        # correctly sets up its internal flat data, and forward the indices parameter.\n",
    "        super().__init__(\n",
    "            [basic_dataset],\n",
    "            data_attributes=data_attributes,\n",
    "            transform_groups=self._transform_groups,\n",
    "            indices=indices\n",
    "        )\n",
    "    \n",
    "    def get_valid_indices(self):\n",
    "        \"\"\"Return indices for which the image file exists.\"\"\"\n",
    "        valid_indices = []\n",
    "        for idx in tqdm(range(len(self.data)), desc=\"Validating images\"):\n",
    "            img_name = self.data.loc[idx, 'image_path'].strip()\n",
    "            full_img_path = os.path.join(self.root_dir, img_name)\n",
    "            if os.path.exists(full_img_path):\n",
    "                valid_indices.append(idx)\n",
    "            else:\n",
    "                print(f\"Image does not exist: {full_img_path}\")\n",
    "        print(f\"Total valid images: {len(valid_indices)}\")\n",
    "        return valid_indices"
   ],
   "id": "e4de91fbe3b7bc65",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating training, validation and testing datasets to implement EWC",
   "id": "cfa1e2e56975ab9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:53:17.356643Z",
     "start_time": "2025-03-09T12:53:15.277438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define the transformation (e.g., normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Experience 1\n",
    "filtered_train_data_exp1 = filter_and_reindex(train_1, root_dir).rename(\n",
    "    columns={'img_path': 'image_path', 'class': 'hotend_class'}\n",
    ")\n",
    "filtered_valid_data_exp1 = filter_and_reindex(valid_1, root_dir).rename(\n",
    "    columns={'img_path': 'image_path', 'class': 'hotend_class'}\n",
    ")\n",
    "filtered_test_data_exp1 = filter_and_reindex(test_1, root_dir).rename(\n",
    "    columns={'img_path': 'image_path', 'class': 'hotend_class'}\n",
    ")\n",
    "\n",
    "train_dataset_exp1 = NaiveCompatibleBalancedDataset(\n",
    "    data_frame=filtered_train_data_exp1,\n",
    "    root_dir=root_dir,\n",
    "    transform=transform,\n",
    "    task_label=0\n",
    ")\n",
    "val_dataset_exp1 = NaiveCompatibleBalancedDataset(\n",
    "    data_frame=filtered_valid_data_exp1,\n",
    "    root_dir=root_dir,\n",
    "    transform=transform,\n",
    "    task_label=0\n",
    ")\n",
    "test_dataset_exp1 = NaiveCompatibleBalancedDataset(\n",
    "    data_frame=filtered_test_data_exp1,\n",
    "    root_dir=root_dir,\n",
    "    transform=transform,\n",
    "    task_label=0\n",
    ")\n",
    "\n",
    "# Experience 2\n",
    "filtered_train_data_exp2 = filter_and_reindex(train_2, root_dir).rename(\n",
    "    columns={'img_path': 'image_path', 'class': 'hotend_class'}\n",
    ")\n",
    "filtered_valid_data_exp2 = filter_and_reindex(valid_2, root_dir).rename(\n",
    "    columns={'img_path': 'image_path', 'class': 'hotend_class'}\n",
    ")\n",
    "filtered_test_data_exp2 = filter_and_reindex(test_2, root_dir).rename(\n",
    "    columns={'img_path': 'image_path', 'class': 'hotend_class'}\n",
    ")\n",
    "\n",
    "train_dataset_exp2 = NaiveCompatibleBalancedDataset(\n",
    "    data_frame=filtered_train_data_exp2,\n",
    "    root_dir=root_dir,\n",
    "    transform=transform,\n",
    "    task_label=0\n",
    ")\n",
    "val_dataset_exp2 = NaiveCompatibleBalancedDataset(\n",
    "    data_frame=filtered_valid_data_exp2,\n",
    "    root_dir=root_dir,\n",
    "    transform=transform,\n",
    "    task_label=0\n",
    ")\n",
    "test_dataset_exp2 = NaiveCompatibleBalancedDataset(\n",
    "    data_frame=filtered_test_data_exp2,\n",
    "    root_dir=root_dir,\n",
    "    transform=transform,\n",
    "    task_label=0\n",
    ")\n",
    "\n",
    "# Experience 3\n",
    "filtered_train_data_exp3 = filter_and_reindex(train_3, root_dir).rename(\n",
    "    columns={'img_path': 'image_path', 'class': 'hotend_class'}\n",
    ")\n",
    "filtered_valid_data_exp3 = filter_and_reindex(valid_3, root_dir).rename(\n",
    "    columns={'img_path': 'image_path', 'class': 'hotend_class'}\n",
    ")\n",
    "filtered_test_data_exp3 = filter_and_reindex(test_3, root_dir).rename(\n",
    "    columns={'img_path': 'image_path', 'class': 'hotend_class'}\n",
    ")\n",
    "\n",
    "train_dataset_exp3 = NaiveCompatibleBalancedDataset(\n",
    "    data_frame=filtered_train_data_exp3,\n",
    "    root_dir=root_dir,\n",
    "    transform=transform,\n",
    "    task_label=0\n",
    ")\n",
    "val_dataset_exp3 = NaiveCompatibleBalancedDataset(\n",
    "    data_frame=filtered_valid_data_exp3,\n",
    "    root_dir=root_dir,\n",
    "    transform=transform,\n",
    "    task_label=0\n",
    ")\n",
    "test_dataset_exp3 = NaiveCompatibleBalancedDataset(\n",
    "    data_frame=filtered_test_data_exp3,\n",
    "    root_dir=root_dir,\n",
    "    transform=transform,\n",
    "    task_label=0\n",
    ")"
   ],
   "id": "7986d3634e8a788c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating images: 100%|██████████| 1419/1419 [00:00<00:00, 9136.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid images: 1419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating images: 100%|██████████| 303/303 [00:00<00:00, 15155.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid images: 303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating images: 100%|██████████| 306/306 [00:00<00:00, 12749.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid images: 306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating images: 100%|██████████| 1419/1419 [00:00<00:00, 13677.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid images: 1419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating images: 100%|██████████| 303/303 [00:00<00:00, 9328.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid images: 303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating images: 100%|██████████| 306/306 [00:00<00:00, 10369.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid images: 306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating images: 100%|██████████| 1419/1419 [00:00<00:00, 12868.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid images: 1419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating images: 100%|██████████| 303/303 [00:00<00:00, 9171.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid images: 303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating images: 100%|██████████| 306/306 [00:00<00:00, 13441.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid images: 306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating Dataloaders for more efficient data processing",
   "id": "5889010372b14f54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:53:18.080355Z",
     "start_time": "2025-03-09T12:53:18.038096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# Experience 1: using the filtered DataFrames\n",
    "train_sampler_exp1 = BalancedBatchSampler(\n",
    "    data_frame=filtered_train_data_exp1, \n",
    "    batch_size=15, \n",
    "    samples_per_class=5\n",
    ")\n",
    "val_sampler_exp1 = BalancedBatchSampler(\n",
    "    data_frame=filtered_valid_data_exp1, \n",
    "    batch_size=15, \n",
    "    samples_per_class=5\n",
    ")\n",
    "test_sampler_exp1 = BalancedBatchSampler(\n",
    "    data_frame=filtered_test_data_exp1, \n",
    "    batch_size=15, \n",
    "    samples_per_class=5\n",
    ")\n",
    "\n",
    "train_loader_exp1 = DataLoader(train_dataset_exp1, batch_sampler=train_sampler_exp1, shuffle=False)\n",
    "val_loader_exp1 = DataLoader(val_dataset_exp1, batch_sampler=val_sampler_exp1, shuffle=False)\n",
    "test_loader_exp1 = DataLoader(test_dataset_exp1, batch_sampler=test_sampler_exp1, shuffle=False)\n",
    "\n",
    "# Experience 2: using the filtered DataFrames\n",
    "train_sampler_exp2 = BalancedBatchSampler(\n",
    "    data_frame=filtered_train_data_exp2, \n",
    "    batch_size=15, \n",
    "    samples_per_class=5\n",
    ")\n",
    "val_sampler_exp2 = BalancedBatchSampler(\n",
    "    data_frame=filtered_valid_data_exp2, \n",
    "    batch_size=15, \n",
    "    samples_per_class=5\n",
    ")\n",
    "test_sampler_exp2 = BalancedBatchSampler(\n",
    "    data_frame=filtered_test_data_exp2, \n",
    "    batch_size=15, \n",
    "    samples_per_class=5\n",
    ")\n",
    "\n",
    "train_loader_exp2 = DataLoader(train_dataset_exp2, batch_sampler=train_sampler_exp2, shuffle=False)\n",
    "val_loader_exp2 = DataLoader(val_dataset_exp2, batch_sampler=val_sampler_exp2, shuffle=False)\n",
    "test_loader_exp2 = DataLoader(test_dataset_exp2, batch_sampler=test_sampler_exp2, shuffle=False)\n",
    "\n",
    "# Experience 3: using the filtered DataFrames\n",
    "train_sampler_exp3 = BalancedBatchSampler(\n",
    "    data_frame=filtered_train_data_exp3, \n",
    "    batch_size=15, \n",
    "    samples_per_class=5\n",
    ")\n",
    "val_sampler_exp3 = BalancedBatchSampler(\n",
    "    data_frame=filtered_valid_data_exp3, \n",
    "    batch_size=15, \n",
    "    samples_per_class=5\n",
    ")\n",
    "test_sampler_exp3 = BalancedBatchSampler(\n",
    "    data_frame=filtered_test_data_exp3, \n",
    "    batch_size=15, \n",
    "    samples_per_class=5\n",
    ")\n",
    "\n",
    "train_loader_exp3 = DataLoader(train_dataset_exp3, batch_sampler=train_sampler_exp3, shuffle=False)\n",
    "val_loader_exp3 = DataLoader(val_dataset_exp3, batch_sampler=val_sampler_exp3, shuffle=False)\n",
    "test_loader_exp3 = DataLoader(test_dataset_exp3, batch_sampler=test_sampler_exp3, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders for all experiences created successfully!\")"
   ],
   "id": "6a9cb0dfaef9af15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders for all experiences created successfully!\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Checking class distribution in each dataset",
   "id": "9b51c95f873a2933"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:53:19.290181Z",
     "start_time": "2025-03-09T12:53:19.257311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "def count_classes(dataset):\n",
    "    # Convert the FlatData into a list of values via list comprehension.\n",
    "    values = [x for x in dataset.targets]\n",
    "    # Convert the list of values to a tensor.\n",
    "    t = torch.tensor(values)\n",
    "    # Now, convert the tensor to a NumPy array and count the classes.\n",
    "    return Counter(t.numpy())\n",
    "\n",
    "print(\"Class distribution in Train Dataset 1:\", count_classes(train_dataset_exp1))\n",
    "print(\"Class distribution in Train Dataset 2:\", count_classes(train_dataset_exp2))\n",
    "print(\"Class distribution in Train Dataset 3:\", count_classes(train_dataset_exp3))\n",
    "print(\"Class distribution in Validation Dataset 1:\", count_classes(val_dataset_exp1))\n",
    "print(\"Class distribution in Validation Dataset 2:\", count_classes(val_dataset_exp2))\n",
    "print(\"Class distribution in Validation Dataset 3:\", count_classes(val_dataset_exp3))\n",
    "print(\"Class distribution in Test Dataset 1:\", count_classes(test_dataset_exp1))\n",
    "print(\"Class distribution in Test Dataset 2:\", count_classes(test_dataset_exp2))\n",
    "print(\"Class distribution in Test Dataset 3:\", count_classes(test_dataset_exp3))"
   ],
   "id": "de58432abf1af70c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in Train Dataset 1: Counter({1: 473, 0: 473, 2: 473})\n",
      "Class distribution in Train Dataset 2: Counter({1: 473, 0: 473, 2: 473})\n",
      "Class distribution in Train Dataset 3: Counter({2: 473, 1: 473, 0: 473})\n",
      "Class distribution in Validation Dataset 1: Counter({1: 101, 2: 101, 0: 101})\n",
      "Class distribution in Validation Dataset 2: Counter({2: 101, 1: 101, 0: 101})\n",
      "Class distribution in Validation Dataset 3: Counter({0: 101, 1: 101, 2: 101})\n",
      "Class distribution in Test Dataset 1: Counter({2: 102, 0: 102, 1: 102})\n",
      "Class distribution in Test Dataset 2: Counter({0: 102, 2: 102, 1: 102})\n",
      "Class distribution in Test Dataset 3: Counter({0: 102, 2: 102, 1: 102})\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Checking unique classes in each experience",
   "id": "b025b4df93557d61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:53:23.781857Z",
     "start_time": "2025-03-09T12:53:23.767946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from avalanche.benchmarks.utils import DataAttribute\n",
    "from avalanche.benchmarks import benchmark_from_datasets\n",
    "# Create the benchmark from your datasets\n",
    "dataset_streams = {\n",
    "    \"train\": [train_dataset_exp1, train_dataset_exp2, train_dataset_exp3],\n",
    "    \"test\": [test_dataset_exp1, test_dataset_exp2, test_dataset_exp3]\n",
    "}\n",
    "# You might want to ensure the benchmark is created here\n",
    "benchmark = benchmark_from_datasets(**dataset_streams)\n",
    "\n",
    "for experience in benchmark.train_stream:\n",
    "    print(f\"Start of experience: {experience.current_experience}\")\n",
    "    \n",
    "    # Try to get the targets via the dynamic property.\n",
    "    try:\n",
    "        targets_data = experience.dataset.targets.data\n",
    "    except AttributeError:\n",
    "        # Fallback: access the internal _data_attributes dictionary.\n",
    "        targets_data = experience.dataset._data_attributes[\"targets\"].data\n",
    "\n",
    "    # If targets_data doesn't have 'tolist', assume it's already iterable.\n",
    "    if hasattr(targets_data, \"tolist\"):\n",
    "        unique_classes = set(targets_data.tolist())\n",
    "    else:\n",
    "        unique_classes = set(targets_data)\n",
    "        \n",
    "    print(f\"Classes in this experience: {unique_classes}\")"
   ],
   "id": "daf703114359b497",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of experience: 0\n",
      "Classes in this experience: {0, 1, 2}\n",
      "Start of experience: 1\n",
      "Classes in this experience: {0, 1, 2}\n",
      "Start of experience: 2\n",
      "Classes in this experience: {0, 1, 2}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Implementing Naive strategy using Avalanche - the end-to-end continual learning library",
   "id": "845a0d03b5690f43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:23:27.735070Z",
     "start_time": "2025-03-09T12:53:26.760421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import csv\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from avalanche.benchmarks import benchmark_from_datasets\n",
    "from avalanche.training import Naive\n",
    "from avalanche.training.plugins import EvaluationPlugin, LRSchedulerPlugin\n",
    "from avalanche.evaluation.metrics import (\n",
    "    accuracy_metrics,\n",
    "    loss_metrics,\n",
    "    timing_metrics,\n",
    "    cpu_usage_metrics,\n",
    "    forgetting_metrics,\n",
    "    StreamConfusionMatrix,\n",
    "    disk_usage_metrics\n",
    ")\n",
    "from avalanche.logging import TensorboardLogger, TextLogger, InteractiveLogger\n",
    "from models.cnn_models import SimpleCNN\n",
    "\n",
    "# -------------------------------\n",
    "# Create main folder for experiment outputs\n",
    "# -------------------------------\n",
    "MAIN_OUT_FOLDER = \"naive_experiment\"\n",
    "os.makedirs(MAIN_OUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# -------------------------------\n",
    "# Helper function: log metrics to CSV\n",
    "# -------------------------------\n",
    "def log_metrics(csv_file, experience_id, epoch, train_loss, train_acc, val_loss, val_acc):\n",
    "    with open(csv_file, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([experience_id, epoch, train_loss, train_acc, val_loss, val_acc])\n",
    "\n",
    "# -------------------------------\n",
    "# Helper function: plot metrics and save to folder \"loss_plots\"\n",
    "# -------------------------------\n",
    "def plot_metrics(epochs, train_vals, val_vals, ylabel, title, filename):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(epochs, train_vals, 'b-', label=f'Train {ylabel}')\n",
    "    plt.plot(epochs, val_vals, 'r-', label=f'Validation {ylabel}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    print(f\"Saved plot to {filename}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Setup loggers and device\n",
    "# -------------------------------\n",
    "tb_logger = TensorboardLogger()\n",
    "text_logger = TextLogger(open('log.txt', 'a'))\n",
    "interactive_logger = InteractiveLogger()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -------------------------------\n",
    "# Setup benchmark and validation datasets\n",
    "# -------------------------------\n",
    "\n",
    "dataset_streams = {\n",
    "    \"train\": [train_dataset_exp1, train_dataset_exp2, train_dataset_exp3],\n",
    "    \"test\": [test_dataset_exp1, test_dataset_exp2, test_dataset_exp3]\n",
    "}\n",
    "benchmark = benchmark_from_datasets(**dataset_streams)\n",
    "# Also store the validation datasets for later use\n",
    "validation_datasets = [val_dataset_exp1, val_dataset_exp2, val_dataset_exp3]\n",
    "\n",
    "# -------------------------------\n",
    "# Set learning rate\n",
    "# -------------------------------\n",
    "lr = 0.001\n",
    "results_summary = []\n",
    "\n",
    "# Create a folder for this hyperparameter configuration.\n",
    "config_folder = os.path.join(MAIN_OUT_FOLDER, f\"lr{lr}\")\n",
    "os.makedirs(config_folder, exist_ok=True)\n",
    "\n",
    "# Prepare a CSV file for summary metrics for this configuration.\n",
    "csv_file_path = os.path.join(config_folder, f\"summary_lr{lr}.csv\")\n",
    "with open(csv_file_path, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Experience\", \"Epoch\", \"TrainLoss\", \"TrainAcc\", \"ValLoss\", \"ValAcc\"])\n",
    "\n",
    "# For each experience.\n",
    "for exp_idx, experience in enumerate(benchmark.train_stream):\n",
    "    print(f\"\\n=== Start of Experience {experience.current_experience} ===\")\n",
    "    \n",
    "    # Select the correct DataLoaders for this experience\n",
    "    if experience.current_experience == 0:\n",
    "        current_train_loader = train_loader_exp1\n",
    "        current_val_loader   = val_loader_exp1\n",
    "        current_test_loader  = test_loader_exp1\n",
    "    elif experience.current_experience == 1:\n",
    "        current_train_loader = train_loader_exp2\n",
    "        current_val_loader   = val_loader_exp2\n",
    "        current_test_loader  = test_loader_exp2\n",
    "    elif experience.current_experience == 2:\n",
    "        current_train_loader = train_loader_exp3\n",
    "        current_val_loader   = val_loader_exp3\n",
    "        current_test_loader  = test_loader_exp3\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected experience id\")\n",
    "    \n",
    "    # Create a folder for this experience.\n",
    "    exp_folder = os.path.join(config_folder, f\"experience_{experience.current_experience}\")\n",
    "    os.makedirs(exp_folder, exist_ok=True)\n",
    "    \n",
    "    # Use the corresponding validation DataLoader to create a validation benchmark.\n",
    "    # (Here, we create a benchmark from the underlying dataset of the validation loader.)\n",
    "    val_benchmark = benchmark_from_datasets(\n",
    "        train=[current_val_loader.dataset],\n",
    "        test=[current_val_loader.dataset]\n",
    "    )\n",
    "    \n",
    "    # Reinitialize model, criterion, and optimizer.\n",
    "    model = SimpleCNN(num_classes=3).to(device)\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    \n",
    "    # Setup a learning rate scheduler and plugin.\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
    "    lr_plugin = LRSchedulerPlugin(scheduler)\n",
    "    \n",
    "    evaluator = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=False, epoch=True, experience=True, stream=True),\n",
    "        loss_metrics(minibatch=False, epoch=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger, text_logger, tb_logger]\n",
    "    )\n",
    "    \n",
    "    # Instantiate the Naive strategy.\n",
    "    # We set train_epochs=1 so we can call train() in a loop for each epoch.\n",
    "    cl_strategy = Naive(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        train_mb_size=15,\n",
    "        train_epochs=1,\n",
    "        eval_mb_size=15,\n",
    "        evaluator=evaluator,\n",
    "        eval_every=-1,  # We'll do our own per-epoch evaluation.\n",
    "        device=device,\n",
    "        plugins=[lr_plugin]\n",
    "    )\n",
    "    \n",
    "    # Lists to store per-epoch metrics.\n",
    "    train_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    val_acc_history = []\n",
    "    num_epochs = 2\n",
    "    \n",
    "    # Train for num_epochs using the custom train DataLoader.\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"Epoch {epoch} for Experience {experience.current_experience} ...\")\n",
    "        train_res = cl_strategy.train(experience, train_loader=current_train_loader)\n",
    "        epoch_train_loss = train_res.get(\"Loss_Epoch/train_phase/train_stream\", None)\n",
    "        epoch_train_acc  = train_res.get(\"Top1_Acc_Epoch/train_phase/train_stream\", None)\n",
    "        train_loss_history.append(epoch_train_loss)\n",
    "        train_acc_history.append(epoch_train_acc)\n",
    "        \n",
    "        # Evaluate on the validation DataLoader.\n",
    "        val_res = cl_strategy.eval(val_benchmark.test_stream)\n",
    "        epoch_val_loss = val_res.get(\"Loss_Stream/eval_phase/test_stream\", None)\n",
    "        epoch_val_acc  = val_res.get(\"Top1_Acc_Stream/eval_phase/test_stream\", None)\n",
    "        val_loss_history.append(epoch_val_loss)\n",
    "        val_acc_history.append(epoch_val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch}: Train Loss={epoch_train_loss:.4f}, Train Acc={epoch_train_acc:.4f} | Val Loss={epoch_val_loss:.4f}, Val Acc={epoch_val_acc:.4f}\")\n",
    "        \n",
    "        # Step the scheduler.\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Log this epoch's metrics.\n",
    "        log_metrics(csv_file_path, experience.current_experience, epoch, epoch_train_loss, epoch_train_acc, epoch_val_loss, epoch_val_acc)\n",
    "    \n",
    "    # Plot losses.\n",
    "    epochs_range = list(range(1, num_epochs + 1))\n",
    "    loss_title = f\"Exp {experience.current_experience}: lr={lr} (Loss)\"\n",
    "    loss_plot_path = os.path.join(exp_folder, f\"loss_plot_exp{experience.current_experience}.png\")\n",
    "    plot_metrics(epochs_range, train_loss_history, val_loss_history, \"Loss\", loss_title, loss_plot_path)\n",
    "    \n",
    "    # Plot accuracies.\n",
    "    acc_title = f\"Exp {experience.current_experience}: lr={lr} (Accuracy)\"\n",
    "    acc_plot_path = os.path.join(exp_folder, f\"acc_plot_exp{experience.current_experience}.png\")\n",
    "    plot_metrics(epochs_range, train_acc_history, val_acc_history, \"Accuracy\", acc_title, acc_plot_path)\n",
    "    \n",
    "    # Evaluate on the entire test DataLoader.\n",
    "    print(\"Testing on the entire test stream...\")\n",
    "    test_res = cl_strategy.eval(benchmark.test_stream)\n",
    "    print(\"Test results:\", test_res)\n",
    "    \n",
    "    # Optionally, store a summary for this hyperparameter configuration.\n",
    "    results_summary.append({\n",
    "        \"lr\": lr,\n",
    "        \"final_train_loss\": train_loss_history[-1],\n",
    "        \"final_val_loss\": val_loss_history[-1],\n",
    "        \"test_results\": test_res\n",
    "    })\n",
    "\n",
    "print(\"\\n=== Hyperparameter Search Summary ===\")\n",
    "for res in results_summary:\n",
    "    print(res)"
   ],
   "id": "5e3269bdfd9b0c77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Start of Experience 0 ===\n",
      "Epoch 1 for Experience 0 ...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [03:02<00:00,  1.92s/it]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream = 0.9921\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream = 0.5060\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 from test stream --\n",
      "100%|██████████| 21/21 [00:27<00:00,  1.32s/it]\n",
      "> Eval on experience 0 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp000 = 0.9011\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp000 = 0.5446\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream = 0.9011\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream = 0.5446\n",
      "Epoch 1: Train Loss=0.9921, Train Acc=0.5060 | Val Loss=0.9011, Val Acc=0.5446\n",
      "Epoch 2 for Experience 0 ...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [02:34<00:00,  1.63s/it]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream = 0.9395\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream = 0.5356\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 from test stream --\n",
      "100%|██████████| 21/21 [00:15<00:00,  1.38it/s]\n",
      "> Eval on experience 0 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp000 = 0.9097\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp000 = 0.5710\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream = 0.9097\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream = 0.5710\n",
      "Epoch 2: Train Loss=0.9395, Train Acc=0.5356 | Val Loss=0.9097, Val Acc=0.5710\n",
      "Saved plot to naive_experiment\\lr0.001\\experience_0\\loss_plot_exp0.png\n",
      "Saved plot to naive_experiment\\lr0.001\\experience_0\\acc_plot_exp0.png\n",
      "Testing on the entire test stream...\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 from test stream --\n",
      "100%|██████████| 21/21 [00:23<00:00,  1.11s/it]\n",
      "> Eval on experience 0 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp000 = 0.9117\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp000 = 0.5490\n",
      "-- Starting eval on experience 1 from test stream --\n",
      "100%|██████████| 21/21 [00:24<00:00,  1.16s/it]\n",
      "> Eval on experience 1 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp001 = 1.1376\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp001 = 0.3399\n",
      "-- Starting eval on experience 2 from test stream --\n",
      "100%|██████████| 21/21 [00:21<00:00,  1.01s/it]\n",
      "> Eval on experience 2 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp002 = 1.2486\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp002 = 0.3366\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream = 1.0993\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream = 0.4085\n",
      "Test results: {'Top1_Acc_Epoch/train_phase/train_stream': 0.5355884425651868, 'Loss_Epoch/train_phase/train_stream': 0.9394696972334864, 'Top1_Acc_Exp/eval_phase/test_stream/Exp000': 0.5490196078431373, 'Loss_Exp/eval_phase/test_stream/Exp000': 0.9117271070386849, 'Top1_Acc_Stream/eval_phase/test_stream': 0.4084967320261438, 'Loss_Stream/eval_phase/test_stream': 1.0992997134822646, 'Top1_Acc_Exp/eval_phase/test_stream/Exp001': 0.33986928104575165, 'Loss_Exp/eval_phase/test_stream/Exp001': 1.1376005954602186, 'Top1_Acc_Exp/eval_phase/test_stream/Exp002': 0.3366013071895425, 'Loss_Exp/eval_phase/test_stream/Exp002': 1.2485714379478903}\n",
      "\n",
      "=== Start of Experience 1 ===\n",
      "Epoch 1 for Experience 1 ...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [04:49<00:00,  3.04s/it]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream = 1.1023\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream = 0.3488\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 from test stream --\n",
      "100%|██████████| 21/21 [00:31<00:00,  1.49s/it]\n",
      "> Eval on experience 0 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp000 = 1.0995\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp000 = 0.3333\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream = 1.0995\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream = 0.3333\n",
      "Epoch 1: Train Loss=1.1023, Train Acc=0.3488 | Val Loss=1.0995, Val Acc=0.3333\n",
      "Epoch 2 for Experience 1 ...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [04:39<00:00,  2.94s/it]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream = 1.0985\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream = 0.3460\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 from test stream --\n",
      "100%|██████████| 21/21 [00:35<00:00,  1.68s/it]\n",
      "> Eval on experience 0 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp000 = 1.0979\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp000 = 0.3498\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream = 1.0979\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream = 0.3498\n",
      "Epoch 2: Train Loss=1.0985, Train Acc=0.3460 | Val Loss=1.0979, Val Acc=0.3498\n",
      "Saved plot to naive_experiment\\lr0.001\\experience_1\\loss_plot_exp1.png\n",
      "Saved plot to naive_experiment\\lr0.001\\experience_1\\acc_plot_exp1.png\n",
      "Testing on the entire test stream...\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 from test stream --\n",
      "100%|██████████| 21/21 [00:35<00:00,  1.69s/it]\n",
      "> Eval on experience 0 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp000 = 1.1038\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp000 = 0.2614\n",
      "-- Starting eval on experience 1 from test stream --\n",
      "100%|██████████| 21/21 [00:34<00:00,  1.66s/it]\n",
      "> Eval on experience 1 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp001 = 1.0978\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp001 = 0.3366\n",
      "-- Starting eval on experience 2 from test stream --\n",
      "100%|██████████| 21/21 [00:35<00:00,  1.70s/it]\n",
      "> Eval on experience 2 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp002 = 1.0985\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp002 = 0.3529\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream = 1.1000\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream = 0.3170\n",
      "Test results: {'Top1_Acc_Epoch/train_phase/train_stream': 0.3460183227625088, 'Loss_Epoch/train_phase/train_stream': 1.098492786949835, 'Top1_Acc_Exp/eval_phase/test_stream/Exp000': 0.26143790849673204, 'Loss_Exp/eval_phase/test_stream/Exp000': 1.103835918155371, 'Top1_Acc_Stream/eval_phase/test_stream': 0.31699346405228757, 'Loss_Stream/eval_phase/test_stream': 1.1000463074328852, 'Top1_Acc_Exp/eval_phase/test_stream/Exp001': 0.3366013071895425, 'Loss_Exp/eval_phase/test_stream/Exp001': 1.0978111355912452, 'Top1_Acc_Exp/eval_phase/test_stream/Exp002': 0.35294117647058826, 'Loss_Exp/eval_phase/test_stream/Exp002': 1.0984918685520397}\n",
      "\n",
      "=== Start of Experience 2 ===\n",
      "Epoch 1 for Experience 2 ...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [04:46<00:00,  3.01s/it]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream = 1.1002\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream = 0.3256\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 from test stream --\n",
      "100%|██████████| 21/21 [00:24<00:00,  1.18s/it]\n",
      "> Eval on experience 0 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp000 = 1.0985\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp000 = 0.3399\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream = 1.0985\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream = 0.3399\n",
      "Epoch 1: Train Loss=1.1002, Train Acc=0.3256 | Val Loss=1.0985, Val Acc=0.3399\n",
      "Epoch 2 for Experience 2 ...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 95/95 [03:19<00:00,  2.10s/it]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream = 1.0990\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream = 0.3214\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 from test stream --\n",
      "100%|██████████| 21/21 [00:19<00:00,  1.08it/s]\n",
      "> Eval on experience 0 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp000 = 1.0989\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp000 = 0.3465\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream = 1.0989\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream = 0.3465\n",
      "Epoch 2: Train Loss=1.0990, Train Acc=0.3214 | Val Loss=1.0989, Val Acc=0.3465\n",
      "Saved plot to naive_experiment\\lr0.001\\experience_2\\loss_plot_exp2.png\n",
      "Saved plot to naive_experiment\\lr0.001\\experience_2\\acc_plot_exp2.png\n",
      "Testing on the entire test stream...\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 from test stream --\n",
      "100%|██████████| 21/21 [00:25<00:00,  1.19s/it]\n",
      "> Eval on experience 0 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp000 = 1.0880\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp000 = 0.4641\n",
      "-- Starting eval on experience 1 from test stream --\n",
      "100%|██████████| 21/21 [00:21<00:00,  1.03s/it]\n",
      "> Eval on experience 1 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp001 = 1.1024\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp001 = 0.3072\n",
      "-- Starting eval on experience 2 from test stream --\n",
      "100%|██████████| 21/21 [00:28<00:00,  1.37s/it]\n",
      "> Eval on experience 2 from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Exp002 = 1.0995\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Exp002 = 0.3007\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream = 1.0966\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream = 0.3573\n",
      "Test results: {'Top1_Acc_Epoch/train_phase/train_stream': 0.321353065539112, 'Loss_Epoch/train_phase/train_stream': 1.0990419556676208, 'Top1_Acc_Exp/eval_phase/test_stream/Exp000': 0.46405228758169936, 'Loss_Exp/eval_phase/test_stream/Exp000': 1.088013692229402, 'Top1_Acc_Stream/eval_phase/test_stream': 0.3572984749455338, 'Loss_Stream/eval_phase/test_stream': 1.0966430742756215, 'Top1_Acc_Exp/eval_phase/test_stream/Exp001': 0.30718954248366015, 'Loss_Exp/eval_phase/test_stream/Exp001': 1.1024427963238137, 'Top1_Acc_Exp/eval_phase/test_stream/Exp002': 0.3006535947712418, 'Loss_Exp/eval_phase/test_stream/Exp002': 1.0994727342736488}\n",
      "\n",
      "=== Hyperparameter Search Summary ===\n",
      "{'lr': 0.001, 'final_train_loss': 0.9394696972334864, 'final_val_loss': 0.909724758403136, 'test_results': {'Top1_Acc_Epoch/train_phase/train_stream': 0.5355884425651868, 'Loss_Epoch/train_phase/train_stream': 0.9394696972334864, 'Top1_Acc_Exp/eval_phase/test_stream/Exp000': 0.5490196078431373, 'Loss_Exp/eval_phase/test_stream/Exp000': 0.9117271070386849, 'Top1_Acc_Stream/eval_phase/test_stream': 0.4084967320261438, 'Loss_Stream/eval_phase/test_stream': 1.0992997134822646, 'Top1_Acc_Exp/eval_phase/test_stream/Exp001': 0.33986928104575165, 'Loss_Exp/eval_phase/test_stream/Exp001': 1.1376005954602186, 'Top1_Acc_Exp/eval_phase/test_stream/Exp002': 0.3366013071895425, 'Loss_Exp/eval_phase/test_stream/Exp002': 1.2485714379478903}}\n",
      "{'lr': 0.001, 'final_train_loss': 1.098492786949835, 'final_val_loss': 1.0979458565759186, 'test_results': {'Top1_Acc_Epoch/train_phase/train_stream': 0.3460183227625088, 'Loss_Epoch/train_phase/train_stream': 1.098492786949835, 'Top1_Acc_Exp/eval_phase/test_stream/Exp000': 0.26143790849673204, 'Loss_Exp/eval_phase/test_stream/Exp000': 1.103835918155371, 'Top1_Acc_Stream/eval_phase/test_stream': 0.31699346405228757, 'Loss_Stream/eval_phase/test_stream': 1.1000463074328852, 'Top1_Acc_Exp/eval_phase/test_stream/Exp001': 0.3366013071895425, 'Loss_Exp/eval_phase/test_stream/Exp001': 1.0978111355912452, 'Top1_Acc_Exp/eval_phase/test_stream/Exp002': 0.35294117647058826, 'Loss_Exp/eval_phase/test_stream/Exp002': 1.0984918685520397}}\n",
      "{'lr': 0.001, 'final_train_loss': 1.0990419556676208, 'final_val_loss': 1.0989033314261105, 'test_results': {'Top1_Acc_Epoch/train_phase/train_stream': 0.321353065539112, 'Loss_Epoch/train_phase/train_stream': 1.0990419556676208, 'Top1_Acc_Exp/eval_phase/test_stream/Exp000': 0.46405228758169936, 'Loss_Exp/eval_phase/test_stream/Exp000': 1.088013692229402, 'Top1_Acc_Stream/eval_phase/test_stream': 0.3572984749455338, 'Loss_Stream/eval_phase/test_stream': 1.0966430742756215, 'Top1_Acc_Exp/eval_phase/test_stream/Exp001': 0.30718954248366015, 'Loss_Exp/eval_phase/test_stream/Exp001': 1.1024427963238137, 'Top1_Acc_Exp/eval_phase/test_stream/Exp002': 0.3006535947712418, 'Loss_Exp/eval_phase/test_stream/Exp002': 1.0994727342736488}}\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e0feec4c343a2c2f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
